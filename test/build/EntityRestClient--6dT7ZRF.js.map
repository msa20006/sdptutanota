{"version":3,"file":"EntityRestClient--6dT7ZRF.js","names":["progressTracker: ExposedProgressTracker","totalWork: number","amount: number","totalAmount: number","worker: Worker | DedicatedWorkerGlobalScope","message: Message<OutgoingCommandType>","handler: (message: Message<IncomingCommandType>) => unknown","ev: any","requestSender: RequestSender<\"facade\">","_: object","property: string","impls: T","message: Request<IncomingRequestType>","facadeName: string","locator: CommonLocator","e: any","msg: any","message: MainRequest","msg: Request<WorkerRequestType>","entropy: Array<EntropyDataChunk>","listener: EventBusListener","cache: EntityRestCache","userFacade: UserFacade","entity: EntityClient","instanceMapper: InstanceMapper","socketFactory: (path: string) => WebSocket","sleepDetector: SleepDetector","progressTracker: ExposedProgressTracker","connectMode: ConnectMode","sysModelInfo","tutanotaModelInfo","event: CloseEvent","error: any","message: MessageEvent<string>","closeOption: CloseEventBusOption","closeIfOpen: boolean","enableAutomaticState: boolean","delay: number | null","delay","counterData: WebsocketCounterData","data: PhishingMarkerWebsocketData","data: WebsocketLeaderStatus","eventBatch: EntityUpdate[]","reconnectionInterval: readonly [number, number]","lastIds: Map<Id, Array<Id>>","eventQueue: EventQueue","eventBatches: EntityEventBatch[]","groupId: Id","modification: QueuedBatch","batch: QueuedBatch","batchId: Id","events: ReadonlyArray<EntityUpdate>","Type","buf","ui8a","handlers: Map<string, CustomCacheHandler<ListElementEntity>>","typeRef: TypeRef<T>","entityRestClient: EntityRestClient","storage: CacheStorage","listId: Id","start: Id","count: number","reverse: boolean","rawList: Array<CalendarEvent>","chunk: Array<CalendarEvent>","range: Range","ids: Array<Id>","data: Date","typ: string","options: EncodeOptions","Type","bytes: number","customTypeEncoders: { [typeName: string]: typeof dateEncoder }","customTypeDecoders: Array<TypeDecoder>","tags: Array<TypeDecoder>","sqlCipherFacade: SqlCipherFacade","interWindowEventSender: InterWindowEventFacadeSendDispatcher","dateProvider: DateProvider","migrator: OfflineStorageMigrator","cleaner: OfflineStorageCleaner","userId: string","databaseKey: Uint8Array","typeRef: TypeRef<SomeEntity>","listId: Id | null","elementId: Id","typeModel: TypeModel","TypeId","type: string","typeRef: TypeRef<T>","listId: Id","elementIds: Id[]","serializedList: ReadonlyArray<Record<string, TaggedSqlValue>>","start: Id","count: number","reverse: boolean","originalEntity: SomeEntity","formattedQuery: FormattedQuery","lowerId: Id","upperId: Id","lower: Id","upper: Id","groupId: Id","batchId: Id","ms: number","typeRef: TypeRef<unknown>","listId: string","typeRef: TypeRef<ListElementEntity>","typeRef: TypeRef<ElementEntity>","model: VersionMetadataBaseKey","version: number","entityRestClient: EntityRestClient","owner: Id","listIdsByType: Map<string, Set<Id>>","key: K","value: OfflineDbMeta[K]","timeRangeDays: number | null","userId: Id","typeRef: TypeRef<ElementEntity | ListElementEntity>","rawCutoffId: Id","loaded: Uint8Array","deserialized: any","loaded: Array<Uint8Array>","result: Array<T>","chunkSize: number","originalList: SqlValue[]","formatter: (chunk: SqlValue[]) => FormattedQuery","result: Array<Record<string, TaggedSqlValue>>","params: SqlValue[]","entityRestClient: EntityRestClient","storage: CacheStorage","typeRef: TypeRef<T>","id: PropertyType<T, \"_id\">","opts: EntityRestClientLoadOptions","listId: Id | null","ids: Array<Id>","ownerEncSessionKeyProvider?: OwnerEncSessionKeyProvider","instance: T","extraHeaders?: Dict","options?: EntityRestClientSetupOptions","instances: Array<T>","options?: EntityRestClientEraseOptions","groupId: Id","batchId: Id","lastUpdateTime: number","elementId: Id","entitiesInCache: T[]","idsToLoad: Id[]","listId: Id","start: Id","count: number","reverse: boolean","countRequested: number","wasReverseRequest: boolean","receivedEntities: T[]","batch: QueuedBatch","createUpdatesForLETs: EntityUpdate[]","regularUpdates: EntityUpdate[]","postMultipleEventUpdates: EntityUpdate[][]","otherEventUpdates: EntityUpdate[]","typeRef: TypeRef<any>","update: EntityUpdate","batch: ReadonlyArray<EntityUpdate>","mail: Mail","newListId: Id","typeRef: TypeRef<SomeEntity>","cached: SomeEntity","newEntity: SomeEntity","ids: Id[]","ret: Id[]","typeRef: TypeRef<unknown>","opts?: EntityRestClientLoadOptions","e: Error","id: Id | IdTuple","range: Range","startId: Id","typeModel: TypeModel","start: string","typeRef: TypeRef<any>","cacheMode: CacheMode | undefined","authDataProvider: AuthDataProvider","restClient: RestClient","lazyCrypto: lazy<CryptoFacade>","instanceMapper: InstanceMapper","blobAccessTokenFacade: BlobAccessTokenFacade","typeRef: TypeRef<T>","id: PropertyType<T, \"_id\">","opts: EntityRestClientLoadOptions","ownerKeyProvider: OwnerKeyProvider | undefined","migratedEntity: Record<string, any>","typeModel: TypeModel","listId: Id","start: Id","count: number","reverse: boolean","listId: Id | null","elementIds: Array<Id>","ownerEncSessionKeyProvider?: OwnerEncSessionKeyProvider","json: string","archiveId: Id | null","queryParams: { ids: string }","headers: Dict | undefined","path: string","suspensionBehavior?: SuspensionBehavior","loadedEntities: Array<any>","instance: any","model: TypeModel","sessionKey: AesKey | null","instance: T","extraHeaders?: Dict","options?: EntityRestClientSetupOptions","instances: Array<T>","errors: Error[]","failedInstances: T[]","idChunks: Array<Array<Id>>","e","options?: EntityRestClientUpdateOptions","options?: EntityRestClientEraseOptions","elementId: Id | null","queryParams: Dict | undefined","extraHeaders: Dict | undefined","ownerKey: OwnerKeyProvider | VersionedKey | undefined","batch: QueuedBatch","result: any","r: any","servers: BlobServerUrl[]","mapper: Mapper<string, T>","errorMsg: string","error: Error | null","doBlobRequest: () => Promise<T>","doEvictTokenBeforeRetry: () => void"],"sources":["../../src/common/api/worker/ProgressMonitorDelegate.ts","../../src/common/api/common/threading/Transport.ts","../../src/common/api/common/WorkerProxy.ts","../../src/common/api/main/WorkerClient.ts","../../src/common/api/worker/EventBusClient.ts","../../libs/cborg.js","../../src/common/api/worker/rest/CustomCacheHandler.ts","../../src/common/api/worker/offline/OfflineStorage.ts","../../src/common/api/worker/rest/DefaultEntityRestCache.ts","../../src/common/api/worker/rest/EntityRestClient.ts"],"sourcesContent":["import type { IProgressMonitor, ProgressMonitorId } from \"../common/utils/ProgressMonitor\"\nimport { ExposedProgressTracker } from \"../main/ProgressTracker.js\"\n\n/** A wrapper that will send completed work remotely */\nexport class ProgressMonitorDelegate implements IProgressMonitor {\n\tprivate readonly ref: Promise<ProgressMonitorId>\n\n\tconstructor(private readonly progressTracker: ExposedProgressTracker, readonly totalWork: number) {\n\t\tthis.ref = progressTracker.registerMonitor(totalWork)\n\t}\n\n\tasync workDone(amount: number) {\n\t\tawait this.progressTracker.workDoneForMonitor(await this.ref, amount)\n\t}\n\n\tasync totalWorkDone(totalAmount: number) {\n\t\tawait this.progressTracker.workDoneForMonitor(await this.ref, this.totalWork - totalAmount)\n\t}\n\n\tasync completed() {\n\t\tawait this.progressTracker.workDoneForMonitor(await this.ref, this.totalWork)\n\t}\n}\n","import { Message } from \"./MessageDispatcher.js\"\nimport { downcast } from \"@tutao/tutanota-utils\"\n\nexport interface Transport<OutgoingCommandType, IncomingCommandType> {\n\t/**\n\t * Post a message to the other side of the transport\n\t */\n\tpostMessage(message: Message<OutgoingCommandType>): void\n\n\t/**\n\t * Set the handler for messages coming from the other end of the transport\n\t */\n\tsetMessageHandler(handler: (message: Message<IncomingCommandType>) => unknown): unknown\n}\n\n/**\n * Queue transport for both WorkerClient and WorkerImpl\n */\nexport class WebWorkerTransport<OutgoingCommandType, IncomingCommandType> implements Transport<OutgoingCommandType, IncomingCommandType> {\n\tconstructor(private readonly worker: Worker | DedicatedWorkerGlobalScope) {}\n\n\tpostMessage(message: Message<OutgoingCommandType>): void {\n\t\treturn this.worker.postMessage(message)\n\t}\n\n\tsetMessageHandler(handler: (message: Message<IncomingCommandType>) => unknown) {\n\t\tthis.worker.onmessage = (ev: any) => handler(downcast(ev.data))\n\t}\n}\n","/**\n * @file Functions to automatically expose certain interfaces across the WorkerProtocol Queue.\n */\nimport { downcast } from \"@tutao/tutanota-utils\"\nimport { Request } from \"./threading/MessageDispatcher.js\"\nimport { ProgrammingError } from \"./error/ProgrammingError\"\n\ntype RequestSender<RequestTypes> = (arg0: Request<RequestTypes>) => Promise<any>\n\n/**\n * Generates proxy where each field will be treated as an interface with async methods. Each method will delegate to the\n * {@param requestSender}.\n * Attention! Make sure that the *only* fields on T are facades. Every facade method must return promise or Bad Things will happen.\n * You should specify T explicitly to avoid mistakes.\n */\nexport function exposeRemote<T>(requestSender: RequestSender<\"facade\">): T {\n\t// Outer proxy is just used to generate individual facades\n\tconst workerProxy = new Proxy(\n\t\t{},\n\t\t{\n\t\t\tget: (_: object, property: string) => {\n\t\t\t\treturn facadeProxy(requestSender, property)\n\t\t\t},\n\t\t},\n\t)\n\treturn downcast<T>(workerProxy)\n}\n\n/**\n * Generate a handler which will delegate to {@param impls}.\n * Attention! Make sure that the *only* fields on T are facades. Every facade method must return promise or Bad Things will happen.\n * You should specify T explicitly to avoid mistakes.\n */\nexport function exposeLocal<T extends object, IncomingRequestType>(impls: T): (message: Request<IncomingRequestType>) => Promise<any> {\n\treturn (message: Request<IncomingRequestType>) => {\n\t\tconst [facade, fn, args] = message.args\n\t\tconst impl = downcast(impls)[facade]\n\n\t\tif (impl == null) {\n\t\t\tthrow new ProgrammingError(`Facade is not exposed: ${facade}.${fn} (exposeLocal)`)\n\t\t}\n\n\t\treturn downcast(impl)[fn](...args)\n\t}\n}\n\nexport type FacadeImpls = {\n\t[facade: string]: any\n}\n\nexport type DelayedImpls<IMPLS extends FacadeImpls> = {\n\t[Property in keyof IMPLS]: () => Promise<IMPLS[Property]>\n}\n\n/**\n * Generate a handler which will delegate to {@param impls}.\n * Attention! Make sure that the *only* fields on T are functions that resolve to facades. Every facade method must return promise or Bad Things will happen.\n * You should specify T explicitly to avoid mistakes.\n */\nexport function exposeLocalDelayed<T extends DelayedImpls<FacadeImpls>, IncomingRequestType>(\n\timpls: T,\n): (message: Request<IncomingRequestType>) => Promise<any> {\n\treturn async (message: Request<IncomingRequestType>) => {\n\t\tconst [facade, fn, args] = message.args\n\t\tconst init = downcast(impls)[facade]\n\n\t\tif (init == null) {\n\t\t\tthrow new ProgrammingError(`Facade is not exposed: ${facade}.${fn} (exposeLocal)`)\n\t\t}\n\n\t\tconst impl = await init()\n\t\tif (impl == null) {\n\t\t\tthrow new ProgrammingError(`Facade is not lazy: ${facade}.${fn} (exposeLocalDelayed)`)\n\t\t}\n\n\t\treturn downcast(impl)[fn](...args)\n\t}\n}\n\n/**\n * Generates proxy which will generate methods which will simulate methods of the facade.\n */\nfunction facadeProxy(requestSender: RequestSender<\"facade\">, facadeName: string) {\n\treturn new Proxy(\n\t\t{},\n\t\t{\n\t\t\tget: (_: object, property: string) => {\n\t\t\t\t// We generate whatever property is asked from us and we assume it is a function. It is normally enforced by the type system\n\t\t\t\t// but runtime also tests for certain properties e.g. when returning a value from a promise it will try to test whether it\n\t\t\t\t// is \"promisable\". It is doing so by checking whether there's a \"then\" function. So we explicitly say we don't have such\n\t\t\t\t// a function.\n\t\t\t\tif (property === \"then\") {\n\t\t\t\t\treturn undefined\n\t\t\t\t} else {\n\t\t\t\t\treturn (...args: any[]) => {\n\t\t\t\t\t\tconst request = new Request(\"facade\" as const, [facadeName, property, args])\n\t\t\t\t\t\treturn requestSender(request)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\t\t},\n\t)\n}\n","import type { Commands } from \"../common/threading/MessageDispatcher.js\"\nimport { MessageDispatcher, Request } from \"../common/threading/MessageDispatcher.js\"\nimport { Transport, WebWorkerTransport } from \"../common/threading/Transport.js\"\nimport { assertMainOrNode } from \"../common/Env\"\nimport { client } from \"../../misc/ClientDetector\"\nimport type { DeferredObject } from \"@tutao/tutanota-utils\"\nimport { defer, downcast } from \"@tutao/tutanota-utils\"\nimport { handleUncaughtError } from \"../../misc/ErrorHandler\"\nimport { DelayedImpls, exposeLocalDelayed, exposeRemote } from \"../common/WorkerProxy\"\nimport type { RestClient } from \"../worker/rest/RestClient\"\nimport { EntropyDataChunk } from \"../worker/facades/EntropyFacade.js\"\nimport { objToError } from \"../common/utils/ErrorUtils.js\"\nimport { CommonLocator } from \"./CommonLocator.js\"\nimport { CommonWorkerInterface, MainInterface } from \"../worker/workerInterfaces.js\"\n\nassertMainOrNode()\n\ntype ProgressUpdater = (progress: number) => unknown\ntype MainRequest = Request<MainRequestType>\n\nexport const enum WsConnectionState {\n\tconnecting,\n\tconnected,\n\tterminated,\n}\n\nexport class WorkerClient {\n\tprivate _deferredInitialized: DeferredObject<void> = defer()\n\tprivate _isInitialized: boolean = false\n\n\tprivate _dispatcher!: MessageDispatcher<WorkerRequestType, MainRequestType>\n\n\tconstructor() {\n\t\tthis.initialized.then(() => {\n\t\t\tthis._isInitialized = true\n\t\t})\n\t}\n\n\tget initialized(): Promise<void> {\n\t\treturn this._deferredInitialized.promise\n\t}\n\n\tasync init(locator: CommonLocator): Promise<void> {\n\t\tif (env.mode !== \"Test\") {\n\t\t\tconst { prefixWithoutFile } = window.tutao.appState\n\t\t\t// In apps/desktop we load HTML file and url ends on path/index.html so we want to load path/WorkerBootstrap.js.\n\t\t\t// In browser we load at domain.com or localhost/path (locally) and we want to load domain.com/WorkerBootstrap.js or\n\t\t\t// localhost/path/WorkerBootstrap.js respectively.\n\t\t\t// Service worker has similar logic but it has luxury of knowing that it's served as sw.js.\n\t\t\tconst workerUrl = prefixWithoutFile + \"/worker-bootstrap.js\"\n\t\t\tconst worker = new Worker(workerUrl, { type: \"module\" })\n\t\t\tthis._dispatcher = new MessageDispatcher(new WebWorkerTransport(worker), this.queueCommands(locator), \"main-worker\")\n\t\t\tawait this._dispatcher.postRequest(new Request(\"setup\", [window.env, this.getInitialEntropy(), client.browserData()]))\n\n\t\t\tworker.onerror = (e: any) => {\n\t\t\t\tthrow new Error(`could not setup worker: ${e.name} ${e.stack} ${e.message} ${e}`)\n\t\t\t}\n\t\t} else {\n\t\t\t// node: we do not use workers but connect the client and the worker queues directly with each other\n\t\t\t// attention: do not load directly with require() here because in the browser SystemJS would load the WorkerImpl in the client although this code is not executed\n\t\t\t// @ts-ignore\n\t\t\tconst WorkerImpl = globalThis.testWorker\n\t\t\tconst workerImpl = new WorkerImpl(this, true)\n\t\t\tawait workerImpl.init(client.browserData())\n\t\t\tworkerImpl._queue._transport = {\n\t\t\t\tpostMessage: (msg: any) => this._dispatcher.handleMessage(msg),\n\t\t\t}\n\t\t\tthis._dispatcher = new MessageDispatcher(\n\t\t\t\t{\n\t\t\t\t\tpostMessage: function (msg: any) {\n\t\t\t\t\t\tworkerImpl._queue.handleMessage(msg)\n\t\t\t\t\t},\n\t\t\t\t} as Transport<WorkerRequestType, MainRequestType>,\n\t\t\t\tthis.queueCommands(locator),\n\t\t\t\t\"main-worker\",\n\t\t\t)\n\t\t}\n\n\t\tthis._deferredInitialized.resolve()\n\t}\n\n\tqueueCommands(locator: CommonLocator): Commands<MainRequestType> {\n\t\treturn {\n\t\t\texecNative: (message: MainRequest) => locator.native.invokeNative(downcast(message.args[0]), downcast(message.args[1])),\n\t\t\terror: (message: MainRequest) => {\n\t\t\t\thandleUncaughtError(objToError(message.args[0]))\n\t\t\t\treturn Promise.resolve()\n\t\t\t},\n\t\t\tfacade: exposeLocalDelayed<DelayedImpls<MainInterface>, MainRequestType>({\n\t\t\t\tasync loginListener() {\n\t\t\t\t\treturn locator.loginListener\n\t\t\t\t},\n\t\t\t\tasync wsConnectivityListener() {\n\t\t\t\t\treturn locator.connectivityModel\n\t\t\t\t},\n\t\t\t\tasync progressTracker() {\n\t\t\t\t\treturn locator.progressTracker\n\t\t\t\t},\n\t\t\t\tasync eventController() {\n\t\t\t\t\treturn locator.eventController\n\t\t\t\t},\n\t\t\t\tasync operationProgressTracker() {\n\t\t\t\t\treturn locator.operationProgressTracker\n\t\t\t\t},\n\t\t\t\tasync infoMessageHandler() {\n\t\t\t\t\treturn locator.infoMessageHandler\n\t\t\t\t},\n\t\t\t}),\n\t\t}\n\t}\n\n\tgetWorkerInterface(): CommonWorkerInterface {\n\t\treturn exposeRemote<CommonWorkerInterface>(async (request) => this._postRequest(request))\n\t}\n\n\trestRequest(...args: Parameters<RestClient[\"request\"]>): Promise<any | null> {\n\t\treturn this._postRequest(new Request(\"restRequest\", args))\n\t}\n\n\t/** @private visible for tests */\n\tasync _postRequest(msg: Request<WorkerRequestType>): Promise<any> {\n\t\tawait this.initialized\n\t\treturn this._dispatcher.postRequest(msg)\n\t}\n\n\treset(): Promise<void> {\n\t\treturn this._postRequest(new Request(\"reset\", []))\n\t}\n\n\t/**\n\t * Add data from either secure random source or Math.random as entropy.\n\t */\n\tprivate getInitialEntropy(): Array<EntropyDataChunk> {\n\t\tconst valueList = new Uint32Array(16)\n\t\tcrypto.getRandomValues(valueList)\n\t\tconst entropy: Array<EntropyDataChunk> = []\n\n\t\tfor (let i = 0; i < valueList.length; i++) {\n\t\t\t// 32 because we have 32-bit values Uint32Array\n\t\t\tentropy.push({\n\t\t\t\tsource: \"random\",\n\t\t\t\tentropy: 32,\n\t\t\t\tdata: valueList[i],\n\t\t\t})\n\t\t}\n\n\t\treturn entropy\n\t}\n}\n\nexport function bootstrapWorker(locator: CommonLocator): WorkerClient {\n\tconst worker = new WorkerClient()\n\tconst start = Date.now()\n\tworker.init(locator).then(() => console.log(\"worker init time (ms):\", Date.now() - start))\n\treturn worker\n}\n","import { assertWorkerOrNode } from \"../common/Env\"\nimport {\n\tAccessBlockedError,\n\tAccessDeactivatedError,\n\tConnectionError,\n\thandleRestError,\n\tNotAuthorizedError,\n\tServiceUnavailableError,\n\tSessionExpiredError,\n} from \"../common/error/RestError\"\nimport {\n\tcreateWebsocketLeaderStatus,\n\tEntityEventBatch,\n\tEntityEventBatchTypeRef,\n\tEntityUpdate,\n\tWebsocketCounterData,\n\tWebsocketCounterDataTypeRef,\n\tWebsocketEntityData,\n\tWebsocketEntityDataTypeRef,\n\tWebsocketLeaderStatus,\n\tWebsocketLeaderStatusTypeRef,\n} from \"../entities/sys/TypeRefs.js\"\nimport { binarySearch, delay, getTypeId, identity, lastThrow, ofClass, promiseFilter, randomIntFromInterval, TypeRef } from \"@tutao/tutanota-utils\"\nimport { OutOfSyncError } from \"../common/error/OutOfSyncError\"\nimport { CloseEventBusOption, GroupType, SECOND_MS } from \"../common/TutanotaConstants\"\nimport { CancelledError } from \"../common/error/CancelledError\"\nimport { EntityClient } from \"../common/EntityClient\"\nimport type { QueuedBatch } from \"./EventQueue.js\"\nimport { EventQueue } from \"./EventQueue.js\"\nimport { ProgressMonitorDelegate } from \"./ProgressMonitorDelegate\"\nimport { compareOldestFirst, GENERATED_MAX_ID, GENERATED_MIN_ID, getElementId, getListId } from \"../common/utils/EntityUtils\"\nimport { InstanceMapper } from \"./crypto/InstanceMapper\"\nimport { WsConnectionState } from \"../main/WorkerClient\"\nimport { EntityRestCache } from \"./rest/DefaultEntityRestCache.js\"\nimport { SleepDetector } from \"./utils/SleepDetector.js\"\nimport sysModelInfo from \"../entities/sys/ModelInfo.js\"\nimport tutanotaModelInfo from \"../entities/tutanota/ModelInfo.js\"\nimport { resolveTypeReference } from \"../common/EntityFunctions.js\"\nimport { PhishingMarkerWebsocketData, PhishingMarkerWebsocketDataTypeRef, ReportedMailFieldMarker } from \"../entities/tutanota/TypeRefs\"\nimport { UserFacade } from \"./facades/UserFacade\"\nimport { ExposedProgressTracker } from \"../main/ProgressTracker.js\"\n\nassertWorkerOrNode()\n\nexport const enum EventBusState {\n\tAutomatic = \"automatic\",\n\t// automatic reconnection is enabled\n\tSuspended = \"suspended\",\n\t// automatic reconnection is suspended but can be enabled again\n\tTerminated = \"terminated\", // automatic reconnection is disabled and websocket is closed but can be opened again by calling connect explicit\n}\n\n// EntityEventBatches expire after 45 days. keep a time diff security of one day.\nexport const ENTITY_EVENT_BATCH_EXPIRE_MS = 44 * 24 * 60 * 60 * 1000\nconst RETRY_AFTER_SERVICE_UNAVAILABLE_ERROR_MS = 30000\nconst NORMAL_SHUTDOWN_CLOSE_CODE = 1\n/**\n * Reconnection interval bounds. When we reconnect we pick a random number of seconds in a range to prevent that all the clients connect at the same time which\n * would put unnecessary load on the server.\n * The range depends on the number of attempts and the server response.\n * */\nconst RECONNECT_INTERVAL = Object.freeze({\n\tSMALL: [5, 10],\n\tMEDIUM: [20, 40],\n\tLARGE: [60, 120],\n} as const)\n// we store the last 1000 event ids per group, so we know if an event was already processed.\n// it is not sufficient to check the last event id because a smaller event id may arrive later\n// than a bigger one if the requests are processed in parallel on the server\nconst MAX_EVENT_IDS_QUEUE_LENGTH = 1000\n\n/** Known types of messages that can be received over websocket. */\nconst enum MessageType {\n\tEntityUpdate = \"entityUpdate\",\n\tUnreadCounterUpdate = \"unreadCounterUpdate\",\n\tPhishingMarkers = \"phishingMarkers\",\n\tLeaderStatus = \"leaderStatus\",\n}\n\nexport const enum ConnectMode {\n\tInitial,\n\tReconnect,\n}\n\nexport interface EventBusListener {\n\tonWebsocketStateChanged(state: WsConnectionState): unknown\n\n\tonCounterChanged(counter: WebsocketCounterData): unknown\n\n\tonLeaderStatusChanged(leaderStatus: WebsocketLeaderStatus): unknown\n\n\tonEntityEventsReceived(events: EntityUpdate[], batchId: Id, groupId: Id): Promise<void>\n\n\t/**\n\t * @param markers only phishing (not spam) markers will be sent as event bus updates\n\t */\n\tonPhishingMarkersReceived(markers: ReportedMailFieldMarker[]): unknown\n\n\tonError(tutanotaError: Error): void\n}\n\nexport class EventBusClient {\n\tprivate state: EventBusState\n\tprivate socket: WebSocket | null\n\tprivate immediateReconnect: boolean = false // if true tries to reconnect immediately after the websocket is closed\n\n\t/**\n\t * Map from group id to last event ids (max. _MAX_EVENT_IDS_QUEUE_LENGTH). We keep them to avoid processing the same event twice if\n\t * it comes out of order from the server) and for requesting missed entity events on reconnect.\n\t *\n\t * We do not have to update these event ids if the groups of the user change because we always take the current users groups from the\n\t * LoginFacade.\n\t */\n\tprivate lastEntityEventIds: Map<Id, Array<Id>>\n\n\t/**\n\t * Last batch which was actually added to the queue. We need it to find out when the group is processed\n\t */\n\tprivate lastAddedBatchForGroup: Map<Id, Id>\n\n\tprivate lastAntiphishingMarkersId: Id | null = null\n\n\t/** Queue to process all events. */\n\tprivate readonly eventQueue: EventQueue\n\n\t/** Queue that handles incoming websocket messages only. Caches them until we process downloaded ones and then adds them to eventQueue. */\n\tprivate readonly entityUpdateMessageQueue: EventQueue\n\tprivate reconnectTimer: TimeoutID | null\n\tprivate connectTimer: TimeoutID | null\n\n\t/**\n\t * Represents a currently retried executing due to a ServiceUnavailableError\n\t */\n\tprivate serviceUnavailableRetry: Promise<void> | null = null\n\tprivate failedConnectionAttempts: number = 0\n\n\tconstructor(\n\t\tprivate readonly listener: EventBusListener,\n\t\tprivate readonly cache: EntityRestCache,\n\t\tprivate readonly userFacade: UserFacade,\n\t\tprivate readonly entity: EntityClient,\n\t\tprivate readonly instanceMapper: InstanceMapper,\n\t\tprivate readonly socketFactory: (path: string) => WebSocket,\n\t\tprivate readonly sleepDetector: SleepDetector,\n\t\tprivate readonly progressTracker: ExposedProgressTracker,\n\t) {\n\t\t// We are not connected by default and will not try to unless connect() is called\n\t\tthis.state = EventBusState.Terminated\n\t\tthis.lastEntityEventIds = new Map()\n\t\tthis.lastAddedBatchForGroup = new Map()\n\t\tthis.socket = null\n\t\tthis.reconnectTimer = null\n\t\tthis.connectTimer = null\n\t\tthis.eventQueue = new EventQueue(\"ws_opt\", true, (modification) => this.eventQueueCallback(modification))\n\t\tthis.entityUpdateMessageQueue = new EventQueue(\"ws_msg\", false, (batch) => this.entityUpdateMessageQueueCallback(batch))\n\t\tthis.reset()\n\t}\n\n\tprivate reset() {\n\t\tthis.immediateReconnect = false\n\n\t\tthis.lastEntityEventIds.clear()\n\n\t\tthis.lastAddedBatchForGroup.clear()\n\n\t\tthis.eventQueue.pause()\n\n\t\tthis.eventQueue.clear()\n\n\t\tthis.serviceUnavailableRetry = null\n\t}\n\n\t/**\n\t * Opens a WebSocket connection to receive server events.\n\t * @param connectMode\n\t */\n\tconnect(connectMode: ConnectMode) {\n\t\tconsole.log(\"ws connect reconnect:\", connectMode === ConnectMode.Reconnect, \"state:\", this.state)\n\t\t// make sure a retry will be cancelled by setting _serviceUnavailableRetry to null\n\t\tthis.serviceUnavailableRetry = null\n\n\t\tthis.listener.onWebsocketStateChanged(WsConnectionState.connecting)\n\n\t\tthis.state = EventBusState.Automatic\n\t\tthis.connectTimer = null\n\n\t\tconst authHeaders = this.userFacade.createAuthHeaders()\n\n\t\t// Native query building is not supported in old browser, mithril is not available in the worker\n\t\tconst authQuery =\n\t\t\t\"modelVersions=\" +\n\t\t\tsysModelInfo.version +\n\t\t\t\".\" +\n\t\t\ttutanotaModelInfo.version +\n\t\t\t\"&clientVersion=\" +\n\t\t\tenv.versionNumber +\n\t\t\t\"&userId=\" +\n\t\t\tthis.userFacade.getLoggedInUser()._id +\n\t\t\t\"&accessToken=\" +\n\t\t\tauthHeaders.accessToken +\n\t\t\t(this.lastAntiphishingMarkersId ? \"&lastPhishingMarkersId=\" + this.lastAntiphishingMarkersId : \"\")\n\t\tconst path = \"/event?\" + authQuery\n\n\t\tthis.unsubscribeFromOldWebsocket()\n\n\t\tthis.socket = this.socketFactory(path)\n\t\tthis.socket.onopen = () => this.onOpen(connectMode)\n\t\tthis.socket.onclose = (event: CloseEvent) => this.onClose(event)\n\t\tthis.socket.onerror = (error: any) => this.onError(error)\n\t\tthis.socket.onmessage = (message: MessageEvent<string>) => this.onMessage(message)\n\n\t\tthis.sleepDetector.start(() => {\n\t\t\tconsole.log(\"ws sleep detected, reconnecting...\")\n\t\t\tthis.tryReconnect(true, true)\n\t\t})\n\t}\n\n\t/**\n\t * Sends a close event to the server and finally closes the connection.\n\t * The state of this event bus client is reset and the client is terminated (does not automatically reconnect) except reconnect == true\n\t */\n\tasync close(closeOption: CloseEventBusOption): Promise<void> {\n\t\tconsole.log(\"ws close closeOption: \", closeOption, \"state:\", this.state)\n\n\t\tswitch (closeOption) {\n\t\t\tcase CloseEventBusOption.Terminate:\n\t\t\t\tthis.terminate()\n\n\t\t\t\tbreak\n\n\t\t\tcase CloseEventBusOption.Pause:\n\t\t\t\tthis.state = EventBusState.Suspended\n\n\t\t\t\tthis.listener.onWebsocketStateChanged(WsConnectionState.connecting)\n\n\t\t\t\tbreak\n\n\t\t\tcase CloseEventBusOption.Reconnect:\n\t\t\t\tthis.listener.onWebsocketStateChanged(WsConnectionState.connecting)\n\n\t\t\t\tbreak\n\t\t}\n\n\t\tthis.socket?.close()\n\t}\n\n\tasync tryReconnect(closeIfOpen: boolean, enableAutomaticState: boolean, delay: number | null = null): Promise<void> {\n\t\tconsole.log(\"ws tryReconnect closeIfOpen:\", closeIfOpen, \"enableAutomaticState:\", enableAutomaticState, \"delay:\", delay)\n\n\t\tif (this.reconnectTimer) {\n\t\t\t// prevent reconnect race-condition\n\t\t\tclearTimeout(this.reconnectTimer)\n\t\t\tthis.reconnectTimer = null\n\t\t}\n\n\t\tif (!delay) {\n\t\t\tthis.reconnect(closeIfOpen, enableAutomaticState)\n\t\t} else {\n\t\t\tthis.reconnectTimer = setTimeout(() => this.reconnect(closeIfOpen, enableAutomaticState), delay)\n\t\t}\n\t}\n\n\t// Returning promise for tests\n\tprivate onOpen(connectMode: ConnectMode): Promise<void> {\n\t\tthis.failedConnectionAttempts = 0\n\t\tconsole.log(\"ws open state:\", this.state)\n\n\t\tconst p = this.initEntityEvents(connectMode)\n\n\t\tthis.listener.onWebsocketStateChanged(WsConnectionState.connected)\n\n\t\treturn p\n\t}\n\n\tprivate onError(error: any) {\n\t\tconsole.log(\"ws error:\", error, JSON.stringify(error), \"state:\", this.state)\n\t}\n\n\tprivate async onMessage(message: MessageEvent<string>): Promise<void> {\n\t\tconst [type, value] = message.data.split(\";\")\n\n\t\tswitch (type) {\n\t\t\tcase MessageType.EntityUpdate: {\n\t\t\t\tconst { eventBatchId, eventBatchOwner, eventBatch }: WebsocketEntityData = await this.instanceMapper.decryptAndMapToInstance(\n\t\t\t\t\tawait resolveTypeReference(WebsocketEntityDataTypeRef),\n\t\t\t\t\tJSON.parse(value),\n\t\t\t\t\tnull,\n\t\t\t\t)\n\t\t\t\tconst filteredEntityUpdates = await this.removeUnknownTypes(eventBatch)\n\t\t\t\tthis.entityUpdateMessageQueue.add(eventBatchId, eventBatchOwner, filteredEntityUpdates)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcase MessageType.UnreadCounterUpdate: {\n\t\t\t\tconst counterData: WebsocketCounterData = await this.instanceMapper.decryptAndMapToInstance(\n\t\t\t\t\tawait resolveTypeReference(WebsocketCounterDataTypeRef),\n\t\t\t\t\tJSON.parse(value),\n\t\t\t\t\tnull,\n\t\t\t\t)\n\t\t\t\tthis.listener.onCounterChanged(counterData)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcase MessageType.PhishingMarkers: {\n\t\t\t\tconst data: PhishingMarkerWebsocketData = await this.instanceMapper.decryptAndMapToInstance(\n\t\t\t\t\tawait resolveTypeReference(PhishingMarkerWebsocketDataTypeRef),\n\t\t\t\t\tJSON.parse(value),\n\t\t\t\t\tnull,\n\t\t\t\t)\n\t\t\t\tthis.lastAntiphishingMarkersId = data.lastId\n\t\t\t\tthis.listener.onPhishingMarkersReceived(data.markers)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcase MessageType.LeaderStatus: {\n\t\t\t\tconst data: WebsocketLeaderStatus = await this.instanceMapper.decryptAndMapToInstance(\n\t\t\t\t\tawait resolveTypeReference(WebsocketLeaderStatusTypeRef),\n\t\t\t\t\tJSON.parse(value),\n\t\t\t\t\tnull,\n\t\t\t\t)\n\t\t\t\tawait this.userFacade.setLeaderStatus(data)\n\t\t\t\tawait this.listener.onLeaderStatusChanged(data)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdefault:\n\t\t\t\tconsole.log(\"ws message with unknown type\", type)\n\t\t\t\tbreak\n\t\t}\n\t}\n\n\t/**\n\t * Filters out specific types from @param entityUpdates that the client does not actually know about\n\t * (that are not in tutanotaTypes), and which should therefore not be processed.\n\t */\n\tprivate async removeUnknownTypes(eventBatch: EntityUpdate[]): Promise<EntityUpdate[]> {\n\t\treturn promiseFilter(eventBatch, async (entityUpdate) => {\n\t\t\tconst typeRef = new TypeRef(entityUpdate.application, entityUpdate.type)\n\t\t\ttry {\n\t\t\t\tawait resolveTypeReference(typeRef)\n\t\t\t\treturn true\n\t\t\t} catch (_error) {\n\t\t\t\tconsole.warn(\"ignoring entityEventUpdate for unknown type with typeId\", getTypeId(typeRef))\n\t\t\t\treturn false\n\t\t\t}\n\t\t})\n\t}\n\n\tprivate onClose(event: CloseEvent) {\n\t\tthis.failedConnectionAttempts++\n\t\tconsole.log(\"ws close event:\", event, \"state:\", this.state)\n\n\t\tthis.userFacade.setLeaderStatus(\n\t\t\tcreateWebsocketLeaderStatus({\n\t\t\t\tleaderStatus: false,\n\t\t\t}),\n\t\t)\n\n\t\tthis.sleepDetector.stop()\n\n\t\t// Avoid running into penalties when trying to authenticate with an invalid session\n\t\t// NotAuthenticatedException 401, AccessDeactivatedException 470, AccessBlocked 472\n\t\t// do not catch session expired here because websocket will be reused when we authenticate again\n\t\tconst serverCode = event.code - 4000\n\n\t\tif ([NotAuthorizedError.CODE, AccessDeactivatedError.CODE, AccessBlockedError.CODE].includes(serverCode)) {\n\t\t\tthis.terminate()\n\t\t\tthis.listener.onError(handleRestError(serverCode, \"web socket error\", null, null))\n\t\t} else if (serverCode === SessionExpiredError.CODE) {\n\t\t\t// session is expired. do not try to reconnect until the user creates a new session\n\t\t\tthis.state = EventBusState.Suspended\n\t\t\tthis.listener.onWebsocketStateChanged(WsConnectionState.connecting)\n\t\t} else if (this.state === EventBusState.Automatic && this.userFacade.isFullyLoggedIn()) {\n\t\t\tthis.listener.onWebsocketStateChanged(WsConnectionState.connecting)\n\n\t\t\tif (this.immediateReconnect) {\n\t\t\t\tthis.immediateReconnect = false\n\t\t\t\tthis.tryReconnect(false, false)\n\t\t\t} else {\n\t\t\t\tlet reconnectionInterval: readonly [number, number]\n\n\t\t\t\tif (serverCode === NORMAL_SHUTDOWN_CLOSE_CODE) {\n\t\t\t\t\treconnectionInterval = RECONNECT_INTERVAL.LARGE\n\t\t\t\t} else if (this.failedConnectionAttempts === 1) {\n\t\t\t\t\treconnectionInterval = RECONNECT_INTERVAL.SMALL\n\t\t\t\t} else if (this.failedConnectionAttempts === 2) {\n\t\t\t\t\treconnectionInterval = RECONNECT_INTERVAL.MEDIUM\n\t\t\t\t} else {\n\t\t\t\t\treconnectionInterval = RECONNECT_INTERVAL.LARGE\n\t\t\t\t}\n\n\t\t\t\tthis.tryReconnect(false, false, SECOND_MS * randomIntFromInterval(reconnectionInterval[0], reconnectionInterval[1]))\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate async initEntityEvents(connectMode: ConnectMode): Promise<void> {\n\t\t// pause processing entity update message while initializing event queue\n\t\tthis.entityUpdateMessageQueue.pause()\n\n\t\t// pause event queue and add all missed entity events first\n\t\tthis.eventQueue.pause()\n\n\t\tconst existingConnection = connectMode == ConnectMode.Reconnect && this.lastEntityEventIds.size > 0\n\t\tconst p = existingConnection ? this.loadMissedEntityEvents(this.eventQueue) : this.initOnNewConnection()\n\n\t\treturn p\n\t\t\t.then(() => {\n\t\t\t\tthis.entityUpdateMessageQueue.resume()\n\t\t\t\tthis.eventQueue.resume()\n\t\t\t})\n\t\t\t.catch(\n\t\t\t\tofClass(ConnectionError, (e) => {\n\t\t\t\t\tconsole.log(\"ws not connected in connect(), close websocket\", e)\n\t\t\t\t\tthis.close(CloseEventBusOption.Reconnect)\n\t\t\t\t}),\n\t\t\t)\n\t\t\t.catch(\n\t\t\t\tofClass(CancelledError, () => {\n\t\t\t\t\t// the processing was aborted due to a reconnect. do not reset any attributes because they might already be in use since reconnection\n\t\t\t\t\tconsole.log(\"ws cancelled retry process entity events after reconnect\")\n\t\t\t\t}),\n\t\t\t)\n\t\t\t.catch(\n\t\t\t\tofClass(ServiceUnavailableError, async (e) => {\n\t\t\t\t\t// a ServiceUnavailableError is a temporary error and we have to retry to avoid data inconsistencies\n\t\t\t\t\t// some EventBatches/missed events are processed already now\n\t\t\t\t\t// for an existing connection we just keep the current state and continue loading missed events for the other groups\n\t\t\t\t\t// for a new connection we reset the last entity event ids because otherwise this would not be completed in the next try\n\t\t\t\t\tif (!existingConnection) {\n\t\t\t\t\t\tthis.lastEntityEventIds.clear()\n\t\t\t\t\t}\n\n\t\t\t\t\tconsole.log(\"ws retry init entity events in \", RETRY_AFTER_SERVICE_UNAVAILABLE_ERROR_MS, e)\n\t\t\t\t\tlet promise = delay(RETRY_AFTER_SERVICE_UNAVAILABLE_ERROR_MS).then(() => {\n\t\t\t\t\t\t// if we have a websocket reconnect we have to stop retrying\n\t\t\t\t\t\tif (this.serviceUnavailableRetry === promise) {\n\t\t\t\t\t\t\tconsole.log(\"ws retry initializing entity events\")\n\t\t\t\t\t\t\treturn this.initEntityEvents(connectMode)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tconsole.log(\"ws cancel initializing entity events\")\n\t\t\t\t\t\t}\n\t\t\t\t\t})\n\t\t\t\t\tthis.serviceUnavailableRetry = promise\n\t\t\t\t\treturn promise\n\t\t\t\t}),\n\t\t\t)\n\t\t\t.catch(\n\t\t\t\tofClass(OutOfSyncError, async (e) => {\n\t\t\t\t\t// we did not check for updates for too long, so some missed EntityEventBatches can not be loaded any more\n\t\t\t\t\t// purge cache if out of sync\n\t\t\t\t\tawait this.cache.purgeStorage()\n\t\t\t\t\t// We want users to re-login. By the time we get here they probably already have loaded some entities which we cannot update\n\t\t\t\t\tthrow e\n\t\t\t\t}),\n\t\t\t)\n\t\t\t.catch((e) => {\n\t\t\t\tthis.entityUpdateMessageQueue.resume()\n\n\t\t\t\tthis.eventQueue.resume()\n\n\t\t\t\tthis.listener.onError(e)\n\t\t\t})\n\t}\n\n\tprivate async initOnNewConnection() {\n\t\tconst { lastIds, someIdsWereCached } = await this.retrieveLastEntityEventIds()\n\t\t// First, we record lastEntityEventIds. We need this to know what we need to re-fetch.\n\t\t// This is not the same as the cache because we might have already downloaded them but cache might not have processed them yet.\n\t\t// Important: do it in one step so that we don't have partial IDs in the map in case an error occurs.\n\t\tthis.lastEntityEventIds = lastIds\n\n\t\t// Second, we need to initialize the cache too.\n\t\tif (someIdsWereCached) {\n\t\t\t// If some of the last IDs were retrieved from the cache then we want to load from that point to bring cache up-to-date. This is mostly important for\n\t\t\t// persistent cache.\n\t\t\tawait this.loadMissedEntityEvents(this.eventQueue)\n\t\t} else {\n\t\t\t// If the cache is clean then this is a clean cache (either ephemeral after first connect or persistent with empty DB).\n\t\t\t// We need to record the time even if we don't process anything to later know if we are out of sync or not.\n\t\t\tawait this.cache.recordSyncTime()\n\t\t}\n\t}\n\n\t/**\n\t * Gets the latest event batch ids for each of the users groups or min id if there is no event batch yet.\n\t * This is needed to know from where to start loading missed events when we connect.\n\t */\n\tprivate async retrieveLastEntityEventIds(): Promise<{ lastIds: Map<Id, Array<Id>>; someIdsWereCached: boolean }> {\n\t\t// set all last event ids in one step to avoid that we have just set them for a few groups when a ServiceUnavailableError occurs\n\t\tconst lastIds: Map<Id, Array<Id>> = new Map()\n\t\tlet someIdsWereCached = false\n\t\tfor (const groupId of this.eventGroups()) {\n\t\t\tconst cachedBatchId = await this.cache.getLastEntityEventBatchForGroup(groupId)\n\t\t\tif (cachedBatchId != null) {\n\t\t\t\tlastIds.set(groupId, [cachedBatchId])\n\t\t\t\tsomeIdsWereCached = true\n\t\t\t} else {\n\t\t\t\tconst batches = await this.entity.loadRange(EntityEventBatchTypeRef, groupId, GENERATED_MAX_ID, 1, true)\n\t\t\t\tconst batchId = batches.length === 1 ? getElementId(batches[0]) : GENERATED_MIN_ID\n\t\t\t\tlastIds.set(groupId, [batchId])\n\t\t\t\t// In case we don't receive any events for the group this time we want to still download from this point next time.\n\t\t\t\tawait this.cache.setLastEntityEventBatchForGroup(groupId, batchId)\n\t\t\t}\n\t\t}\n\n\t\treturn { lastIds, someIdsWereCached }\n\t}\n\n\t/** Load event batches since the last time we were connected to bring cache and other things up-to-date.\n\t * @param eventQueue is passed in for testing\n\t * @VisibleForTesting\n\t * */\n\tasync loadMissedEntityEvents(eventQueue: EventQueue): Promise<void> {\n\t\tif (!this.userFacade.isFullyLoggedIn()) {\n\t\t\treturn\n\t\t}\n\n\t\tawait this.checkOutOfSync()\n\n\t\tlet eventBatches: EntityEventBatch[] = []\n\t\tfor (let groupId of this.eventGroups()) {\n\t\t\tconst eventBatchForGroup = await this.loadEntityEventsForGroup(groupId)\n\t\t\teventBatches = eventBatches.concat(eventBatchForGroup)\n\t\t}\n\n\t\tconst timeSortedEventBatches = eventBatches.sort((a, b) => compareOldestFirst(getElementId(a), getElementId(b)))\n\t\t// Count all batches that will actually be processed so that the progress is correct\n\t\tlet totalExpectedBatches = 0\n\t\tfor (const batch of timeSortedEventBatches) {\n\t\t\tconst filteredEntityUpdates = await this.removeUnknownTypes(batch.events)\n\t\t\tconst batchWasAddedToQueue = this.addBatch(getElementId(batch), getListId(batch), filteredEntityUpdates, eventQueue)\n\t\t\tif (batchWasAddedToQueue) {\n\t\t\t\ttotalExpectedBatches++\n\t\t\t}\n\t\t}\n\n\t\t// We only have the correct amount of total work after adding all entity event batches.\n\t\t// The progress for processed batches is tracked inside the event queue.\n\t\tconst progressMonitor = new ProgressMonitorDelegate(this.progressTracker, totalExpectedBatches + 1)\n\t\tconsole.log(\"ws\", `progress monitor expects ${totalExpectedBatches} events`)\n\t\tawait progressMonitor.workDone(1) // show progress right away\n\t\teventQueue.setProgressMonitor(progressMonitor)\n\n\t\t// We've loaded all the batches, we've added them to the queue, we can let the cache remember sync point for us to detect out of sync now.\n\t\t// It is possible that we will record the time before the batch will be processed but the risk is low.\n\t\tawait this.cache.recordSyncTime()\n\t}\n\n\tprivate async loadEntityEventsForGroup(groupId: Id): Promise<EntityEventBatch[]> {\n\t\ttry {\n\t\t\treturn await this.entity.loadAll(EntityEventBatchTypeRef, groupId, this.getLastEventBatchIdOrMinIdForGroup(groupId))\n\t\t} catch (e) {\n\t\t\tif (e instanceof NotAuthorizedError) {\n\t\t\t\tconsole.log(\"ws could not download entity updates, lost permission\")\n\t\t\t\treturn []\n\t\t\t} else {\n\t\t\t\tthrow e\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate async checkOutOfSync() {\n\t\t// We try to detect whether event batches have already expired.\n\t\t// If this happened we don't need to download anything, we need to purge the cache and start all over.\n\t\tif (await this.cache.isOutOfSync()) {\n\t\t\t// We handle it where we initialize the connection and purge the cache there.\n\t\t\tthrow new OutOfSyncError(\"some missed EntityEventBatches cannot be loaded any more\")\n\t\t}\n\t}\n\n\tprivate async eventQueueCallback(modification: QueuedBatch): Promise<void> {\n\t\ttry {\n\t\t\tawait this.processEventBatch(modification)\n\t\t} catch (e) {\n\t\t\tconsole.log(\"ws error while processing event batches\", e)\n\t\t\tthis.listener.onError(e)\n\t\t\tthrow e\n\t\t}\n\t}\n\n\tprivate async entityUpdateMessageQueueCallback(batch: QueuedBatch): Promise<void> {\n\t\tthis.addBatch(batch.batchId, batch.groupId, batch.events, this.eventQueue)\n\t\tthis.eventQueue.resume()\n\t}\n\n\tprivate unsubscribeFromOldWebsocket() {\n\t\tif (this.socket) {\n\t\t\t// Remove listeners. We don't want old socket to mess our state\n\t\t\tthis.socket.onopen = this.socket.onclose = this.socket.onerror = this.socket.onmessage = identity\n\t\t}\n\t}\n\n\tprivate async terminate(): Promise<void> {\n\t\tthis.state = EventBusState.Terminated\n\n\t\tthis.reset()\n\n\t\tthis.listener.onWebsocketStateChanged(WsConnectionState.terminated)\n\t}\n\n\t/**\n\t * Tries to reconnect the websocket if it is not connected.\n\t */\n\tprivate reconnect(closeIfOpen: boolean, enableAutomaticState: boolean) {\n\t\tconsole.log(\n\t\t\t\"ws reconnect socket.readyState: (CONNECTING=0, OPEN=1, CLOSING=2, CLOSED=3): \" + (this.socket ? this.socket.readyState : \"null\"),\n\t\t\t\"state:\",\n\t\t\tthis.state,\n\t\t\t\"closeIfOpen:\",\n\t\t\tcloseIfOpen,\n\t\t\t\"enableAutomaticState:\",\n\t\t\tenableAutomaticState,\n\t\t)\n\n\t\tif (this.state !== EventBusState.Terminated && enableAutomaticState) {\n\t\t\tthis.state = EventBusState.Automatic\n\t\t}\n\n\t\tif (closeIfOpen && this.socket && this.socket.readyState === WebSocket.OPEN) {\n\t\t\tthis.immediateReconnect = true\n\t\t\tthis.socket.close()\n\t\t} else if (\n\t\t\t(this.socket == null || this.socket.readyState === WebSocket.CLOSED || this.socket.readyState === WebSocket.CLOSING) &&\n\t\t\tthis.state !== EventBusState.Terminated &&\n\t\t\tthis.userFacade.isFullyLoggedIn()\n\t\t) {\n\t\t\t// Don't try to connect right away because connection may not be actually there\n\t\t\t// see #1165\n\t\t\tif (this.connectTimer) {\n\t\t\t\tclearTimeout(this.connectTimer)\n\t\t\t}\n\n\t\t\tthis.connectTimer = setTimeout(() => this.connect(ConnectMode.Reconnect), 100)\n\t\t}\n\t}\n\n\tprivate addBatch(batchId: Id, groupId: Id, events: ReadonlyArray<EntityUpdate>, eventQueue: EventQueue): boolean {\n\t\tconst lastForGroup = this.lastEntityEventIds.get(groupId) || []\n\t\t// find the position for inserting into last entity events (negative value is considered as not present in the array)\n\t\tconst index = binarySearch(lastForGroup, batchId, compareOldestFirst)\n\t\tlet wasAdded\n\n\t\tif (index < 0) {\n\t\t\tlastForGroup.splice(-index, 0, batchId)\n\t\t\t// only add the batch if it was not process before\n\t\t\twasAdded = eventQueue.add(batchId, groupId, events)\n\t\t} else {\n\t\t\twasAdded = false\n\t\t}\n\n\t\tif (lastForGroup.length > MAX_EVENT_IDS_QUEUE_LENGTH) {\n\t\t\tlastForGroup.shift()\n\t\t}\n\n\t\tthis.lastEntityEventIds.set(batchId, lastForGroup)\n\n\t\tif (wasAdded) {\n\t\t\tthis.lastAddedBatchForGroup.set(groupId, batchId)\n\t\t}\n\t\treturn wasAdded\n\t}\n\n\tprivate async processEventBatch(batch: QueuedBatch): Promise<void> {\n\t\ttry {\n\t\t\tif (this.isTerminated()) return\n\t\t\tconst filteredEvents = await this.cache.entityEventsReceived(batch)\n\t\t\tif (!this.isTerminated()) await this.listener.onEntityEventsReceived(filteredEvents, batch.batchId, batch.groupId)\n\t\t} catch (e) {\n\t\t\tif (e instanceof ServiceUnavailableError) {\n\t\t\t\t// a ServiceUnavailableError is a temporary error and we have to retry to avoid data inconsistencies\n\t\t\t\tconsole.log(\"ws retry processing event in 30s\", e)\n\t\t\t\tconst retryPromise = delay(RETRY_AFTER_SERVICE_UNAVAILABLE_ERROR_MS).then(() => {\n\t\t\t\t\t// if we have a websocket reconnect we have to stop retrying\n\t\t\t\t\tif (this.serviceUnavailableRetry === retryPromise) {\n\t\t\t\t\t\treturn this.processEventBatch(batch)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tthrow new CancelledError(\"stop retry processing after service unavailable due to reconnect\")\n\t\t\t\t\t}\n\t\t\t\t})\n\t\t\t\tthis.serviceUnavailableRetry = retryPromise\n\t\t\t\treturn retryPromise\n\t\t\t} else {\n\t\t\t\tconsole.log(\"EVENT\", \"error\", e)\n\t\t\t\tthrow e\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate getLastEventBatchIdOrMinIdForGroup(groupId: Id): Id {\n\t\tconst lastIds = this.lastEntityEventIds.get(groupId)\n\n\t\treturn lastIds && lastIds.length > 0 ? lastThrow(lastIds) : GENERATED_MIN_ID\n\t}\n\n\tprivate isTerminated() {\n\t\treturn this.state === EventBusState.Terminated\n\t}\n\n\tprivate eventGroups(): Id[] {\n\t\treturn this.userFacade\n\t\t\t.getLoggedInUser()\n\t\t\t.memberships.filter((membership) => membership.groupType !== GroupType.MailingList)\n\t\t\t.map((membership) => membership.group)\n\t\t\t.concat(this.userFacade.getLoggedInUser().userGroup.group)\n\t}\n}\n","// This is an unfortunate replacement for @sindresorhus/is that we need to\n// re-implement for performance purposes. In particular the is.observable()\n// check is expensive, and unnecessary for our purposes. The values returned\n// are compatible with @sindresorhus/is, however.\n\nconst typeofs = [\n  'string',\n  'number',\n  'bigint',\n  'symbol'\n];\n\nconst objectTypeNames = [\n  'Function',\n  'Generator',\n  'AsyncGenerator',\n  'GeneratorFunction',\n  'AsyncGeneratorFunction',\n  'AsyncFunction',\n  'Observable',\n  'Array',\n  'Buffer',\n  'Object',\n  'RegExp',\n  'Date',\n  'Error',\n  'Map',\n  'Set',\n  'WeakMap',\n  'WeakSet',\n  'ArrayBuffer',\n  'SharedArrayBuffer',\n  'DataView',\n  'Promise',\n  'URL',\n  'HTMLElement',\n  'Int8Array',\n  'Uint8Array',\n  'Uint8ClampedArray',\n  'Int16Array',\n  'Uint16Array',\n  'Int32Array',\n  'Uint32Array',\n  'Float32Array',\n  'Float64Array',\n  'BigInt64Array',\n  'BigUint64Array'\n];\n\n/**\n * @param {any} value\n * @returns {string}\n */\nfunction is (value) {\n  if (value === null) {\n    return 'null'\n  }\n  if (value === undefined) {\n    return 'undefined'\n  }\n  if (value === true || value === false) {\n    return 'boolean'\n  }\n  const typeOf = typeof value;\n  if (typeofs.includes(typeOf)) {\n    return typeOf\n  }\n  /* c8 ignore next 4 */\n  // not going to bother testing this, it's not going to be valid anyway\n  if (typeOf === 'function') {\n    return 'Function'\n  }\n  if (Array.isArray(value)) {\n    return 'Array'\n  }\n  if (isBuffer$1(value)) {\n    return 'Buffer'\n  }\n  const objectType = getObjectType(value);\n  if (objectType) {\n    return objectType\n  }\n  /* c8 ignore next */\n  return 'Object'\n}\n\n/**\n * @param {any} value\n * @returns {boolean}\n */\nfunction isBuffer$1 (value) {\n  return value && value.constructor && value.constructor.isBuffer && value.constructor.isBuffer.call(null, value)\n}\n\n/**\n * @param {any} value\n * @returns {string|undefined}\n */\nfunction getObjectType (value) {\n  const objectTypeName = Object.prototype.toString.call(value).slice(8, -1);\n  if (objectTypeNames.includes(objectTypeName)) {\n    return objectTypeName\n  }\n  /* c8 ignore next */\n  return undefined\n}\n\nclass Type {\n  /**\n   * @param {number} major\n   * @param {string} name\n   * @param {boolean} terminal\n   */\n  constructor (major, name, terminal) {\n    this.major = major;\n    this.majorEncoded = major << 5;\n    this.name = name;\n    this.terminal = terminal;\n  }\n\n  /* c8 ignore next 3 */\n  toString () {\n    return `Type[${this.major}].${this.name}`\n  }\n\n  /**\n   * @param {Type} typ\n   * @returns {number}\n   */\n  compare (typ) {\n    /* c8 ignore next 1 */\n    return this.major < typ.major ? -1 : this.major > typ.major ? 1 : 0\n  }\n}\n\n// convert to static fields when better supported\nType.uint = new Type(0, 'uint', true);\nType.negint = new Type(1, 'negint', true);\nType.bytes = new Type(2, 'bytes', true);\nType.string = new Type(3, 'string', true);\nType.array = new Type(4, 'array', false);\nType.map = new Type(5, 'map', false);\nType.tag = new Type(6, 'tag', false); // terminal?\nType.float = new Type(7, 'float', true);\nType.false = new Type(7, 'false', true);\nType.true = new Type(7, 'true', true);\nType.null = new Type(7, 'null', true);\nType.undefined = new Type(7, 'undefined', true);\nType.break = new Type(7, 'break', true);\n// Type.indefiniteLength = new Type(0, 'indefiniteLength', true)\n\nclass Token {\n  /**\n   * @param {Type} type\n   * @param {any} [value]\n   * @param {number} [encodedLength]\n   */\n  constructor (type, value, encodedLength) {\n    this.type = type;\n    this.value = value;\n    this.encodedLength = encodedLength;\n    /** @type {Uint8Array|undefined} */\n    this.encodedBytes = undefined;\n    /** @type {Uint8Array|undefined} */\n    this.byteValue = undefined;\n  }\n\n  /* c8 ignore next 3 */\n  toString () {\n    return `Token[${this.type}].${this.value}`\n  }\n}\n\n// Use Uint8Array directly in the browser, use Buffer in Node.js but don't\n// speak its name directly to avoid bundlers pulling in the `Buffer` polyfill\n\n// @ts-ignore\nconst useBuffer = globalThis.process &&\n  // @ts-ignore\n  !globalThis.process.browser &&\n  // @ts-ignore\n  globalThis.Buffer &&\n  // @ts-ignore\n  typeof globalThis.Buffer.isBuffer === 'function';\n\nconst textDecoder = new TextDecoder();\nconst textEncoder = new TextEncoder();\n\n/**\n * @param {Uint8Array} buf\n * @returns {boolean}\n */\nfunction isBuffer (buf) {\n  // @ts-ignore\n  return useBuffer && globalThis.Buffer.isBuffer(buf)\n}\n\n/**\n * @param {Uint8Array|number[]} buf\n * @returns {Uint8Array}\n */\nfunction asU8A (buf) {\n  /* c8 ignore next */\n  if (!(buf instanceof Uint8Array)) {\n    return Uint8Array.from(buf)\n  }\n  return isBuffer(buf) ? new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength) : buf\n}\n\nconst toString = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return end - start > 64\n        ? // eslint-disable-line operator-linebreak\n      // @ts-ignore\n        globalThis.Buffer.from(bytes.subarray(start, end)).toString('utf8')\n        : utf8Slice(bytes, start, end)\n    }\n  /* c8 ignore next 11 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return end - start > 64\n        ? textDecoder.decode(bytes.subarray(start, end))\n        : utf8Slice(bytes, start, end)\n    };\n\nconst fromString = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {string} string\n     */\n    (string) => {\n      return string.length > 64\n        ? // eslint-disable-line operator-linebreak\n      // @ts-ignore\n        globalThis.Buffer.from(string)\n        : utf8ToBytes(string)\n    }\n  /* c8 ignore next 7 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {string} string\n     */\n    (string) => {\n      return string.length > 64 ? textEncoder.encode(string) : utf8ToBytes(string)\n    };\n\n/**\n * Buffer variant not fast enough for what we need\n * @param {number[]} arr\n * @returns {Uint8Array}\n */\nconst fromArray = (arr) => {\n  return Uint8Array.from(arr)\n};\n\nconst slice = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      if (isBuffer(bytes)) {\n        return new Uint8Array(bytes.subarray(start, end))\n      }\n      return bytes.slice(start, end)\n    }\n  /* c8 ignore next 9 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return bytes.slice(start, end)\n    };\n\nconst concat = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array[]} chunks\n     * @param {number} length\n     * @returns {Uint8Array}\n     */\n    (chunks, length) => {\n      // might get a stray plain Array here\n      /* c8 ignore next 1 */\n      chunks = chunks.map((c) => c instanceof Uint8Array\n        ? c\n        // this case is occasionally missed during test runs so becomes coverage-flaky\n        /* c8 ignore next 4 */\n        : // eslint-disable-line operator-linebreak\n        // @ts-ignore\n        globalThis.Buffer.from(c));\n      // @ts-ignore\n      return asU8A(globalThis.Buffer.concat(chunks, length))\n    }\n  /* c8 ignore next 19 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array[]} chunks\n     * @param {number} length\n     * @returns {Uint8Array}\n     */\n    (chunks, length) => {\n      const out = new Uint8Array(length);\n      let off = 0;\n      for (let b of chunks) {\n        if (off + b.length > out.length) {\n          // final chunk that's bigger than we need\n          b = b.subarray(0, out.length - off);\n        }\n        out.set(b, off);\n        off += b.length;\n      }\n      return out\n    };\n\nconst alloc = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {number} size\n     * @returns {Uint8Array}\n     */\n    (size) => {\n      // we always write over the contents we expose so this should be safe\n      // @ts-ignore\n      return globalThis.Buffer.allocUnsafe(size)\n    }\n  /* c8 ignore next 8 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {number} size\n     * @returns {Uint8Array}\n     */\n    (size) => {\n      return new Uint8Array(size)\n    };\n\n/**\n * @param {Uint8Array} b1\n * @param {Uint8Array} b2\n * @returns {number}\n */\nfunction compare (b1, b2) {\n  /* c8 ignore next 5 */\n  if (isBuffer(b1) && isBuffer(b2)) {\n    // probably not possible to get here in the current API\n    // @ts-ignore Buffer\n    return b1.compare(b2)\n  }\n  for (let i = 0; i < b1.length; i++) {\n    if (b1[i] === b2[i]) {\n      continue\n    }\n    return b1[i] < b2[i] ? -1 : 1\n  } /* c8 ignore next 3 */\n  return 0\n}\n\n// The below code is taken from https://github.com/google/closure-library/blob/8598d87242af59aac233270742c8984e2b2bdbe0/closure/goog/crypt/crypt.js#L117-L143\n// Licensed Apache-2.0.\n\n/**\n * @param {string} str\n * @returns {number[]}\n */\nfunction utf8ToBytes (str) {\n  const out = [];\n  let p = 0;\n  for (let i = 0; i < str.length; i++) {\n    let c = str.charCodeAt(i);\n    if (c < 128) {\n      out[p++] = c;\n    } else if (c < 2048) {\n      out[p++] = (c >> 6) | 192;\n      out[p++] = (c & 63) | 128;\n    } else if (\n      ((c & 0xFC00) === 0xD800) && (i + 1) < str.length &&\n      ((str.charCodeAt(i + 1) & 0xFC00) === 0xDC00)) {\n      // Surrogate Pair\n      c = 0x10000 + ((c & 0x03FF) << 10) + (str.charCodeAt(++i) & 0x03FF);\n      out[p++] = (c >> 18) | 240;\n      out[p++] = ((c >> 12) & 63) | 128;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    } else {\n      out[p++] = (c >> 12) | 224;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    }\n  }\n  return out\n}\n\n// The below code is mostly taken from https://github.com/feross/buffer\n// Licensed MIT. Copyright (c) Feross Aboukhadijeh\n\n/**\n * @param {Uint8Array} buf\n * @param {number} offset\n * @param {number} end\n * @returns {string}\n */\nfunction utf8Slice (buf, offset, end) {\n  const res = [];\n\n  while (offset < end) {\n    const firstByte = buf[offset];\n    let codePoint = null;\n    let bytesPerSequence = (firstByte > 0xef) ? 4 : (firstByte > 0xdf) ? 3 : (firstByte > 0xbf) ? 2 : 1;\n\n    if (offset + bytesPerSequence <= end) {\n      let secondByte, thirdByte, fourthByte, tempCodePoint;\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte;\n          }\n          break\n        case 2:\n          secondByte = buf[offset + 1];\n          if ((secondByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1f) << 0x6 | (secondByte & 0x3f);\n            if (tempCodePoint > 0x7f) {\n              codePoint = tempCodePoint;\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[offset + 1];\n          thirdByte = buf[offset + 2];\n          if ((secondByte & 0xc0) === 0x80 && (thirdByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0xf) << 0xc | (secondByte & 0x3f) << 0x6 | (thirdByte & 0x3f);\n            /* c8 ignore next 3 */\n            if (tempCodePoint > 0x7ff && (tempCodePoint < 0xd800 || tempCodePoint > 0xdfff)) {\n              codePoint = tempCodePoint;\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[offset + 1];\n          thirdByte = buf[offset + 2];\n          fourthByte = buf[offset + 3];\n          if ((secondByte & 0xc0) === 0x80 && (thirdByte & 0xc0) === 0x80 && (fourthByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0xf) << 0x12 | (secondByte & 0x3f) << 0xc | (thirdByte & 0x3f) << 0x6 | (fourthByte & 0x3f);\n            if (tempCodePoint > 0xffff && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint;\n            }\n          }\n      }\n    }\n\n    /* c8 ignore next 5 */\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xfffd;\n      bytesPerSequence = 1;\n    } else if (codePoint > 0xffff) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000;\n      res.push(codePoint >>> 10 & 0x3ff | 0xd800);\n      codePoint = 0xdc00 | codePoint & 0x3ff;\n    }\n\n    res.push(codePoint);\n    offset += bytesPerSequence;\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nconst MAX_ARGUMENTS_LENGTH = 0x1000;\n\n/**\n * @param {number[]} codePoints\n * @returns {string}\n */\nfunction decodeCodePointsArray (codePoints) {\n  const len = codePoints.length;\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n  /* c8 ignore next 10 */\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  let res = '';\n  let i = 0;\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    );\n  }\n  return res\n}\n\n/**\n * Bl is a list of byte chunks, similar to https://github.com/rvagg/bl but for\n * writing rather than reading.\n * A Bl object accepts set() operations for individual bytes and copyTo() for\n * inserting byte arrays. These write operations don't automatically increment\n * the internal cursor so its \"length\" won't be changed. Instead, increment()\n * must be called to extend its length to cover the inserted data.\n * The toBytes() call will convert all internal memory to a single Uint8Array of\n * the correct length, truncating any data that is stored but hasn't been\n * included by an increment().\n * get() can retrieve a single byte.\n * All operations (except toBytes()) take an \"offset\" argument that will perform\n * the write at the offset _from the current cursor_. For most operations this\n * will be `0` to write at the current cursor position but it can be ahead of\n * the current cursor. Negative offsets probably work but are untested.\n */\n\n\n// the ts-ignores in this file are almost all for the `Uint8Array|number[]` duality that exists\n// for perf reasons. Consider better approaches to this or removing it entirely, it is quite\n// risky because of some assumptions about small chunks === number[] and everything else === Uint8Array.\n\nconst defaultChunkSize = 256;\n\nclass Bl {\n  /**\n   * @param {number} [chunkSize]\n   */\n  constructor (chunkSize = defaultChunkSize) {\n    this.chunkSize = chunkSize;\n    /** @type {number} */\n    this.cursor = 0;\n    /** @type {number} */\n    this.maxCursor = -1;\n    /** @type {(Uint8Array|number[])[]} */\n    this.chunks = [];\n    // keep the first chunk around if we can to save allocations for future encodes\n    /** @type {Uint8Array|number[]|null} */\n    this._initReuseChunk = null;\n  }\n\n  reset () {\n    this.cursor = 0;\n    this.maxCursor = -1;\n    if (this.chunks.length) {\n      this.chunks = [];\n    }\n    if (this._initReuseChunk !== null) {\n      this.chunks.push(this._initReuseChunk);\n      this.maxCursor = this._initReuseChunk.length - 1;\n    }\n  }\n\n  /**\n   * @param {Uint8Array|number[]} bytes\n   */\n  push (bytes) {\n    let topChunk = this.chunks[this.chunks.length - 1];\n    const newMax = this.cursor + bytes.length;\n    if (newMax <= this.maxCursor + 1) {\n      // we have at least one chunk and we can fit these bytes into that chunk\n      const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;\n      // @ts-ignore\n      topChunk.set(bytes, chunkPos);\n    } else {\n      // can't fit it in\n      if (topChunk) {\n        // trip the last chunk to `cursor` if we need to\n        const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;\n        if (chunkPos < topChunk.length) {\n          // @ts-ignore\n          this.chunks[this.chunks.length - 1] = topChunk.subarray(0, chunkPos);\n          this.maxCursor = this.cursor - 1;\n        }\n      }\n      if (bytes.length < 64 && bytes.length < this.chunkSize) {\n        // make a new chunk and copy the new one into it\n        topChunk = alloc(this.chunkSize);\n        this.chunks.push(topChunk);\n        this.maxCursor += topChunk.length;\n        if (this._initReuseChunk === null) {\n          this._initReuseChunk = topChunk;\n        }\n        // @ts-ignore\n        topChunk.set(bytes, 0);\n      } else {\n        // push the new bytes in as its own chunk\n        this.chunks.push(bytes);\n        this.maxCursor += bytes.length;\n      }\n    }\n    this.cursor += bytes.length;\n  }\n\n  /**\n   * @param {boolean} [reset]\n   * @returns {Uint8Array}\n   */\n  toBytes (reset = false) {\n    let byts;\n    if (this.chunks.length === 1) {\n      const chunk = this.chunks[0];\n      if (reset && this.cursor > chunk.length / 2) {\n        /* c8 ignore next 2 */\n        // @ts-ignore\n        byts = this.cursor === chunk.length ? chunk : chunk.subarray(0, this.cursor);\n        this._initReuseChunk = null;\n        this.chunks = [];\n      } else {\n        // @ts-ignore\n        byts = slice(chunk, 0, this.cursor);\n      }\n    } else {\n      // @ts-ignore\n      byts = concat(this.chunks, this.cursor);\n    }\n    if (reset) {\n      this.reset();\n    }\n    return byts\n  }\n}\n\nconst decodeErrPrefix = 'CBOR decode error:';\nconst encodeErrPrefix = 'CBOR encode error:';\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} need\n */\nfunction assertEnoughData (data, pos, need) {\n  if (data.length - pos < need) {\n    throw new Error(`${decodeErrPrefix} not enough data for type`)\n  }\n}\n\n/* globals BigInt */\n\n\nconst uintBoundaries = [24, 256, 65536, 4294967296, BigInt('18446744073709551616')];\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nfunction readUint8 (data, offset, options) {\n  assertEnoughData(data, offset, 1);\n  const value = data[offset];\n  if (options.strict === true && value < uintBoundaries[0]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nfunction readUint16 (data, offset, options) {\n  assertEnoughData(data, offset, 2);\n  const value = (data[offset] << 8) | data[offset + 1];\n  if (options.strict === true && value < uintBoundaries[1]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nfunction readUint32 (data, offset, options) {\n  assertEnoughData(data, offset, 4);\n  const value = (data[offset] * 16777216 /* 2 ** 24 */) + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3];\n  if (options.strict === true && value < uintBoundaries[2]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number|bigint}\n */\nfunction readUint64 (data, offset, options) {\n  // assume BigInt, convert back to Number if within safe range\n  assertEnoughData(data, offset, 8);\n  const hi = (data[offset] * 16777216 /* 2 ** 24 */) + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3];\n  const lo = (data[offset + 4] * 16777216 /* 2 ** 24 */) + (data[offset + 5] << 16) + (data[offset + 6] << 8) + data[offset + 7];\n  const value = (BigInt(hi) << BigInt(32)) + BigInt(lo);\n  if (options.strict === true && value < uintBoundaries[3]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  if (value <= Number.MAX_SAFE_INTEGER) {\n    return Number(value)\n  }\n  if (options.allowBigInt === true) {\n    return value\n  }\n  throw new Error(`${decodeErrPrefix} integers outside of the safe integer range are not supported`)\n}\n\n/* not required thanks to quick[] list\nconst oneByteTokens = new Array(24).fill(0).map((v, i) => new Token(Type.uint, i, 1))\nexport function decodeUintCompact (data, pos, minor, options) {\n  return oneByteTokens[minor]\n}\n*/\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeUint8 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeUint16 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeUint32 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint32(data, pos + 1, options), 5)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeUint64 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint64(data, pos + 1, options), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nfunction encodeUint (buf, token) {\n  return encodeUintValue(buf, 0, token.value)\n}\n\n/**\n * @param {Bl} buf\n * @param {number} major\n * @param {number|bigint} uint\n */\nfunction encodeUintValue (buf, major, uint) {\n  if (uint < uintBoundaries[0]) {\n    const nuint = Number(uint);\n    // pack into one byte, minor=0, additional=value\n    buf.push([major | nuint]);\n  } else if (uint < uintBoundaries[1]) {\n    const nuint = Number(uint);\n    // pack into two byte, minor=0, additional=24\n    buf.push([major | 24, nuint]);\n  } else if (uint < uintBoundaries[2]) {\n    const nuint = Number(uint);\n    // pack into three byte, minor=0, additional=25\n    buf.push([major | 25, nuint >>> 8, nuint & 0xff]);\n  } else if (uint < uintBoundaries[3]) {\n    const nuint = Number(uint);\n    // pack into five byte, minor=0, additional=26\n    buf.push([major | 26, (nuint >>> 24) & 0xff, (nuint >>> 16) & 0xff, (nuint >>> 8) & 0xff, nuint & 0xff]);\n  } else {\n    const buint = BigInt(uint);\n    if (buint < uintBoundaries[4]) {\n      // pack into nine byte, minor=0, additional=27\n      const set = [major | 27, 0, 0, 0, 0, 0, 0, 0];\n      // simulate bitwise above 32 bits\n      let lo = Number(buint & BigInt(0xffffffff));\n      let hi = Number(buint >> BigInt(32) & BigInt(0xffffffff));\n      set[8] = lo & 0xff;\n      lo = lo >> 8;\n      set[7] = lo & 0xff;\n      lo = lo >> 8;\n      set[6] = lo & 0xff;\n      lo = lo >> 8;\n      set[5] = lo & 0xff;\n      set[4] = hi & 0xff;\n      hi = hi >> 8;\n      set[3] = hi & 0xff;\n      hi = hi >> 8;\n      set[2] = hi & 0xff;\n      hi = hi >> 8;\n      set[1] = hi & 0xff;\n      buf.push(set);\n    } else {\n      throw new Error(`${decodeErrPrefix} encountered BigInt larger than allowable range`)\n    }\n  }\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeUint.encodedSize = function encodedSize (token) {\n  return encodeUintValue.encodedSize(token.value)\n};\n\n/**\n * @param {number} uint\n * @returns {number}\n */\nencodeUintValue.encodedSize = function encodedSize (uint) {\n  if (uint < uintBoundaries[0]) {\n    return 1\n  }\n  if (uint < uintBoundaries[1]) {\n    return 2\n  }\n  if (uint < uintBoundaries[2]) {\n    return 3\n  }\n  if (uint < uintBoundaries[3]) {\n    return 5\n  }\n  return 9\n};\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeUint.compareTokens = function compareTokens (tok1, tok2) {\n  return tok1.value < tok2.value ? -1 : tok1.value > tok2.value ? 1 : /* c8 ignore next */ 0\n};\n\n/* eslint-env es2020 */\n\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeNegint8 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeNegint16 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeNegint32 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - readUint32(data, pos + 1, options), 5)\n}\n\nconst neg1b = BigInt(-1);\nconst pos1b = BigInt(1);\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeNegint64 (data, pos, _minor, options) {\n  const int = readUint64(data, pos + 1, options);\n  if (typeof int !== 'bigint') {\n    const value = -1 - int;\n    if (value >= Number.MIN_SAFE_INTEGER) {\n      return new Token(Type.negint, value, 9)\n    }\n  }\n  if (options.allowBigInt !== true) {\n    throw new Error(`${decodeErrPrefix} integers outside of the safe integer range are not supported`)\n  }\n  return new Token(Type.negint, neg1b - BigInt(int), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nfunction encodeNegint (buf, token) {\n  const negint = token.value;\n  const unsigned = (typeof negint === 'bigint' ? (negint * neg1b - pos1b) : (negint * -1 - 1));\n  encodeUintValue(buf, token.type.majorEncoded, unsigned);\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeNegint.encodedSize = function encodedSize (token) {\n  const negint = token.value;\n  const unsigned = (typeof negint === 'bigint' ? (negint * neg1b - pos1b) : (negint * -1 - 1));\n  /* c8 ignore next 4 */\n  // handled by quickEncode, we shouldn't get here but it's included for completeness\n  if (unsigned < uintBoundaries[0]) {\n    return 1\n  }\n  if (unsigned < uintBoundaries[1]) {\n    return 2\n  }\n  if (unsigned < uintBoundaries[2]) {\n    return 3\n  }\n  if (unsigned < uintBoundaries[3]) {\n    return 5\n  }\n  return 9\n};\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeNegint.compareTokens = function compareTokens (tok1, tok2) {\n  // opposite of the uint comparison since we store the uint version in bytes\n  return tok1.value < tok2.value ? 1 : tok1.value > tok2.value ? -1 : /* c8 ignore next */ 0\n};\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken$3 (data, pos, prefix, length) {\n  assertEnoughData(data, pos, prefix + length);\n  const buf = slice(data, pos + prefix, pos + prefix + length);\n  return new Token(Type.bytes, buf, prefix + length)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nfunction decodeBytesCompact (data, pos, minor, _options) {\n  return toToken$3(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeBytes8 (data, pos, _minor, options) {\n  return toToken$3(data, pos, 2, readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeBytes16 (data, pos, _minor, options) {\n  return toToken$3(data, pos, 3, readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeBytes32 (data, pos, _minor, options) {\n  return toToken$3(data, pos, 5, readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeBytes64 (data, pos, _minor, options) {\n  const l = readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer bytes lengths not supported`)\n  }\n  return toToken$3(data, pos, 9, l)\n}\n\n/**\n * `encodedBytes` allows for caching when we do a byte version of a string\n * for key sorting purposes\n * @param {Token} token\n * @returns {Uint8Array}\n */\nfunction tokenBytes (token) {\n  if (token.encodedBytes === undefined) {\n    token.encodedBytes = token.type === Type.string ? fromString(token.value) : token.value;\n  }\n  // @ts-ignore c'mon\n  return token.encodedBytes\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nfunction encodeBytes (buf, token) {\n  const bytes = tokenBytes(token);\n  encodeUintValue(buf, token.type.majorEncoded, bytes.length);\n  buf.push(bytes);\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeBytes.encodedSize = function encodedSize (token) {\n  const bytes = tokenBytes(token);\n  return encodeUintValue.encodedSize(bytes.length) + bytes.length\n};\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeBytes.compareTokens = function compareTokens (tok1, tok2) {\n  return compareBytes(tokenBytes(tok1), tokenBytes(tok2))\n};\n\n/**\n * @param {Uint8Array} b1\n * @param {Uint8Array} b2\n * @returns {number}\n */\nfunction compareBytes (b1, b2) {\n  return b1.length < b2.length ? -1 : b1.length > b2.length ? 1 : compare(b1, b2)\n}\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} prefix\n * @param {number} length\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction toToken$2 (data, pos, prefix, length, options) {\n  const totLength = prefix + length;\n  assertEnoughData(data, pos, totLength);\n  const tok = new Token(Type.string, toString(data, pos + prefix, pos + totLength), totLength);\n  if (options.retainStringBytes === true) {\n    tok.byteValue = slice(data, pos + prefix, pos + totLength);\n  }\n  return tok\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeStringCompact (data, pos, minor, options) {\n  return toToken$2(data, pos, 1, minor, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeString8 (data, pos, _minor, options) {\n  return toToken$2(data, pos, 2, readUint8(data, pos + 1, options), options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeString16 (data, pos, _minor, options) {\n  return toToken$2(data, pos, 3, readUint16(data, pos + 1, options), options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeString32 (data, pos, _minor, options) {\n  return toToken$2(data, pos, 5, readUint32(data, pos + 1, options), options)\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeString64 (data, pos, _minor, options) {\n  const l = readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer string lengths not supported`)\n  }\n  return toToken$2(data, pos, 9, l, options)\n}\n\nconst encodeString = encodeBytes;\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken$1 (_data, _pos, prefix, length) {\n  return new Token(Type.array, length, prefix)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nfunction decodeArrayCompact (data, pos, minor, _options) {\n  return toToken$1(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeArray8 (data, pos, _minor, options) {\n  return toToken$1(data, pos, 2, readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeArray16 (data, pos, _minor, options) {\n  return toToken$1(data, pos, 3, readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeArray32 (data, pos, _minor, options) {\n  return toToken$1(data, pos, 5, readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeArray64 (data, pos, _minor, options) {\n  const l = readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer array lengths not supported`)\n  }\n  return toToken$1(data, pos, 9, l)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeArrayIndefinite (data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return toToken$1(data, pos, 1, Infinity)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nfunction encodeArray (buf, token) {\n  encodeUintValue(buf, Type.array.majorEncoded, token.value);\n}\n\n// using an array as a map key, are you sure about this? we can only sort\n// by map length here, it's up to the encoder to decide to look deeper\nencodeArray.compareTokens = encodeUint.compareTokens;\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeArray.encodedSize = function encodedSize (token) {\n  return encodeUintValue.encodedSize(token.value)\n};\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken (_data, _pos, prefix, length) {\n  return new Token(Type.map, length, prefix)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nfunction decodeMapCompact (data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeMap8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeMap16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeMap32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeMap64 (data, pos, _minor, options) {\n  const l = readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer map lengths not supported`)\n  }\n  return toToken(data, pos, 9, l)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeMapIndefinite (data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return toToken(data, pos, 1, Infinity)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nfunction encodeMap (buf, token) {\n  encodeUintValue(buf, Type.map.majorEncoded, token.value);\n}\n\n// using a map as a map key, are you sure about this? we can only sort\n// by map length here, it's up to the encoder to decide to look deeper\nencodeMap.compareTokens = encodeUint.compareTokens;\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeMap.encodedSize = function encodedSize (token) {\n  return encodeUintValue.encodedSize(token.value)\n};\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nfunction decodeTagCompact (_data, _pos, minor, _options) {\n  return new Token(Type.tag, minor, 1)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeTag8 (data, pos, _minor, options) {\n  return new Token(Type.tag, readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeTag16 (data, pos, _minor, options) {\n  return new Token(Type.tag, readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeTag32 (data, pos, _minor, options) {\n  return new Token(Type.tag, readUint32(data, pos + 1, options), 5)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeTag64 (data, pos, _minor, options) {\n  return new Token(Type.tag, readUint64(data, pos + 1, options), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nfunction encodeTag (buf, token) {\n  encodeUintValue(buf, Type.tag.majorEncoded, token.value);\n}\n\nencodeTag.compareTokens = encodeUint.compareTokens;\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeTag.encodedSize = function encodedSize (token) {\n  return encodeUintValue.encodedSize(token.value)\n};\n\n// TODO: shift some of the bytes logic to bytes-utils so we can use Buffer\n// where possible\n\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n * @typedef {import('../interface').EncodeOptions} EncodeOptions\n */\n\nconst MINOR_FALSE = 20;\nconst MINOR_TRUE = 21;\nconst MINOR_NULL = 22;\nconst MINOR_UNDEFINED = 23;\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeUndefined (_data, _pos, _minor, options) {\n  if (options.allowUndefined === false) {\n    throw new Error(`${decodeErrPrefix} undefined values are not supported`)\n  } else if (options.coerceUndefinedToNull === true) {\n    return new Token(Type.null, null, 1)\n  }\n  return new Token(Type.undefined, undefined, 1)\n}\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeBreak (_data, _pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return new Token(Type.break, undefined, 1)\n}\n\n/**\n * @param {number} value\n * @param {number} bytes\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction createToken (value, bytes, options) {\n  if (options) {\n    if (options.allowNaN === false && Number.isNaN(value)) {\n      throw new Error(`${decodeErrPrefix} NaN values are not supported`)\n    }\n    if (options.allowInfinity === false && (value === Infinity || value === -Infinity)) {\n      throw new Error(`${decodeErrPrefix} Infinity values are not supported`)\n    }\n  }\n  return new Token(Type.float, value, bytes)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeFloat16 (data, pos, _minor, options) {\n  return createToken(readFloat16(data, pos + 1), 3, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeFloat32 (data, pos, _minor, options) {\n  return createToken(readFloat32(data, pos + 1), 5, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction decodeFloat64 (data, pos, _minor, options) {\n  return createToken(readFloat64(data, pos + 1), 9, options)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n * @param {EncodeOptions} options\n */\nfunction encodeFloat (buf, token, options) {\n  const float = token.value;\n\n  if (float === false) {\n    buf.push([Type.float.majorEncoded | MINOR_FALSE]);\n  } else if (float === true) {\n    buf.push([Type.float.majorEncoded | MINOR_TRUE]);\n  } else if (float === null) {\n    buf.push([Type.float.majorEncoded | MINOR_NULL]);\n  } else if (float === undefined) {\n    buf.push([Type.float.majorEncoded | MINOR_UNDEFINED]);\n  } else {\n    let decoded;\n    let success = false;\n    if (!options || options.float64 !== true) {\n      encodeFloat16(float);\n      decoded = readFloat16(ui8a, 1);\n      if (float === decoded || Number.isNaN(float)) {\n        ui8a[0] = 0xf9;\n        buf.push(ui8a.slice(0, 3));\n        success = true;\n      } else {\n        encodeFloat32(float);\n        decoded = readFloat32(ui8a, 1);\n        if (float === decoded) {\n          ui8a[0] = 0xfa;\n          buf.push(ui8a.slice(0, 5));\n          success = true;\n        }\n      }\n    }\n    if (!success) {\n      encodeFloat64(float);\n      decoded = readFloat64(ui8a, 1);\n      ui8a[0] = 0xfb;\n      buf.push(ui8a.slice(0, 9));\n    }\n  }\n}\n\n/**\n * @param {Token} token\n * @param {EncodeOptions} options\n * @returns {number}\n */\nencodeFloat.encodedSize = function encodedSize (token, options) {\n  const float = token.value;\n\n  if (float === false || float === true || float === null || float === undefined) {\n    return 1\n  }\n\n  if (!options || options.float64 !== true) {\n    encodeFloat16(float);\n    let decoded = readFloat16(ui8a, 1);\n    if (float === decoded || Number.isNaN(float)) {\n      return 3\n    }\n    encodeFloat32(float);\n    decoded = readFloat32(ui8a, 1);\n    if (float === decoded) {\n      return 5\n    }\n  }\n  return 9\n};\n\nconst buffer = new ArrayBuffer(9);\nconst dataView = new DataView(buffer, 1);\nconst ui8a = new Uint8Array(buffer, 0);\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat16 (inp) {\n  if (inp === Infinity) {\n    dataView.setUint16(0, 0x7c00, false);\n  } else if (inp === -Infinity) {\n    dataView.setUint16(0, 0xfc00, false);\n  } else if (Number.isNaN(inp)) {\n    dataView.setUint16(0, 0x7e00, false);\n  } else {\n    dataView.setFloat32(0, inp);\n    const valu32 = dataView.getUint32(0);\n    const exponent = (valu32 & 0x7f800000) >> 23;\n    const mantissa = valu32 & 0x7fffff;\n\n    /* c8 ignore next 6 */\n    if (exponent === 0xff) {\n      // too big, Infinity, but this should be hard (impossible?) to trigger\n      dataView.setUint16(0, 0x7c00, false);\n    } else if (exponent === 0x00) {\n      // 0.0, -0.0 and subnormals, shouldn't be possible to get here because 0.0 should be counted as an int\n      dataView.setUint16(0, ((inp & 0x80000000) >> 16) | (mantissa >> 13), false);\n    } else { // standard numbers\n      // chunks of logic here borrowed from https://github.com/PJK/libcbor/blob/c78f437182533e3efa8d963ff4b945bb635c2284/src/cbor/encoding.c#L127\n      const logicalExponent = exponent - 127;\n      // Now we know that 2^exponent <= 0 logically\n      /* c8 ignore next 6 */\n      if (logicalExponent < -24) {\n        /* No unambiguous representation exists, this float is not a half float\n          and is too small to be represented using a half, round off to zero.\n          Consistent with the reference implementation. */\n        // should be difficult (impossible?) to get here in JS\n        dataView.setUint16(0, 0);\n      } else if (logicalExponent < -14) {\n        /* Offset the remaining decimal places by shifting the significand, the\n          value is lost. This is an implementation decision that works around the\n          absence of standard half-float in the language. */\n        dataView.setUint16(0, ((valu32 & 0x80000000) >> 16) | /* sign bit */ (1 << (24 + logicalExponent)), false);\n      } else {\n        dataView.setUint16(0, ((valu32 & 0x80000000) >> 16) | ((logicalExponent + 15) << 10) | (mantissa >> 13), false);\n      }\n    }\n  }\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat16 (ui8a, pos) {\n  if (ui8a.length - pos < 2) {\n    throw new Error(`${decodeErrPrefix} not enough data for float16`)\n  }\n\n  const half = (ui8a[pos] << 8) + ui8a[pos + 1];\n  if (half === 0x7c00) {\n    return Infinity\n  }\n  if (half === 0xfc00) {\n    return -Infinity\n  }\n  if (half === 0x7e00) {\n    return NaN\n  }\n  const exp = (half >> 10) & 0x1f;\n  const mant = half & 0x3ff;\n  let val;\n  if (exp === 0) {\n    val = mant * (2 ** -24);\n  } else if (exp !== 31) {\n    val = (mant + 1024) * (2 ** (exp - 25));\n  /* c8 ignore next 4 */\n  } else {\n    // may not be possible to get here\n    val = mant === 0 ? Infinity : NaN;\n  }\n  return (half & 0x8000) ? -val : val\n}\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat32 (inp) {\n  dataView.setFloat32(0, inp, false);\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat32 (ui8a, pos) {\n  if (ui8a.length - pos < 4) {\n    throw new Error(`${decodeErrPrefix} not enough data for float32`)\n  }\n  const offset = (ui8a.byteOffset || 0) + pos;\n  return new DataView(ui8a.buffer, offset, 4).getFloat32(0, false)\n}\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat64 (inp) {\n  dataView.setFloat64(0, inp, false);\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat64 (ui8a, pos) {\n  if (ui8a.length - pos < 8) {\n    throw new Error(`${decodeErrPrefix} not enough data for float64`)\n  }\n  const offset = (ui8a.byteOffset || 0) + pos;\n  return new DataView(ui8a.buffer, offset, 8).getFloat64(0, false)\n}\n\n/**\n * @param {Token} _tok1\n * @param {Token} _tok2\n * @returns {number}\n */\nencodeFloat.compareTokens = encodeUint.compareTokens;\n/*\nencodeFloat.compareTokens = function compareTokens (_tok1, _tok2) {\n  return _tok1\n  throw new Error(`${encodeErrPrefix} cannot use floats as map keys`)\n}\n*/\n\n/**\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n */\nfunction invalidMinor (data, pos, minor) {\n  throw new Error(`${decodeErrPrefix} encountered invalid minor (${minor}) for major ${data[pos] >>> 5}`)\n}\n\n/**\n * @param {string} msg\n * @returns {()=>any}\n */\nfunction errorer (msg) {\n  return () => { throw new Error(`${decodeErrPrefix} ${msg}`) }\n}\n\n/** @type {((data:Uint8Array, pos:number, minor:number, options?:DecodeOptions) => any)[]} */\nconst jump = [];\n\n// unsigned integer, 0x00..0x17 (0..23)\nfor (let i = 0; i <= 0x17; i++) {\n  jump[i] = invalidMinor; // uint.decodeUintCompact, handled by quick[]\n}\njump[0x18] = decodeUint8; // unsigned integer, one-byte uint8_t follows\njump[0x19] = decodeUint16; // unsigned integer, two-byte uint16_t follows\njump[0x1a] = decodeUint32; // unsigned integer, four-byte uint32_t follows\njump[0x1b] = decodeUint64; // unsigned integer, eight-byte uint64_t follows\njump[0x1c] = invalidMinor;\njump[0x1d] = invalidMinor;\njump[0x1e] = invalidMinor;\njump[0x1f] = invalidMinor;\n// negative integer, -1-0x00..-1-0x17 (-1..-24)\nfor (let i = 0x20; i <= 0x37; i++) {\n  jump[i] = invalidMinor; // negintDecode, handled by quick[]\n}\njump[0x38] = decodeNegint8; // negative integer, -1-n one-byte uint8_t for n follows\njump[0x39] = decodeNegint16; // negative integer, -1-n two-byte uint16_t for n follows\njump[0x3a] = decodeNegint32; // negative integer, -1-n four-byte uint32_t for follows\njump[0x3b] = decodeNegint64; // negative integer, -1-n eight-byte uint64_t for follows\njump[0x3c] = invalidMinor;\njump[0x3d] = invalidMinor;\njump[0x3e] = invalidMinor;\njump[0x3f] = invalidMinor;\n// byte string, 0x00..0x17 bytes follow\nfor (let i = 0x40; i <= 0x57; i++) {\n  jump[i] = decodeBytesCompact;\n}\njump[0x58] = decodeBytes8; // byte string, one-byte uint8_t for n, and then n bytes follow\njump[0x59] = decodeBytes16; // byte string, two-byte uint16_t for n, and then n bytes follow\njump[0x5a] = decodeBytes32; // byte string, four-byte uint32_t for n, and then n bytes follow\njump[0x5b] = decodeBytes64; // byte string, eight-byte uint64_t for n, and then n bytes follow\njump[0x5c] = invalidMinor;\njump[0x5d] = invalidMinor;\njump[0x5e] = invalidMinor;\njump[0x5f] = errorer('indefinite length bytes/strings are not supported'); // byte string, byte strings follow, terminated by \"break\"\n// UTF-8 string 0x00..0x17 bytes follow\nfor (let i = 0x60; i <= 0x77; i++) {\n  jump[i] = decodeStringCompact;\n}\njump[0x78] = decodeString8; // UTF-8 string, one-byte uint8_t for n, and then n bytes follow\njump[0x79] = decodeString16; // UTF-8 string, two-byte uint16_t for n, and then n bytes follow\njump[0x7a] = decodeString32; // UTF-8 string, four-byte uint32_t for n, and then n bytes follow\njump[0x7b] = decodeString64; // UTF-8 string, eight-byte uint64_t for n, and then n bytes follow\njump[0x7c] = invalidMinor;\njump[0x7d] = invalidMinor;\njump[0x7e] = invalidMinor;\njump[0x7f] = errorer('indefinite length bytes/strings are not supported'); // UTF-8 strings follow, terminated by \"break\"\n// array, 0x00..0x17 data items follow\nfor (let i = 0x80; i <= 0x97; i++) {\n  jump[i] = decodeArrayCompact;\n}\njump[0x98] = decodeArray8; // array, one-byte uint8_t for n, and then n data items follow\njump[0x99] = decodeArray16; // array, two-byte uint16_t for n, and then n data items follow\njump[0x9a] = decodeArray32; // array, four-byte uint32_t for n, and then n data items follow\njump[0x9b] = decodeArray64; // array, eight-byte uint64_t for n, and then n data items follow\njump[0x9c] = invalidMinor;\njump[0x9d] = invalidMinor;\njump[0x9e] = invalidMinor;\njump[0x9f] = decodeArrayIndefinite; // array, data items follow, terminated by \"break\"\n// map, 0x00..0x17 pairs of data items follow\nfor (let i = 0xa0; i <= 0xb7; i++) {\n  jump[i] = decodeMapCompact;\n}\njump[0xb8] = decodeMap8; // map, one-byte uint8_t for n, and then n pairs of data items follow\njump[0xb9] = decodeMap16; // map, two-byte uint16_t for n, and then n pairs of data items follow\njump[0xba] = decodeMap32; // map, four-byte uint32_t for n, and then n pairs of data items follow\njump[0xbb] = decodeMap64; // map, eight-byte uint64_t for n, and then n pairs of data items follow\njump[0xbc] = invalidMinor;\njump[0xbd] = invalidMinor;\njump[0xbe] = invalidMinor;\njump[0xbf] = decodeMapIndefinite; // map, pairs of data items follow, terminated by \"break\"\n// tags\nfor (let i = 0xc0; i <= 0xd7; i++) {\n  jump[i] = decodeTagCompact;\n}\njump[0xd8] = decodeTag8;\njump[0xd9] = decodeTag16;\njump[0xda] = decodeTag32;\njump[0xdb] = decodeTag64;\njump[0xdc] = invalidMinor;\njump[0xdd] = invalidMinor;\njump[0xde] = invalidMinor;\njump[0xdf] = invalidMinor;\n// 0xe0..0xf3 simple values, unsupported\nfor (let i = 0xe0; i <= 0xf3; i++) {\n  jump[i] = errorer('simple values are not supported');\n}\njump[0xf4] = invalidMinor; // false, handled by quick[]\njump[0xf5] = invalidMinor; // true, handled by quick[]\njump[0xf6] = invalidMinor; // null, handled by quick[]\njump[0xf7] = decodeUndefined; // undefined\njump[0xf8] = errorer('simple values are not supported'); // simple value, one byte follows, unsupported\njump[0xf9] = decodeFloat16; // half-precision float (two-byte IEEE 754)\njump[0xfa] = decodeFloat32; // single-precision float (four-byte IEEE 754)\njump[0xfb] = decodeFloat64; // double-precision float (eight-byte IEEE 754)\njump[0xfc] = invalidMinor;\njump[0xfd] = invalidMinor;\njump[0xfe] = invalidMinor;\njump[0xff] = decodeBreak; // \"break\" stop code\n\n/** @type {Token[]} */\nconst quick = [];\n// ints <24\nfor (let i = 0; i < 24; i++) {\n  quick[i] = new Token(Type.uint, i, 1);\n}\n// negints >= -24\nfor (let i = -1; i >= -24; i--) {\n  quick[31 - i] = new Token(Type.negint, i, 1);\n}\n// empty bytes\nquick[0x40] = new Token(Type.bytes, new Uint8Array(0), 1);\n// empty string\nquick[0x60] = new Token(Type.string, '', 1);\n// empty list\nquick[0x80] = new Token(Type.array, 0, 1);\n// empty map\nquick[0xa0] = new Token(Type.map, 0, 1);\n// false\nquick[0xf4] = new Token(Type.false, false, 1);\n// true\nquick[0xf5] = new Token(Type.true, true, 1);\n// null\nquick[0xf6] = new Token(Type.null, null, 1);\n\n/**\n * @param {Token} token\n * @returns {Uint8Array|undefined}\n */\nfunction quickEncodeToken (token) {\n  switch (token.type) {\n    case Type.false:\n      return fromArray([0xf4])\n    case Type.true:\n      return fromArray([0xf5])\n    case Type.null:\n      return fromArray([0xf6])\n    case Type.bytes:\n      if (!token.value.length) {\n        return fromArray([0x40])\n      }\n      return\n    case Type.string:\n      if (token.value === '') {\n        return fromArray([0x60])\n      }\n      return\n    case Type.array:\n      if (token.value === 0) {\n        return fromArray([0x80])\n      }\n      /* c8 ignore next 2 */\n      // shouldn't be possible if this were called when there was only one token\n      return\n    case Type.map:\n      if (token.value === 0) {\n        return fromArray([0xa0])\n      }\n      /* c8 ignore next 2 */\n      // shouldn't be possible if this were called when there was only one token\n      return\n    case Type.uint:\n      if (token.value < 24) {\n        return fromArray([Number(token.value)])\n      }\n      return\n    case Type.negint:\n      if (token.value >= -24) {\n        return fromArray([31 - Number(token.value)])\n      }\n  }\n}\n\n/**\n * @typedef {import('../interface').EncodeOptions} EncodeOptions\n * @typedef {import('../interface').OptionalTypeEncoder} OptionalTypeEncoder\n * @typedef {import('../interface').Reference} Reference\n * @typedef {import('../interface').StrictTypeEncoder} StrictTypeEncoder\n * @typedef {import('../interface').TokenTypeEncoder} TokenTypeEncoder\n * @typedef {import('../interface').TokenOrNestedTokens} TokenOrNestedTokens\n */\n\n/** @type {EncodeOptions} */\nconst defaultEncodeOptions = {\n  float64: false,\n  mapSorter,\n  quickEncodeToken\n};\n\n/** @returns {TokenTypeEncoder[]} */\nfunction makeCborEncoders () {\n  const encoders = [];\n  encoders[Type.uint.major] = encodeUint;\n  encoders[Type.negint.major] = encodeNegint;\n  encoders[Type.bytes.major] = encodeBytes;\n  encoders[Type.string.major] = encodeString;\n  encoders[Type.array.major] = encodeArray;\n  encoders[Type.map.major] = encodeMap;\n  encoders[Type.tag.major] = encodeTag;\n  encoders[Type.float.major] = encodeFloat;\n  return encoders\n}\n\nconst cborEncoders = makeCborEncoders();\n\nconst buf = new Bl();\n\n/** @implements {Reference} */\nclass Ref {\n  /**\n   * @param {object|any[]} obj\n   * @param {Reference|undefined} parent\n   */\n  constructor (obj, parent) {\n    this.obj = obj;\n    this.parent = parent;\n  }\n\n  /**\n   * @param {object|any[]} obj\n   * @returns {boolean}\n   */\n  includes (obj) {\n    /** @type {Reference|undefined} */\n    let p = this;\n    do {\n      if (p.obj === obj) {\n        return true\n      }\n    } while (p = p.parent) // eslint-disable-line\n    return false\n  }\n\n  /**\n   * @param {Reference|undefined} stack\n   * @param {object|any[]} obj\n   * @returns {Reference}\n   */\n  static createCheck (stack, obj) {\n    if (stack && stack.includes(obj)) {\n      throw new Error(`${encodeErrPrefix} object contains circular references`)\n    }\n    return new Ref(obj, stack)\n  }\n}\n\nconst simpleTokens = {\n  null: new Token(Type.null, null),\n  undefined: new Token(Type.undefined, undefined),\n  true: new Token(Type.true, true),\n  false: new Token(Type.false, false),\n  emptyArray: new Token(Type.array, 0),\n  emptyMap: new Token(Type.map, 0)\n};\n\n/** @type {{[typeName: string]: StrictTypeEncoder}} */\nconst typeEncoders = {\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  number (obj, _typ, _options, _refStack) {\n    if (!Number.isInteger(obj) || !Number.isSafeInteger(obj)) {\n      return new Token(Type.float, obj)\n    } else if (obj >= 0) {\n      return new Token(Type.uint, obj)\n    } else {\n      return new Token(Type.negint, obj)\n    }\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  bigint (obj, _typ, _options, _refStack) {\n    if (obj >= BigInt(0)) {\n      return new Token(Type.uint, obj)\n    } else {\n      return new Token(Type.negint, obj)\n    }\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Uint8Array (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, obj)\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  string (obj, _typ, _options, _refStack) {\n    return new Token(Type.string, obj)\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  boolean (obj, _typ, _options, _refStack) {\n    return obj ? simpleTokens.true : simpleTokens.false\n  },\n\n  /**\n   * @param {any} _obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  null (_obj, _typ, _options, _refStack) {\n    return simpleTokens.null\n  },\n\n  /**\n   * @param {any} _obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  undefined (_obj, _typ, _options, _refStack) {\n    return simpleTokens.undefined\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  ArrayBuffer (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, new Uint8Array(obj))\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  DataView (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength))\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} options\n   * @param {Reference} [refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Array (obj, _typ, options, refStack) {\n    if (!obj.length) {\n      if (options.addBreakTokens === true) {\n        return [simpleTokens.emptyArray, new Token(Type.break)]\n      }\n      return simpleTokens.emptyArray\n    }\n    refStack = Ref.createCheck(refStack, obj);\n    const entries = [];\n    let i = 0;\n    for (const e of obj) {\n      entries[i++] = objectToTokens(e, options, refStack);\n    }\n    if (options.addBreakTokens) {\n      return [new Token(Type.array, obj.length), entries, new Token(Type.break)]\n    }\n    return [new Token(Type.array, obj.length), entries]\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} typ\n   * @param {EncodeOptions} options\n   * @param {Reference} [refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Object (obj, typ, options, refStack) {\n    // could be an Object or a Map\n    const isMap = typ !== 'Object';\n    // it's slightly quicker to use Object.keys() than Object.entries()\n    const keys = isMap ? obj.keys() : Object.keys(obj);\n    const length = isMap ? obj.size : keys.length;\n    if (!length) {\n      if (options.addBreakTokens === true) {\n        return [simpleTokens.emptyMap, new Token(Type.break)]\n      }\n      return simpleTokens.emptyMap\n    }\n    refStack = Ref.createCheck(refStack, obj);\n    /** @type {TokenOrNestedTokens[]} */\n    const entries = [];\n    let i = 0;\n    for (const key of keys) {\n      entries[i++] = [\n        objectToTokens(key, options, refStack),\n        objectToTokens(isMap ? obj.get(key) : obj[key], options, refStack)\n      ];\n    }\n    sortMapEntries(entries, options);\n    if (options.addBreakTokens) {\n      return [new Token(Type.map, length), entries, new Token(Type.break)]\n    }\n    return [new Token(Type.map, length), entries]\n  }\n};\n\ntypeEncoders.Map = typeEncoders.Object;\ntypeEncoders.Buffer = typeEncoders.Uint8Array;\nfor (const typ of 'Uint8Clamped Uint16 Uint32 Int8 Int16 Int32 BigUint64 BigInt64 Float32 Float64'.split(' ')) {\n  typeEncoders[`${typ}Array`] = typeEncoders.DataView;\n}\n\n/**\n * @param {any} obj\n * @param {EncodeOptions} [options]\n * @param {Reference} [refStack]\n * @returns {TokenOrNestedTokens}\n */\nfunction objectToTokens (obj, options = {}, refStack) {\n  const typ = is(obj);\n  const customTypeEncoder = (options && options.typeEncoders && /** @type {OptionalTypeEncoder} */ options.typeEncoders[typ]) || typeEncoders[typ];\n  if (typeof customTypeEncoder === 'function') {\n    const tokens = customTypeEncoder(obj, typ, options, refStack);\n    if (tokens != null) {\n      return tokens\n    }\n  }\n  const typeEncoder = typeEncoders[typ];\n  if (!typeEncoder) {\n    throw new Error(`${encodeErrPrefix} unsupported type: ${typ}`)\n  }\n  return typeEncoder(obj, typ, options, refStack)\n}\n\n/*\nCBOR key sorting is a mess.\n\nThe canonicalisation recommendation from https://tools.ietf.org/html/rfc7049#section-3.9\nincludes the wording:\n\n> The keys in every map must be sorted lowest value to highest.\n> Sorting is performed on the bytes of the representation of the key\n> data items without paying attention to the 3/5 bit splitting for\n> major types.\n> ...\n>  *  If two keys have different lengths, the shorter one sorts\n      earlier;\n>  *  If two keys have the same length, the one with the lower value\n      in (byte-wise) lexical order sorts earlier.\n\n1. It is not clear what \"bytes of the representation of the key\" means: is it\n   the CBOR representation, or the binary representation of the object itself?\n   Consider the int and uint difference here.\n2. It is not clear what \"without paying attention to\" means: do we include it\n   and compare on that? Or do we omit the special prefix byte, (mostly) treating\n   the key in its plain binary representation form.\n\nThe FIDO 2.0: Client To Authenticator Protocol spec takes the original CBOR\nwording and clarifies it according to their understanding.\nhttps://fidoalliance.org/specs/fido-v2.0-rd-20170927/fido-client-to-authenticator-protocol-v2.0-rd-20170927.html#message-encoding\n\n> The keys in every map must be sorted lowest value to highest. Sorting is\n> performed on the bytes of the representation of the key data items without\n> paying attention to the 3/5 bit splitting for major types. The sorting rules\n> are:\n>  * If the major types are different, the one with the lower value in numerical\n>    order sorts earlier.\n>  * If two keys have different lengths, the shorter one sorts earlier;\n>  * If two keys have the same length, the one with the lower value in\n>    (byte-wise) lexical order sorts earlier.\n\nSome other implementations, such as borc, do a full encode then do a\nlength-first, byte-wise-second comparison:\nhttps://github.com/dignifiedquire/borc/blob/b6bae8b0bcde7c3976b0f0f0957208095c392a36/src/encoder.js#L358\nhttps://github.com/dignifiedquire/borc/blob/b6bae8b0bcde7c3976b0f0f0957208095c392a36/src/utils.js#L143-L151\n\nThis has the benefit of being able to easily handle arbitrary keys, including\ncomplex types (maps and arrays).\n\nWe'll opt for the FIDO approach, since it affords some efficies since we don't\nneed a full encode of each key to determine order and can defer to the types\nto determine how to most efficiently order their values (i.e. int and uint\nordering can be done on the numbers, no need for byte-wise, for example).\n\nRecommendation: stick to single key types or you'll get into trouble, and prefer\nstring keys because it's much simpler that way.\n*/\n\n/*\n(UPDATE, Dec 2020)\nhttps://tools.ietf.org/html/rfc8949 is the updated CBOR spec and clarifies some\nof the questions above with a new recommendation for sorting order being much\ncloser to what would be expected in other environments (i.e. no length-first\nweirdness).\nThis new sorting order is not yet implemented here but could be added as an\noption. \"Determinism\" (canonicity) is system dependent and it's difficult to\nchange existing systems that are built with existing expectations. So if a new\nordering is introduced here, the old needs to be kept as well with the user\nhaving the option.\n*/\n\n/**\n * @param {TokenOrNestedTokens[]} entries\n * @param {EncodeOptions} options\n */\nfunction sortMapEntries (entries, options) {\n  if (options.mapSorter) {\n    entries.sort(options.mapSorter);\n  }\n}\n\n/**\n * @param {(Token|Token[])[]} e1\n * @param {(Token|Token[])[]} e2\n * @returns {number}\n */\nfunction mapSorter (e1, e2) {\n  // the key position ([0]) could have a single token or an array\n  // almost always it'll be a single token but complex key might get involved\n  /* c8 ignore next 2 */\n  const keyToken1 = Array.isArray(e1[0]) ? e1[0][0] : e1[0];\n  const keyToken2 = Array.isArray(e2[0]) ? e2[0][0] : e2[0];\n\n  // different key types\n  if (keyToken1.type !== keyToken2.type) {\n    return keyToken1.type.compare(keyToken2.type)\n  }\n\n  const major = keyToken1.type.major;\n  // TODO: handle case where cmp === 0 but there are more keyToken e. complex type)\n  const tcmp = cborEncoders[major].compareTokens(keyToken1, keyToken2);\n  /* c8 ignore next 5 */\n  if (tcmp === 0) {\n    // duplicate key or complex type where the first token matched,\n    // i.e. a map or array and we're only comparing the opening token\n    console.warn('WARNING: complex key types used, CBOR key sorting guarantees are gone');\n  }\n  return tcmp\n}\n\n/**\n * @param {Bl} buf\n * @param {TokenOrNestedTokens} tokens\n * @param {TokenTypeEncoder[]} encoders\n * @param {EncodeOptions} options\n */\nfunction tokensToEncoded (buf, tokens, encoders, options) {\n  if (Array.isArray(tokens)) {\n    for (const token of tokens) {\n      tokensToEncoded(buf, token, encoders, options);\n    }\n  } else {\n    encoders[tokens.type.major](buf, tokens, options);\n  }\n}\n\n/**\n * @param {any} data\n * @param {TokenTypeEncoder[]} encoders\n * @param {EncodeOptions} options\n * @returns {Uint8Array}\n */\nfunction encodeCustom (data, encoders, options) {\n  const tokens = objectToTokens(data, options);\n  if (!Array.isArray(tokens) && options.quickEncodeToken) {\n    const quickBytes = options.quickEncodeToken(tokens);\n    if (quickBytes) {\n      return quickBytes\n    }\n    const encoder = encoders[tokens.type.major];\n    if (encoder.encodedSize) {\n      const size = encoder.encodedSize(tokens, options);\n      const buf = new Bl(size);\n      encoder(buf, tokens, options);\n      /* c8 ignore next 4 */\n      // this would be a problem with encodedSize() functions\n      if (buf.chunks.length !== 1) {\n        throw new Error(`Unexpected error: pre-calculated length for ${tokens} was wrong`)\n      }\n      return asU8A(buf.chunks[0])\n    }\n  }\n  buf.reset();\n  tokensToEncoded(buf, tokens, encoders, options);\n  return buf.toBytes(true)\n}\n\n/**\n * @param {any} data\n * @param {EncodeOptions} [options]\n * @returns {Uint8Array}\n */\nfunction encode (data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options);\n  return encodeCustom(data, cborEncoders, options)\n}\n\n/**\n * @typedef {import('./token.js').Token} Token\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n * @typedef {import('../interface').DecodeTokenizer} DecodeTokenizer\n */\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\n\n/**\n * @implements {DecodeTokenizer}\n */\nclass Tokeniser {\n  /**\n   * @param {Uint8Array} data\n   * @param {DecodeOptions} options\n   */\n  constructor (data, options = {}) {\n    this._pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n\n  pos () {\n    return this._pos\n  }\n\n  done () {\n    return this._pos >= this.data.length\n  }\n\n  next () {\n    const byt = this.data[this._pos];\n    let token = quick[byt];\n    if (token === undefined) {\n      const decoder = jump[byt];\n      /* c8 ignore next 4 */\n      // if we're here then there's something wrong with our jump or quick lists!\n      if (!decoder) {\n        throw new Error(`${decodeErrPrefix} no decoder for major type ${byt >>> 5} (byte 0x${byt.toString(16).padStart(2, '0')})`)\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this._pos, minor, this.options);\n    }\n    // @ts-ignore we get to assume encodedLength is set (crossing fingers slightly)\n    this._pos += token.encodedLength;\n    return token\n  }\n}\n\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\n\n/**\n * @param {Token} token\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokenToArray (token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        // normal end to indefinite length array\n        break\n      }\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed array`)\n    }\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found array but not enough entries (got ${i}, expected ${token.value})`)\n    }\n    arr[i] = value;\n  }\n  return arr\n}\n\n/**\n * @param {Token} token\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokenToMap (token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        // normal end to indefinite length map\n        break\n      }\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed map`)\n    }\n    if (key === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no key], expected ${token.value})`)\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${decodeErrPrefix} non-string keys not supported (got ${typeof key})`)\n    }\n    if (options.rejectDuplicateMapKeys === true) {\n      // @ts-ignore\n      if ((useMaps && m.has(key)) || (!useMaps && (key in obj))) {\n        throw new Error(`${decodeErrPrefix} found repeat map key \"${key}\"`)\n      }\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no value], expected ${token.value})`)\n    }\n    if (useMaps) {\n      // @ts-ignore TODO reconsider this .. maybe needs to be strict about key types\n      m.set(key, value);\n    } else {\n      // @ts-ignore TODO reconsider this .. maybe needs to be strict about key types\n      obj[key] = value;\n    }\n  }\n  // @ts-ignore c'mon man\n  return useMaps ? m : obj\n}\n\n/**\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokensToObject (tokeniser, options) {\n  // should we support array as an argument?\n  // check for tokenIter[Symbol.iterator] and replace tokenIter with what that returns?\n  if (tokeniser.done()) {\n    return DONE\n  }\n\n  const token = tokeniser.next();\n\n  if (token.type === Type.break) {\n    return BREAK\n  }\n\n  if (token.type.terminal) {\n    return token.value\n  }\n\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options)\n  }\n\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options)\n  }\n\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged)\n    }\n    throw new Error(`${decodeErrPrefix} tag not supported (${token.value})`)\n  }\n  /* c8 ignore next */\n  throw new Error('unsupported')\n}\n\n/**\n * @param {Uint8Array} data\n * @param {DecodeOptions} [options]\n * @returns {[any, Uint8Array]}\n */\nfunction decodeFirst (data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${decodeErrPrefix} data to decode must be a Uint8Array`)\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${decodeErrPrefix} did not find any content to decode`)\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${decodeErrPrefix} got unexpected break`)\n  }\n  return [decoded, data.subarray(tokeniser.pos())]\n}\n\n/**\n * @param {Uint8Array} data\n * @param {DecodeOptions} [options]\n * @returns {any}\n */\nfunction decode (data, options) {\n  const [decoded, remainder] = decodeFirst(data, options);\n  if (remainder.length > 0) {\n    throw new Error(`${decodeErrPrefix} too many terminals, data makes no sense`)\n  }\n  return decoded\n}\n\nexport { Token, Tokeniser as Tokenizer, Type, decode, decodeFirst, encode, tokensToObject };\n","import { ListElementEntity } from \"../../common/EntityTypes.js\"\nimport { CalendarEvent, CalendarEventTypeRef, Mail } from \"../../entities/tutanota/TypeRefs.js\"\nimport { freezeMap, getTypeId, TypeRef } from \"@tutao/tutanota-utils\"\nimport { CUSTOM_MAX_ID, CUSTOM_MIN_ID, firstBiggerThanSecond, getElementId, LOAD_MULTIPLE_LIMIT } from \"../../common/utils/EntityUtils.js\"\nimport { resolveTypeReference } from \"../../common/EntityFunctions.js\"\nimport { CacheStorage, ExposedCacheStorage, Range } from \"./DefaultEntityRestCache.js\"\nimport { EntityRestClient } from \"./EntityRestClient.js\"\nimport { ProgrammingError } from \"../../common/error/ProgrammingError.js\"\nimport { EntityUpdate } from \"../../entities/sys/TypeRefs\"\n\n/**\n * update when implementing custom cache handlers.\n * add new types to the union when implementing new\n * custom cache handlers.\n */\ntype CustomCacheHandledType = never | CalendarEvent | Mail\n\n/**\n * makes sure that any {ref<A>, handler<A>} pair passed to\n * the constructor uses the same A for both props and that they\n * are types for which we actually do custom handling.\n */\ntype CustomCacheHandlerMapping = CustomCacheHandledType extends infer A\n\t? A extends ListElementEntity\n\t\t? { ref: TypeRef<A>; handler: CustomCacheHandler<A> }\n\t\t: never\n\t: never\n\n/**\n * wrapper for a TypeRef -> CustomCacheHandler map that's needed because we can't\n * use TypeRefs directly as map keys due to object identity not matching.\n *\n * it is mostly read-only\n */\nexport class CustomCacheHandlerMap {\n\tprivate readonly handlers: ReadonlyMap<string, CustomCacheHandler<ListElementEntity>>\n\n\tconstructor(...args: ReadonlyArray<CustomCacheHandlerMapping>) {\n\t\tconst handlers: Map<string, CustomCacheHandler<ListElementEntity>> = new Map()\n\t\tfor (const { ref, handler } of args) {\n\t\t\tconst key = getTypeId(ref)\n\t\t\thandlers.set(key, handler)\n\t\t}\n\t\tthis.handlers = freezeMap(handlers)\n\t}\n\n\tget<T extends ListElementEntity>(typeRef: TypeRef<T>): CustomCacheHandler<T> | undefined {\n\t\tconst typeId = getTypeId(typeRef)\n\t\t// map is frozen after the constructor. constructor arg types are set up to uphold this invariant.\n\t\treturn this.handlers.get(typeId) as CustomCacheHandler<T> | undefined\n\t}\n}\n\n/**\n * Some types are not cached like other types, for example because their custom Ids are not sortable.\n * make sure to update CustomHandledType when implementing this for a new type.\n */\nexport interface CustomCacheHandler<T extends ListElementEntity> {\n\tloadRange?: (storage: ExposedCacheStorage, listId: Id, start: Id, count: number, reverse: boolean) => Promise<T[]>\n\n\tgetElementIdsInCacheRange?: (storage: ExposedCacheStorage, listId: Id, ids: Array<Id>) => Promise<Array<Id>>\n\n\tshouldLoadOnCreateEvent?: (event: EntityUpdate) => Promise<boolean>\n}\n\n/**\n * implements range loading in JS because the custom Ids of calendar events prevent us from doing\n * this effectively in the database.\n */\nexport class CustomCalendarEventCacheHandler implements CustomCacheHandler<CalendarEvent> {\n\tconstructor(private readonly entityRestClient: EntityRestClient) {}\n\n\tasync loadRange(storage: CacheStorage, listId: Id, start: Id, count: number, reverse: boolean): Promise<CalendarEvent[]> {\n\t\tconst range = await storage.getRangeForList(CalendarEventTypeRef, listId)\n\n\t\t//if offline db for this list is empty load from server\n\t\tlet rawList: Array<CalendarEvent> = []\n\t\tif (range == null) {\n\t\t\tlet chunk: Array<CalendarEvent> = []\n\t\t\tlet currentMin = CUSTOM_MIN_ID\n\t\t\twhile (true) {\n\t\t\t\tchunk = await this.entityRestClient.loadRange(CalendarEventTypeRef, listId, currentMin, LOAD_MULTIPLE_LIMIT, false)\n\t\t\t\trawList.push(...chunk)\n\t\t\t\tif (chunk.length < LOAD_MULTIPLE_LIMIT) break\n\t\t\t\tcurrentMin = getElementId(chunk[chunk.length - 1])\n\t\t\t}\n\t\t\tfor (const event of rawList) {\n\t\t\t\tawait storage.put(event)\n\t\t\t}\n\n\t\t\t// we have all events now\n\t\t\tawait storage.setNewRangeForList(CalendarEventTypeRef, listId, CUSTOM_MIN_ID, CUSTOM_MAX_ID)\n\t\t} else {\n\t\t\tthis.assertCorrectRange(range)\n\t\t\trawList = await storage.getWholeList(CalendarEventTypeRef, listId)\n\t\t\tconsole.log(`CalendarEvent list ${listId} has ${rawList.length} events`)\n\t\t}\n\t\tconst typeModel = await resolveTypeReference(CalendarEventTypeRef)\n\t\tconst sortedList = reverse\n\t\t\t? rawList\n\t\t\t\t\t.filter((calendarEvent) => firstBiggerThanSecond(start, getElementId(calendarEvent), typeModel))\n\t\t\t\t\t.sort((a, b) => (firstBiggerThanSecond(getElementId(b), getElementId(a), typeModel) ? 1 : -1))\n\t\t\t: rawList\n\t\t\t\t\t.filter((calendarEvent) => firstBiggerThanSecond(getElementId(calendarEvent), start, typeModel))\n\t\t\t\t\t.sort((a, b) => (firstBiggerThanSecond(getElementId(a), getElementId(b), typeModel) ? 1 : -1))\n\t\treturn sortedList.slice(0, count)\n\t}\n\n\tprivate assertCorrectRange(range: Range) {\n\t\tif (range.lower !== CUSTOM_MIN_ID || range.upper !== CUSTOM_MAX_ID) {\n\t\t\tthrow new ProgrammingError(`Invalid range for CalendarEvent: ${JSON.stringify(range)}`)\n\t\t}\n\t}\n\n\tasync getElementIdsInCacheRange(storage: CacheStorage, listId: Id, ids: Array<Id>): Promise<Array<Id>> {\n\t\tconst range = await storage.getRangeForList(CalendarEventTypeRef, listId)\n\t\tif (range) {\n\t\t\tthis.assertCorrectRange(range)\n\t\t\t// assume none of the given Ids are already cached to make sure they are loaded now\n\t\t\treturn ids\n\t\t} else {\n\t\t\treturn []\n\t\t}\n\t}\n}\n\nexport class CustomMailEventCacheHandler implements CustomCacheHandler<Mail> {\n\tasync shouldLoadOnCreateEvent(): Promise<boolean> {\n\t\t// New emails should be pre-cached.\n\t\t//  - we need them to display the folder contents\n\t\t//  - will very likely be loaded by indexer later\n\t\t//  - we might have the instance in offline cache already because of notification process\n\t\treturn true\n\t}\n}\n","import { ElementEntity, ListElementEntity, SomeEntity, TypeModel } from \"../../common/EntityTypes.js\"\nimport { CUSTOM_MIN_ID, firstBiggerThanSecond, GENERATED_MIN_ID, getElementId } from \"../../common/utils/EntityUtils.js\"\nimport { CacheStorage, expandId, ExposedCacheStorage, LastUpdateTime } from \"../rest/DefaultEntityRestCache.js\"\nimport * as cborg from \"cborg\"\nimport { EncodeOptions, Token, Type } from \"cborg\"\nimport {\n\tassert,\n\tassertNotNull,\n\tbase64ExtToBase64,\n\tbase64ToBase64Ext,\n\tbase64ToBase64Url,\n\tbase64UrlToBase64,\n\tgetTypeId,\n\tgroupByAndMapUniquely,\n\tmapNullable,\n\tsplitInChunks,\n\tTypeRef,\n} from \"@tutao/tutanota-utils\"\nimport { isDesktop, isOfflineStorageAvailable, isTest } from \"../../common/Env.js\"\nimport { modelInfos, resolveTypeReference } from \"../../common/EntityFunctions.js\"\nimport { DateProvider } from \"../../common/DateProvider.js\"\nimport { TokenOrNestedTokens } from \"cborg/interface\"\nimport { CalendarEventTypeRef, MailTypeRef } from \"../../entities/tutanota/TypeRefs.js\"\nimport { OfflineStorageMigrator } from \"./OfflineStorageMigrator.js\"\nimport { CustomCacheHandlerMap, CustomCalendarEventCacheHandler, CustomMailEventCacheHandler } from \"../rest/CustomCacheHandler.js\"\nimport { EntityRestClient } from \"../rest/EntityRestClient.js\"\nimport { InterWindowEventFacadeSendDispatcher } from \"../../../native/common/generatedipc/InterWindowEventFacadeSendDispatcher.js\"\nimport { SqlCipherFacade } from \"../../../native/common/generatedipc/SqlCipherFacade.js\"\nimport { FormattedQuery, SqlValue, TaggedSqlValue, untagSqlObject } from \"./SqlValue.js\"\nimport { AssociationType, Cardinality, Type as TypeId, ValueType } from \"../../common/EntityConstants.js\"\nimport { OutOfSyncError } from \"../../common/error/OutOfSyncError.js\"\nimport { sql, SqlFragment } from \"./Sql.js\"\n\n/**\n * this is the value of SQLITE_MAX_VARIABLE_NUMBER in sqlite3.c\n * it may change if the sqlite version is updated.\n * */\nconst MAX_SAFE_SQL_VARS = 32766\n\nfunction dateEncoder(data: Date, typ: string, options: EncodeOptions): TokenOrNestedTokens | null {\n\tconst time = data.getTime()\n\treturn [\n\t\t// https://datatracker.ietf.org/doc/rfc8943/\n\t\tnew Token(Type.tag, 100),\n\t\tnew Token(time < 0 ? Type.negint : Type.uint, time),\n\t]\n}\n\nfunction dateDecoder(bytes: number): Date {\n\treturn new Date(bytes)\n}\n\nexport const customTypeEncoders: { [typeName: string]: typeof dateEncoder } = Object.freeze({\n\tDate: dateEncoder,\n})\n\ntype TypeDecoder = (_: any) => any\nexport const customTypeDecoders: Array<TypeDecoder> = (() => {\n\tconst tags: Array<TypeDecoder> = []\n\ttags[100] = dateDecoder\n\treturn tags\n})()\n\n/**\n * For each of these keys we track the current version in the database.\n * The keys are different model versions (because we need to migrate the data with certain model version changes) and \"offline\" key which is used to track\n * migrations that are needed for other reasons e.g. if DB structure changes or if we need to invalidate some tables.\n */\nexport type VersionMetadataBaseKey = keyof typeof modelInfos | \"offline\"\n\ntype VersionMetadataEntries = {\n\t// Yes this is cursed, give me a break\n\t[P in VersionMetadataBaseKey as `${P}-version`]: number\n}\n\nexport interface OfflineDbMeta extends VersionMetadataEntries {\n\tlastUpdateTime: number\n\ttimeRangeDays: number\n}\n\nconst TableDefinitions = Object.freeze({\n\t// plus ownerGroup added in a migration\n\tlist_entities:\n\t\t\"type TEXT NOT NULL, listId TEXT NOT NULL, elementId TEXT NOT NULL, ownerGroup TEXT, entity BLOB NOT NULL, PRIMARY KEY (type, listId, elementId)\",\n\t// plus ownerGroup added in a migration\n\telement_entities: \"type TEXT NOT NULL, elementId TEXT NOT NULL, ownerGroup TEXT, entity BLOB NOT NULL, PRIMARY KEY (type, elementId)\",\n\tranges: \"type TEXT NOT NULL, listId TEXT NOT NULL, lower TEXT NOT NULL, upper TEXT NOT NULL, PRIMARY KEY (type, listId)\",\n\tlastUpdateBatchIdPerGroupId: \"groupId TEXT NOT NULL, batchId TEXT NOT NULL, PRIMARY KEY (groupId)\",\n\tmetadata: \"key TEXT NOT NULL, value BLOB, PRIMARY KEY (key)\",\n\tblob_element_entities:\n\t\t\"type TEXT NOT NULL, listId TEXT NOT NULL, elementId TEXT NOT NULL, ownerGroup TEXT, entity BLOB NOT NULL, PRIMARY KEY (type, listId, elementId)\",\n} as const)\n\ntype Range = { lower: Id; upper: Id }\n\nexport interface OfflineStorageInitArgs {\n\tuserId: Id\n\tdatabaseKey: Uint8Array\n\ttimeRangeDays: number | null\n\tforceNewDatabase: boolean\n}\n\nexport class OfflineStorage implements CacheStorage, ExposedCacheStorage {\n\tprivate customCacheHandler: CustomCacheHandlerMap | null = null\n\tprivate userId: Id | null = null\n\tprivate timeRangeDays: number | null = null\n\n\tconstructor(\n\t\tprivate readonly sqlCipherFacade: SqlCipherFacade,\n\t\tprivate readonly interWindowEventSender: InterWindowEventFacadeSendDispatcher,\n\t\tprivate readonly dateProvider: DateProvider,\n\t\tprivate readonly migrator: OfflineStorageMigrator,\n\t\tprivate readonly cleaner: OfflineStorageCleaner,\n\t) {\n\t\tassert(isOfflineStorageAvailable() || isTest(), \"Offline storage is not available.\")\n\t}\n\n\t/**\n\t * @return {boolean} whether the database was newly created or not\n\t */\n\tasync init({ userId, databaseKey, timeRangeDays, forceNewDatabase }: OfflineStorageInitArgs): Promise<boolean> {\n\t\tthis.userId = userId\n\t\tthis.timeRangeDays = timeRangeDays\n\t\tif (forceNewDatabase) {\n\t\t\tif (isDesktop()) {\n\t\t\t\tawait this.interWindowEventSender.localUserDataInvalidated(userId)\n\t\t\t}\n\t\t\tawait this.sqlCipherFacade.deleteDb(userId)\n\t\t}\n\t\t// We open database here, and it is closed in the native side when the window is closed or the page is reloaded\n\t\tawait this.sqlCipherFacade.openDb(userId, databaseKey)\n\t\tawait this.createTables()\n\n\t\ttry {\n\t\t\tawait this.migrator.migrate(this, this.sqlCipherFacade)\n\t\t} catch (e) {\n\t\t\tif (e instanceof OutOfSyncError) {\n\t\t\t\tconsole.warn(\"Offline db is out of sync!\", e)\n\t\t\t\tawait this.recreateDbFile(userId, databaseKey)\n\t\t\t\tawait this.migrator.migrate(this, this.sqlCipherFacade)\n\t\t\t} else {\n\t\t\t\tthrow e\n\t\t\t}\n\t\t}\n\t\t// if nothing is written here, it means it's a new database\n\t\treturn (await this.getLastUpdateTime()).type === \"never\"\n\t}\n\n\tprivate async recreateDbFile(userId: string, databaseKey: Uint8Array): Promise<void> {\n\t\tconsole.log(`recreating DB file for userId ${userId}`)\n\t\tawait this.sqlCipherFacade.closeDb()\n\t\tawait this.sqlCipherFacade.deleteDb(userId)\n\t\tawait this.sqlCipherFacade.openDb(userId, databaseKey)\n\t\tawait this.createTables()\n\t}\n\n\t/**\n\t * currently, we close DBs from the native side (mainly on things like reload and on android's onDestroy)\n\t */\n\tasync deinit() {\n\t\tthis.userId = null\n\t\tawait this.sqlCipherFacade.closeDb()\n\t}\n\n\tasync deleteIfExists(typeRef: TypeRef<SomeEntity>, listId: Id | null, elementId: Id): Promise<void> {\n\t\tconst type = getTypeId(typeRef)\n\t\tlet typeModel: TypeModel\n\t\ttypeModel = await resolveTypeReference(typeRef)\n\t\telementId = ensureBase64Ext(typeModel, elementId)\n\t\tlet formattedQuery\n\t\tswitch (typeModel.type) {\n\t\t\tcase TypeId.Element:\n\t\t\t\tformattedQuery = sql`DELETE\n\t\t\t\t\t\t\t\t\t FROM element_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t   AND elementId = ${elementId}`\n\t\t\t\tbreak\n\t\t\tcase TypeId.ListElement:\n\t\t\t\tformattedQuery = sql`DELETE\n\t\t\t\t\t\t\t\t\t FROM list_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t   AND listId = ${listId}\n\t\t\t\t\t\t\t\t\t   AND elementId = ${elementId}`\n\t\t\t\tbreak\n\t\t\tcase TypeId.BlobElement:\n\t\t\t\tformattedQuery = sql`DELETE\n\t\t\t\t\t\t\t\t\t FROM blob_element_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t   AND listId = ${listId}\n\t\t\t\t\t\t\t\t\t   AND elementId = ${elementId}`\n\t\t\t\tbreak\n\t\t\tdefault:\n\t\t\t\tthrow new Error(\"must be a persistent type\")\n\t\t}\n\t\tawait this.sqlCipherFacade.run(formattedQuery.query, formattedQuery.params)\n\t}\n\n\tasync deleteAllOfType(typeRef: TypeRef<SomeEntity>): Promise<void> {\n\t\tconst type = getTypeId(typeRef)\n\t\tlet typeModel: TypeModel\n\t\ttypeModel = await resolveTypeReference(typeRef)\n\t\tlet formattedQuery\n\t\tswitch (typeModel.type) {\n\t\t\tcase TypeId.Element:\n\t\t\t\tformattedQuery = sql`DELETE\n\t\t\t\t\t\t\t\t\t FROM element_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}`\n\t\t\t\tbreak\n\t\t\tcase TypeId.ListElement:\n\t\t\t\tformattedQuery = sql`DELETE\n\t\t\t\t\t\t\t\t\t FROM list_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}`\n\t\t\t\tawait this.sqlCipherFacade.run(formattedQuery.query, formattedQuery.params)\n\t\t\t\tawait this.deleteAllRangesForType(type)\n\t\t\t\treturn\n\t\t\tcase TypeId.BlobElement:\n\t\t\t\tformattedQuery = sql`DELETE\n\t\t\t\t\t\t\t\t\t FROM blob_element_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}`\n\t\t\t\tbreak\n\t\t\tdefault:\n\t\t\t\tthrow new Error(\"must be a persistent type\")\n\t\t}\n\t\tawait this.sqlCipherFacade.run(formattedQuery.query, formattedQuery.params)\n\t}\n\n\tprivate async deleteAllRangesForType(type: string): Promise<void> {\n\t\tconst { query, params } = sql`DELETE\n\t\t\t\t\t\t\t\t\t  FROM ranges\n\t\t\t\t\t\t\t\t\t  WHERE type = ${type}`\n\t\tawait this.sqlCipherFacade.run(query, params)\n\t}\n\n\tasync get<T extends SomeEntity>(typeRef: TypeRef<T>, listId: Id | null, elementId: Id): Promise<T | null> {\n\t\tconst type = getTypeId(typeRef)\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\telementId = ensureBase64Ext(typeModel, elementId)\n\t\tlet formattedQuery\n\t\tswitch (typeModel.type) {\n\t\t\tcase TypeId.Element:\n\t\t\t\tformattedQuery = sql`SELECT entity\n\t\t\t\t\t\t\t\t\t from element_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t   AND elementId = ${elementId}`\n\t\t\t\tbreak\n\t\t\tcase TypeId.ListElement:\n\t\t\t\tformattedQuery = sql`SELECT entity\n\t\t\t\t\t\t\t\t\t from list_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t   AND listId = ${listId}\n\t\t\t\t\t\t\t\t\t   AND elementId = ${elementId}`\n\t\t\t\tbreak\n\t\t\tcase TypeId.BlobElement:\n\t\t\t\tformattedQuery = sql`SELECT entity\n\t\t\t\t\t\t\t\t\t from blob_element_entities\n\t\t\t\t\t\t\t\t\t WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t   AND listId = ${listId}\n\t\t\t\t\t\t\t\t\t   AND elementId = ${elementId}`\n\t\t\t\tbreak\n\t\t\tdefault:\n\t\t\t\tthrow new Error(\"must be a persistent type\")\n\t\t}\n\t\tconst result = await this.sqlCipherFacade.get(formattedQuery.query, formattedQuery.params)\n\t\treturn result?.entity ? await this.deserialize(typeRef, result.entity.value as Uint8Array) : null\n\t}\n\n\tasync provideMultiple<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, elementIds: Id[]): Promise<Array<T>> {\n\t\tif (elementIds.length === 0) return []\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\telementIds = elementIds.map((el) => ensureBase64Ext(typeModel, el))\n\n\t\tconst type = getTypeId(typeRef)\n\t\tconst serializedList: ReadonlyArray<Record<string, TaggedSqlValue>> = await this.allChunked(\n\t\t\tMAX_SAFE_SQL_VARS - 2,\n\t\t\telementIds,\n\t\t\t(c) => sql`SELECT entity\n\t\t\t\t\t   FROM list_entities\n\t\t\t\t\t   WHERE type = ${type}\n\t\t\t\t\t\t AND listId = ${listId}\n\t\t\t\t\t\t AND elementId IN ${paramList(c)}`,\n\t\t)\n\t\treturn await this.deserializeList(\n\t\t\ttypeRef,\n\t\t\tserializedList.map((r) => r.entity.value as Uint8Array),\n\t\t)\n\t}\n\n\tasync getIdsInRange<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id): Promise<Array<Id>> {\n\t\tconst type = getTypeId(typeRef)\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\tconst range = await this.getRange(typeRef, listId)\n\t\tif (range == null) {\n\t\t\tthrow new Error(`no range exists for ${type} and list ${listId}`)\n\t\t}\n\t\tconst { query, params } = sql`SELECT elementId\n\t\t\t\t\t\t\t\t\t  FROM list_entities\n\t\t\t\t\t\t\t\t\t  WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t\tAND listId = ${listId}\n\t\t\t\t\t\t\t\t\t\tAND (elementId = ${range.lower}\n\t\t\t\t\t\t\t\t\t\t  OR ${firstIdBigger(\"elementId\", range.lower)})\n\t\t\t\t\t\t\t\t\t\tAND NOT (${firstIdBigger(\"elementId\", range.upper)})`\n\t\tconst rows = await this.sqlCipherFacade.all(query, params)\n\t\treturn rows.map((row) => customIdToBase64Url(typeModel, row.elementId.value as string))\n\t}\n\n\t/** don't use this internally in this class, use OfflineStorage::getRange instead. OfflineStorage is\n\t * using converted custom IDs internally which is undone when using this to access the range.\n\t */\n\tasync getRangeForList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id): Promise<Range | null> {\n\t\tlet range = await this.getRange(typeRef, listId)\n\t\tif (range == null) return range\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\treturn {\n\t\t\tlower: customIdToBase64Url(typeModel, range.lower),\n\t\t\tupper: customIdToBase64Url(typeModel, range.upper),\n\t\t}\n\t}\n\n\tasync isElementIdInCacheRange<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, elementId: Id): Promise<boolean> {\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\telementId = ensureBase64Ext(typeModel, elementId)\n\n\t\tconst range = await this.getRange(typeRef, listId)\n\t\treturn range != null && !firstBiggerThanSecond(elementId, range.upper) && !firstBiggerThanSecond(range.lower, elementId)\n\t}\n\n\tasync provideFromRange<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, start: Id, count: number, reverse: boolean): Promise<T[]> {\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\tstart = ensureBase64Ext(typeModel, start)\n\t\tconst type = getTypeId(typeRef)\n\t\tlet formattedQuery\n\t\tif (reverse) {\n\t\t\tformattedQuery = sql`SELECT entity\n\t\t\t\t\t\t\t\t FROM list_entities\n\t\t\t\t\t\t\t\t WHERE type = ${type}\n\t\t\t\t\t\t\t\t   AND listId = ${listId}\n\t\t\t\t\t\t\t\t   AND ${firstIdBigger(start, \"elementId\")}\n\t\t\t\t\t\t\t\t ORDER BY LENGTH(elementId) DESC, elementId DESC LIMIT ${count}`\n\t\t} else {\n\t\t\tformattedQuery = sql`SELECT entity\n\t\t\t\t\t\t\t\t FROM list_entities\n\t\t\t\t\t\t\t\t WHERE type = ${type}\n\t\t\t\t\t\t\t\t   AND listId = ${listId}\n\t\t\t\t\t\t\t\t   AND ${firstIdBigger(\"elementId\", start)}\n\t\t\t\t\t\t\t\t ORDER BY LENGTH(elementId) ASC, elementId ASC LIMIT ${count}`\n\t\t}\n\t\tconst { query, params } = formattedQuery\n\t\tconst serializedList: ReadonlyArray<Record<string, TaggedSqlValue>> = await this.sqlCipherFacade.all(query, params)\n\t\treturn await this.deserializeList(\n\t\t\ttypeRef,\n\t\t\tserializedList.map((r) => r.entity.value as Uint8Array),\n\t\t)\n\t}\n\n\tasync put(originalEntity: SomeEntity): Promise<void> {\n\t\tconst serializedEntity = this.serialize(originalEntity)\n\t\tlet { listId, elementId } = expandId(originalEntity._id)\n\t\tconst type = getTypeId(originalEntity._type)\n\t\tconst ownerGroup = originalEntity._ownerGroup\n\t\tconst typeModel = await resolveTypeReference(originalEntity._type)\n\t\telementId = ensureBase64Ext(typeModel, elementId)\n\t\tlet formattedQuery: FormattedQuery\n\t\tswitch (typeModel.type) {\n\t\t\tcase TypeId.Element:\n\t\t\t\tformattedQuery = sql`INSERT\n\t\t\t\tOR REPLACE INTO element_entities (type, elementId, ownerGroup, entity) VALUES (\n\t\t\t\t${type},\n\t\t\t\t${elementId},\n\t\t\t\t${ownerGroup},\n\t\t\t\t${serializedEntity}\n\t\t\t\t)`\n\t\t\t\tbreak\n\t\t\tcase TypeId.ListElement:\n\t\t\t\tformattedQuery = sql`INSERT\n\t\t\t\tOR REPLACE INTO list_entities (type, listId, elementId, ownerGroup, entity) VALUES (\n\t\t\t\t${type},\n\t\t\t\t${listId},\n\t\t\t\t${elementId},\n\t\t\t\t${ownerGroup},\n\t\t\t\t${serializedEntity}\n\t\t\t\t)`\n\t\t\t\tbreak\n\t\t\tcase TypeId.BlobElement:\n\t\t\t\tformattedQuery = sql`INSERT\n\t\t\t\tOR REPLACE INTO blob_element_entities (type, listId, elementId, ownerGroup, entity) VALUES (\n\t\t\t\t${type},\n\t\t\t\t${listId},\n\t\t\t\t${elementId},\n\t\t\t\t${ownerGroup},\n\t\t\t\t${serializedEntity}\n\t\t\t\t)`\n\t\t\t\tbreak\n\t\t\tdefault:\n\t\t\t\tthrow new Error(\"must be a persistent type\")\n\t\t}\n\t\tawait this.sqlCipherFacade.run(formattedQuery.query, formattedQuery.params)\n\t}\n\n\tasync setLowerRangeForList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, lowerId: Id): Promise<void> {\n\t\tlowerId = ensureBase64Ext(await resolveTypeReference(typeRef), lowerId)\n\t\tconst type = getTypeId(typeRef)\n\t\tconst { query, params } = sql`UPDATE ranges\n\t\t\t\t\t\t\t\t\t  SET lower = ${lowerId}\n\t\t\t\t\t\t\t\t\t  WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t\tAND listId = ${listId}`\n\t\tawait this.sqlCipherFacade.run(query, params)\n\t}\n\n\tasync setUpperRangeForList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, upperId: Id): Promise<void> {\n\t\tupperId = ensureBase64Ext(await resolveTypeReference(typeRef), upperId)\n\t\tconst type = getTypeId(typeRef)\n\t\tconst { query, params } = sql`UPDATE ranges\n\t\t\t\t\t\t\t\t\t  SET upper = ${upperId}\n\t\t\t\t\t\t\t\t\t  WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t\tAND listId = ${listId}`\n\t\tawait this.sqlCipherFacade.run(query, params)\n\t}\n\n\tasync setNewRangeForList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, lower: Id, upper: Id): Promise<void> {\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\tlower = ensureBase64Ext(typeModel, lower)\n\t\tupper = ensureBase64Ext(typeModel, upper)\n\n\t\tconst type = getTypeId(typeRef)\n\t\tconst { query, params } = sql`INSERT\n\t\tOR REPLACE INTO ranges VALUES (\n\t\t${type},\n\t\t${listId},\n\t\t${lower},\n\t\t${upper}\n\t\t)`\n\t\treturn this.sqlCipherFacade.run(query, params)\n\t}\n\n\tasync getLastBatchIdForGroup(groupId: Id): Promise<Id | null> {\n\t\tconst { query, params } = sql`SELECT batchId\n\t\t\t\t\t\t\t\t\t  from lastUpdateBatchIdPerGroupId\n\t\t\t\t\t\t\t\t\t  WHERE groupId = ${groupId}`\n\t\tconst row = (await this.sqlCipherFacade.get(query, params)) as { batchId: TaggedSqlValue } | null\n\t\treturn (row?.batchId?.value ?? null) as Id | null\n\t}\n\n\tasync putLastBatchIdForGroup(groupId: Id, batchId: Id): Promise<void> {\n\t\tconst { query, params } = sql`INSERT\n\t\tOR REPLACE INTO lastUpdateBatchIdPerGroupId VALUES (\n\t\t${groupId},\n\t\t${batchId}\n\t\t)`\n\t\tawait this.sqlCipherFacade.run(query, params)\n\t}\n\n\tasync getLastUpdateTime(): Promise<LastUpdateTime> {\n\t\tconst time = await this.getMetadata(\"lastUpdateTime\")\n\t\treturn time ? { type: \"recorded\", time } : { type: \"never\" }\n\t}\n\n\tasync putLastUpdateTime(ms: number): Promise<void> {\n\t\tawait this.putMetadata(\"lastUpdateTime\", ms)\n\t}\n\n\tasync purgeStorage(): Promise<void> {\n\t\tfor (let name of Object.keys(TableDefinitions)) {\n\t\t\tawait this.sqlCipherFacade.run(\n\t\t\t\t`DELETE\n\t\t\t\t FROM ${name}`,\n\t\t\t\t[],\n\t\t\t)\n\t\t}\n\t}\n\n\tasync deleteRange(typeRef: TypeRef<unknown>, listId: string): Promise<void> {\n\t\tconst { query, params } = sql`DELETE\n\t\t\t\t\t\t\t\t\t  FROM ranges\n\t\t\t\t\t\t\t\t\t  WHERE type = ${getTypeId(typeRef)}\n\t\t\t\t\t\t\t\t\t\tAND listId = ${listId}`\n\t\tawait this.sqlCipherFacade.run(query, params)\n\t}\n\n\tasync getRawListElementsOfType(typeRef: TypeRef<ListElementEntity>): Promise<Array<ListElementEntity>> {\n\t\tconst { query, params } = sql`SELECT entity\n\t\t\t\t\t\t\t\t\t  from list_entities\n\t\t\t\t\t\t\t\t\t  WHERE type = ${getTypeId(typeRef)}`\n\t\tconst items = (await this.sqlCipherFacade.all(query, params)) ?? []\n\t\treturn items.map((item) => this.decodeCborEntity(item.entity.value as Uint8Array) as Record<string, unknown> & ListElementEntity)\n\t}\n\n\tasync getRawElementsOfType(typeRef: TypeRef<ElementEntity>): Promise<Array<ElementEntity>> {\n\t\tconst { query, params } = sql`SELECT entity\n\t\t\t\t\t\t\t\t\t  from element_entities\n\t\t\t\t\t\t\t\t\t  WHERE type = ${getTypeId(typeRef)}`\n\t\tconst items = (await this.sqlCipherFacade.all(query, params)) ?? []\n\t\treturn items.map((item) => this.decodeCborEntity(item.entity.value as Uint8Array) as Record<string, unknown> & ElementEntity)\n\t}\n\n\tasync getElementsOfType<T extends ElementEntity>(typeRef: TypeRef<T>): Promise<Array<T>> {\n\t\tconst { query, params } = sql`SELECT entity\n\t\t\t\t\t\t\t\t\t  from element_entities\n\t\t\t\t\t\t\t\t\t  WHERE type = ${getTypeId(typeRef)}`\n\t\tconst items = (await this.sqlCipherFacade.all(query, params)) ?? []\n\t\treturn await this.deserializeList(\n\t\t\ttypeRef,\n\t\t\titems.map((row) => row.entity.value as Uint8Array),\n\t\t)\n\t}\n\n\tasync getWholeList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id): Promise<Array<T>> {\n\t\tconst { query, params } = sql`SELECT entity\n\t\t\t\t\t\t\t\t\t  FROM list_entities\n\t\t\t\t\t\t\t\t\t  WHERE type = ${getTypeId(typeRef)}\n\t\t\t\t\t\t\t\t\t\tAND listId = ${listId}`\n\t\tconst items = (await this.sqlCipherFacade.all(query, params)) ?? []\n\t\treturn await this.deserializeList(\n\t\t\ttypeRef,\n\t\t\titems.map((row) => row.entity.value as Uint8Array),\n\t\t)\n\t}\n\n\tasync dumpMetadata(): Promise<Partial<OfflineDbMeta>> {\n\t\tconst query = \"SELECT * from metadata\"\n\t\tconst stored = (await this.sqlCipherFacade.all(query, [])).map((row) => [row.key.value as string, row.value.value as Uint8Array] as const)\n\t\treturn Object.fromEntries(stored.map(([key, value]) => [key, cborg.decode(value)])) as OfflineDbMeta\n\t}\n\n\tasync setStoredModelVersion(model: VersionMetadataBaseKey, version: number) {\n\t\treturn this.putMetadata(`${model}-version`, version)\n\t}\n\n\tgetCustomCacheHandlerMap(entityRestClient: EntityRestClient): CustomCacheHandlerMap {\n\t\tif (this.customCacheHandler == null) {\n\t\t\tthis.customCacheHandler = new CustomCacheHandlerMap(\n\t\t\t\t{\n\t\t\t\t\tref: CalendarEventTypeRef,\n\t\t\t\t\thandler: new CustomCalendarEventCacheHandler(entityRestClient),\n\t\t\t\t},\n\t\t\t\t{ ref: MailTypeRef, handler: new CustomMailEventCacheHandler() },\n\t\t\t)\n\t\t}\n\t\treturn this.customCacheHandler\n\t}\n\n\tgetUserId(): Id {\n\t\treturn assertNotNull(this.userId, \"No user id, not initialized?\")\n\t}\n\n\tasync deleteAllOwnedBy(owner: Id): Promise<void> {\n\t\t{\n\t\t\tconst { query, params } = sql`DELETE\n\t\t\t\t\t\t\t\t\t\t  FROM element_entities\n\t\t\t\t\t\t\t\t\t\t  WHERE ownerGroup = ${owner}`\n\t\t\tawait this.sqlCipherFacade.run(query, params)\n\t\t}\n\t\t{\n\t\t\t// first, check which list Ids contain entities owned by the lost group\n\t\t\tconst { query, params } = sql`SELECT listId, type\n\t\t\t\t\t\t\t\t\t\t  FROM list_entities\n\t\t\t\t\t\t\t\t\t\t  WHERE ownerGroup = ${owner}`\n\t\t\tconst rangeRows = await this.sqlCipherFacade.all(query, params)\n\t\t\tconst rows = rangeRows.map((row) => untagSqlObject(row) as { listId: string; type: string })\n\t\t\tconst listIdsByType: Map<string, Set<Id>> = groupByAndMapUniquely(\n\t\t\t\trows,\n\t\t\t\t(row) => row.type,\n\t\t\t\t(row) => row.listId,\n\t\t\t)\n\t\t\t// delete the ranges for those listIds\n\t\t\tfor (const [type, listIds] of listIdsByType.entries()) {\n\t\t\t\t// this particular query uses one other SQL var for the type.\n\t\t\t\tconst safeChunkSize = MAX_SAFE_SQL_VARS - 1\n\t\t\t\tconst listIdArr = Array.from(listIds)\n\t\t\t\tawait this.runChunked(\n\t\t\t\t\tsafeChunkSize,\n\t\t\t\t\tlistIdArr,\n\t\t\t\t\t(c) => sql`DELETE\n\t\t\t\t\t\t\t   FROM ranges\n\t\t\t\t\t\t\t   WHERE type = ${type}\n\t\t\t\t\t\t\t\t AND listId IN ${paramList(c)}`,\n\t\t\t\t)\n\t\t\t\tawait this.runChunked(\n\t\t\t\t\tsafeChunkSize,\n\t\t\t\t\tlistIdArr,\n\t\t\t\t\t(c) => sql`DELETE\n\t\t\t\t\t\t\t   FROM list_entities\n\t\t\t\t\t\t\t   WHERE type = ${type}\n\t\t\t\t\t\t\t\t AND listId IN ${paramList(c)}`,\n\t\t\t\t)\n\t\t\t}\n\t\t}\n\t\t{\n\t\t\tconst { query, params } = sql`DELETE\n\t\t\t\t\t\t\t\t\t\t  FROM blob_element_entities\n\t\t\t\t\t\t\t\t\t\t  WHERE ownerGroup = ${owner}`\n\t\t\tawait this.sqlCipherFacade.run(query, params)\n\t\t}\n\t\t{\n\t\t\tconst { query, params } = sql`DELETE\n\t\t\t\t\t\t\t\t\t\t  FROM lastUpdateBatchIdPerGroupId\n\t\t\t\t\t\t\t\t\t\t  WHERE groupId = ${owner}`\n\t\t\tawait this.sqlCipherFacade.run(query, params)\n\t\t}\n\t}\n\n\tasync deleteWholeList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id): Promise<void> {\n\t\tawait this.lockRangesDbAccess(listId)\n\t\tawait this.deleteRange(typeRef, listId)\n\t\tconst { query, params } = sql`DELETE\n\t\t\t\t\t\t\t\t\t  FROM list_entities\n\t\t\t\t\t\t\t\t\t  WHERE listId = ${listId}`\n\t\tawait this.sqlCipherFacade.run(query, params)\n\t\tawait this.unlockRangesDbAccess(listId)\n\t}\n\n\tprivate async putMetadata<K extends keyof OfflineDbMeta>(key: K, value: OfflineDbMeta[K]): Promise<void> {\n\t\tlet encodedValue\n\t\ttry {\n\t\t\tencodedValue = cborg.encode(value)\n\t\t} catch (e) {\n\t\t\tconsole.log(\"[OfflineStorage] failed to encode metadata for key\", key, \"with value\", value)\n\t\t\tthrow e\n\t\t}\n\t\tconst { query, params } = sql`INSERT\n\t\tOR REPLACE INTO metadata VALUES (\n\t\t${key},\n\t\t${encodedValue}\n\t\t)`\n\t\tawait this.sqlCipherFacade.run(query, params)\n\t}\n\n\tprivate async getMetadata<K extends keyof OfflineDbMeta>(key: K): Promise<OfflineDbMeta[K] | null> {\n\t\tconst { query, params } = sql`SELECT value\n\t\t\t\t\t\t\t\t\t  from metadata\n\t\t\t\t\t\t\t\t\t  WHERE key = ${key}`\n\t\tconst encoded = await this.sqlCipherFacade.get(query, params)\n\t\treturn encoded && cborg.decode(encoded.value.value as Uint8Array)\n\t}\n\n\t/**\n\t * Clear out unneeded data from the offline database (i.e. trash and spam lists, old data).\n\t * This will be called after login (CachePostLoginActions.ts) to ensure fast login time.\n\t * @param timeRangeDays: the maximum age of days that mails should be to be kept in the database. if null, will use a default value\n\t * @param userId id of the current user. default, last stored userId\n\t */\n\tasync clearExcludedData(timeRangeDays: number | null = this.timeRangeDays, userId: Id = this.getUserId()): Promise<void> {\n\t\tawait this.cleaner.cleanOfflineDb(this, timeRangeDays, userId, this.dateProvider.now())\n\t}\n\n\tprivate async createTables() {\n\t\tfor (let [name, definition] of Object.entries(TableDefinitions)) {\n\t\t\tawait this.sqlCipherFacade.run(\n\t\t\t\t`CREATE TABLE IF NOT EXISTS ${name}\n\t\t\t\t (\n\t\t\t\t\t ${definition}\n\t\t\t\t )`,\n\t\t\t\t[],\n\t\t\t)\n\t\t}\n\t}\n\n\tasync getRange(typeRef: TypeRef<ElementEntity | ListElementEntity>, listId: Id): Promise<Range | null> {\n\t\tconst type = getTypeId(typeRef)\n\t\tconst { query, params } = sql`SELECT upper, lower\n\t\t\t\t\t\t\t\t\t  FROM ranges\n\t\t\t\t\t\t\t\t\t  WHERE type = ${type}\n\t\t\t\t\t\t\t\t\t\tAND listId = ${listId}`\n\t\tconst row = (await this.sqlCipherFacade.get(query, params)) ?? null\n\n\t\treturn mapNullable(row, untagSqlObject) as Range | null\n\t}\n\n\tasync deleteIn(typeRef: TypeRef<unknown>, listId: Id | null, elementIds: Id[]): Promise<void> {\n\t\tif (elementIds.length === 0) return\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\tswitch (typeModel.type) {\n\t\t\tcase TypeId.Element:\n\t\t\t\treturn await this.runChunked(\n\t\t\t\t\tMAX_SAFE_SQL_VARS - 1,\n\t\t\t\t\telementIds,\n\t\t\t\t\t(c) => sql`DELETE\n\t\t\t\t\t\t\t   FROM element_entities\n\t\t\t\t\t\t\t   WHERE type = ${getTypeId(typeRef)}\n\t\t\t\t\t\t\t\t AND elementId IN ${paramList(c)}`,\n\t\t\t\t)\n\t\t\tcase TypeId.ListElement:\n\t\t\t\treturn await this.runChunked(\n\t\t\t\t\tMAX_SAFE_SQL_VARS - 2,\n\t\t\t\t\telementIds,\n\t\t\t\t\t(c) => sql`DELETE\n\t\t\t\t\t\t\t   FROM list_entities\n\t\t\t\t\t\t\t   WHERE type = ${getTypeId(typeRef)}\n\t\t\t\t\t\t\t\t AND listId = ${listId}\n\t\t\t\t\t\t\t\t AND elementId IN ${paramList(c)}`,\n\t\t\t\t)\n\t\t\tcase TypeId.BlobElement:\n\t\t\t\treturn await this.runChunked(\n\t\t\t\t\tMAX_SAFE_SQL_VARS - 2,\n\t\t\t\t\telementIds,\n\t\t\t\t\t(c) => sql`DELETE\n\t\t\t\t\t\t\t   FROM blob_element_entities\n\t\t\t\t\t\t\t   WHERE type = ${getTypeId(typeRef)}\n\t\t\t\t\t\t\t\t AND listId = ${listId}\n\t\t\t\t\t\t\t\t AND elementId IN ${paramList(c)}`,\n\t\t\t\t)\n\t\t\tdefault:\n\t\t\t\tthrow new Error(\"must be a persistent type\")\n\t\t}\n\t}\n\n\t/**\n\t * We want to lock the access to the \"ranges\" db when updating / reading the\n\t * offline available mail list / mailset ranges for each mail list (referenced using the listId).\n\t * @param listId the mail list or mail set entry list that we want to lock\n\t */\n\tasync lockRangesDbAccess(listId: Id) {\n\t\tawait this.sqlCipherFacade.lockRangesDbAccess(listId)\n\t}\n\n\t/**\n\t * This is the counterpart to the function \"lockRangesDbAccess(listId)\".\n\t * @param listId the mail list that we want to unlock\n\t */\n\tasync unlockRangesDbAccess(listId: Id) {\n\t\tawait this.sqlCipherFacade.unlockRangesDbAccess(listId)\n\t}\n\n\tasync updateRangeForListAndDeleteObsoleteData<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, rawCutoffId: Id): Promise<void> {\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\tconst isCustomId = isCustomIdType(typeModel)\n\t\tconst convertedCutoffId = ensureBase64Ext(typeModel, rawCutoffId)\n\n\t\tconst range = await this.getRange(typeRef, listId)\n\t\tif (range == null) {\n\t\t\treturn\n\t\t}\n\n\t\t// If the range for a given list is complete from the beginning (starts at GENERATED_MIN_ID), then we only want to actually modify the\n\t\t// saved range if we would be removing elements from the list, in order to not lose the information that the range is complete in storage.\n\t\t// So we have to check how old the oldest element in said range is. If it is newer than cutoffId, then we will not modify the range,\n\t\t// otherwise we will just modify it normally\n\t\tconst expectedMinId = isCustomId ? CUSTOM_MIN_ID : GENERATED_MIN_ID\n\t\tif (range.lower === expectedMinId) {\n\t\t\tconst entities = await this.provideFromRange(typeRef, listId, expectedMinId, 1, false)\n\t\t\tconst id = mapNullable(entities[0], getElementId)\n\t\t\tconst rangeWontBeModified = id == null || firstBiggerThanSecond(id, convertedCutoffId) || id === convertedCutoffId\n\t\t\tif (rangeWontBeModified) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tif (firstBiggerThanSecond(convertedCutoffId, range.lower)) {\n\t\t\t// If the upper id of the range is below the cutoff, then the entire range will be deleted from the storage\n\t\t\t// so we just delete the range as well\n\t\t\t// Otherwise, we only want to modify\n\t\t\tif (firstBiggerThanSecond(convertedCutoffId, range.upper)) {\n\t\t\t\tawait this.deleteRange(typeRef, listId)\n\t\t\t} else {\n\t\t\t\tawait this.setLowerRangeForList(typeRef, listId, rawCutoffId)\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate serialize(originalEntity: SomeEntity): Uint8Array {\n\t\ttry {\n\t\t\treturn cborg.encode(originalEntity, { typeEncoders: customTypeEncoders })\n\t\t} catch (e) {\n\t\t\tconsole.log(\"[OfflineStorage] failed to encode entity of type\", originalEntity._type, \"with id\", originalEntity._id)\n\t\t\tthrow e\n\t\t}\n\t}\n\n\t/**\n\t * Convert the type from CBOR representation to the runtime type\n\t */\n\tprivate async deserialize<T extends SomeEntity>(typeRef: TypeRef<T>, loaded: Uint8Array): Promise<T | null> {\n\t\tlet deserialized\n\t\ttry {\n\t\t\tdeserialized = this.decodeCborEntity(loaded)\n\t\t} catch (e) {\n\t\t\tconsole.log(e)\n\t\t\tconsole.log(`Error with CBOR decode. Trying to decode (of type: ${typeof loaded}): ${loaded}`)\n\t\t\treturn null\n\t\t}\n\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\treturn (await this.fixupTypeRefs(typeModel, deserialized)) as T\n\t}\n\n\tprivate decodeCborEntity(loaded: Uint8Array): Record<string, unknown> {\n\t\treturn cborg.decode(loaded, { tags: customTypeDecoders })\n\t}\n\n\tprivate async fixupTypeRefs(typeModel: TypeModel, deserialized: any): Promise<unknown> {\n\t\t// TypeRef cannot be deserialized back automatically. We could write a codec for it but we don't actually need to store it so we just \"patch\" it.\n\t\t// Some places rely on TypeRef being a class and not a plain object.\n\t\t// We also have to update all aggregates, recursively.\n\t\tdeserialized._type = new TypeRef(typeModel.app, typeModel.name)\n\t\tfor (const [associationName, associationModel] of Object.entries(typeModel.associations)) {\n\t\t\tif (associationModel.type === AssociationType.Aggregation) {\n\t\t\t\tconst aggregateTypeRef = new TypeRef(associationModel.dependency ?? typeModel.app, associationModel.refType)\n\t\t\t\tconst aggregateTypeModel = await resolveTypeReference(aggregateTypeRef)\n\t\t\t\tswitch (associationModel.cardinality) {\n\t\t\t\t\tcase Cardinality.One:\n\t\t\t\t\tcase Cardinality.ZeroOrOne: {\n\t\t\t\t\t\tconst aggregate = deserialized[associationName]\n\t\t\t\t\t\tif (aggregate) {\n\t\t\t\t\t\t\tawait this.fixupTypeRefs(aggregateTypeModel, aggregate)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t\tcase Cardinality.Any: {\n\t\t\t\t\t\tconst aggregateList = deserialized[associationName]\n\t\t\t\t\t\tfor (const aggregate of aggregateList) {\n\t\t\t\t\t\t\tawait this.fixupTypeRefs(aggregateTypeModel, aggregate)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn deserialized\n\t}\n\n\tprivate async deserializeList<T extends SomeEntity>(typeRef: TypeRef<T>, loaded: Array<Uint8Array>): Promise<Array<T>> {\n\t\t// manually reimplementing promiseMap to make sure we don't hit the scheduler since there's nothing actually async happening\n\t\tconst result: Array<T> = []\n\t\tfor (const entity of loaded) {\n\t\t\tconst deserialized = await this.deserialize(typeRef, entity)\n\t\t\tif (deserialized != null) {\n\t\t\t\tresult.push(deserialized)\n\t\t\t}\n\t\t}\n\t\treturn result\n\t}\n\n\t/**\n\t * convenience method to run a potentially too large query over several chunks.\n\t * chunkSize must be chosen such that the total number of SQL variables in the final query does not exceed MAX_SAFE_SQL_VARS\n\t * */\n\tprivate async runChunked(chunkSize: number, originalList: SqlValue[], formatter: (chunk: SqlValue[]) => FormattedQuery): Promise<void> {\n\t\tfor (const chunk of splitInChunks(chunkSize, originalList)) {\n\t\t\tconst formattedQuery = formatter(chunk)\n\t\t\tawait this.sqlCipherFacade.run(formattedQuery.query, formattedQuery.params)\n\t\t}\n\t}\n\n\t/**\n\t * convenience method to execute a potentially too large query over several chunks.\n\t * chunkSize must be chosen such that the total number of SQL variables in the final query does not exceed MAX_SAFE_SQL_VARS\n\t * */\n\tprivate async allChunked(\n\t\tchunkSize: number,\n\t\toriginalList: SqlValue[],\n\t\tformatter: (chunk: SqlValue[]) => FormattedQuery,\n\t): Promise<Array<Record<string, TaggedSqlValue>>> {\n\t\tconst result: Array<Record<string, TaggedSqlValue>> = []\n\t\tfor (const chunk of splitInChunks(chunkSize, originalList)) {\n\t\t\tconst formattedQuery = formatter(chunk)\n\t\t\tresult.push(...(await this.sqlCipherFacade.all(formattedQuery.query, formattedQuery.params)))\n\t\t}\n\t\treturn result\n\t}\n}\n\n/*\n * used to automatically create the right amount of SQL variables for selecting ids from a dynamic list.\n * must be used within sql`<query>` template string to inline the logic into the query.\n *\n * It is very important that params is kept to a size such that the total amount of SQL variables is\n * less than MAX_SAFE_SQL_VARS.\n */\nfunction paramList(params: SqlValue[]): SqlFragment {\n\tconst qs = params.map(() => \"?\").join(\",\")\n\treturn new SqlFragment(`(${qs})`, params)\n}\n\n/**\n * comparison to select ids that are bigger or smaller than a parameter id\n * must be used within sql`<query>` template string to inline the logic into the query.\n *\n * will always insert 3 constants and 3 SQL variables into the query.\n */\nfunction firstIdBigger(...args: [string, \"elementId\"] | [\"elementId\", string]): SqlFragment {\n\tlet [l, r]: [string, string] = args\n\tlet v\n\tif (l === \"elementId\") {\n\t\tv = r\n\t\tr = \"?\"\n\t} else {\n\t\tv = l\n\t\tl = \"?\"\n\t}\n\treturn new SqlFragment(`(CASE WHEN length(${l}) > length(${r}) THEN 1 WHEN length(${l}) < length(${r}) THEN 0 ELSE ${l} > ${r} END)`, [v, v, v])\n}\n\nexport function isCustomIdType(typeModel: TypeModel): boolean {\n\treturn typeModel.values._id.type === ValueType.CustomId\n}\n\n/**\n * We store customIds as base64ext in the db to make them sortable, but we get them as base64url from the server.\n */\nexport function ensureBase64Ext(typeModel: TypeModel, elementId: Id): Id {\n\tif (isCustomIdType(typeModel)) {\n\t\treturn base64ToBase64Ext(base64UrlToBase64(elementId))\n\t}\n\treturn elementId\n}\n\nexport function customIdToBase64Url(typeModel: TypeModel, elementId: Id): Id {\n\tif (isCustomIdType(typeModel)) {\n\t\treturn base64ToBase64Url(base64ExtToBase64(elementId))\n\t}\n\treturn elementId\n}\n\nexport interface OfflineStorageCleaner {\n\tcleanOfflineDb(offlineStorage: OfflineStorage, timeRangeDays: number | null, userId: Id, now: number): Promise<void>\n}\n","import {\n\tCacheMode,\n\tEntityRestClient,\n\tEntityRestClientEraseOptions,\n\tEntityRestClientLoadOptions,\n\tEntityRestClientSetupOptions,\n\tEntityRestInterface,\n\tgetCacheModeBehavior,\n\tOwnerEncSessionKeyProvider,\n} from \"./EntityRestClient\"\nimport { resolveTypeReference } from \"../../common/EntityFunctions\"\nimport { OperationType } from \"../../common/TutanotaConstants\"\nimport { assertNotNull, difference, getFirstOrThrow, getTypeId, groupBy, isEmpty, isSameTypeRef, lastThrow, TypeRef } from \"@tutao/tutanota-utils\"\nimport {\n\tAuditLogEntryTypeRef,\n\tBucketPermissionTypeRef,\n\tEntityEventBatchTypeRef,\n\tEntityUpdate,\n\tGroupKeyTypeRef,\n\tKeyRotationTypeRef,\n\tPermissionTypeRef,\n\tRecoverCodeTypeRef,\n\tRejectedSenderTypeRef,\n\tSecondFactorTypeRef,\n\tSessionTypeRef,\n\tUser,\n\tUserGroupKeyDistributionTypeRef,\n\tUserGroupRootTypeRef,\n\tUserTypeRef,\n} from \"../../entities/sys/TypeRefs.js\"\nimport { ValueType } from \"../../common/EntityConstants.js\"\nimport { NotAuthorizedError, NotFoundError } from \"../../common/error/RestError\"\nimport {\n\tCalendarEventUidIndexTypeRef,\n\tMail,\n\tMailDetailsBlobTypeRef,\n\tMailFolderTypeRef,\n\tMailSetEntryTypeRef,\n\tMailTypeRef,\n} from \"../../entities/tutanota/TypeRefs.js\"\nimport { CUSTOM_MAX_ID, CUSTOM_MIN_ID, firstBiggerThanSecond, GENERATED_MAX_ID, GENERATED_MIN_ID, getElementId, isSameId } from \"../../common/utils/EntityUtils\"\nimport { ProgrammingError } from \"../../common/error/ProgrammingError\"\nimport { assertWorkerOrNode } from \"../../common/Env\"\nimport type { ListElementEntity, SomeEntity, TypeModel } from \"../../common/EntityTypes\"\nimport { QueuedBatch } from \"../EventQueue.js\"\nimport { ENTITY_EVENT_BATCH_EXPIRE_MS } from \"../EventBusClient\"\nimport { CustomCacheHandlerMap } from \"./CustomCacheHandler.js\"\nimport { containsEventOfType, EntityUpdateData, getEventOfType } from \"../../common/utils/EntityUpdateUtils.js\"\nimport { isCustomIdType } from \"../offline/OfflineStorage.js\"\n\nassertWorkerOrNode()\n\n/**\n *\n * The minimum size of a range request when extending an existing range\n * Because we extend by making (potentially) many range requests until we reach the startId\n * We want to avoid that the requests are too small\n */\nexport const EXTEND_RANGE_MIN_CHUNK_SIZE = 40\nconst IGNORED_TYPES = [\n\tEntityEventBatchTypeRef,\n\tPermissionTypeRef,\n\tBucketPermissionTypeRef,\n\tSessionTypeRef,\n\tSecondFactorTypeRef,\n\tRecoverCodeTypeRef,\n\tRejectedSenderTypeRef,\n\t// when doing automatic calendar updates, we will miss uid index entity updates if we're using the cache.\n\t// this is mainly caused by some calendaring apps sending the same update multiple times in the same mail.\n\t// the earliest place where we could deduplicate would be in entityEventsReceived on the calendarModel.\n\tCalendarEventUidIndexTypeRef,\n\tKeyRotationTypeRef,\n\tUserGroupRootTypeRef,\n\tUserGroupKeyDistributionTypeRef,\n\tAuditLogEntryTypeRef, // Should not be part of cached data because there are errors inside entity event processing after rotating the admin group key\n] as const\n\n/**\n * List of types containing a customId that we want to explicitly enable caching for.\n * CustomId types are not cached by default because their id is using base64UrlEncoding while GeneratedUId types are using base64Ext encoding.\n * base64Url encoding results in a different sort order of elements that we have on the server, this is problematic for caching LET and their ranges.\n * When enabling caching for customId types we convert the id that we store in cache from base64Url to base64Ext so we have the same sort order. (see function\n * OfflineStorage.ensureBase64Ext). In theory, we can try to enable caching for all types but as of now we enable it for a limited amount of types because there\n * are other ways to cache customId types (see implementation of CustomCacheHandler)\n */\nconst CACHEABLE_CUSTOMID_TYPES = [MailSetEntryTypeRef, GroupKeyTypeRef] as const\n\nexport interface EntityRestCache extends EntityRestInterface {\n\t/**\n\t * Clear out the contents of the cache.\n\t */\n\tpurgeStorage(): Promise<void>\n\n\t/**\n\t * Get the batch id of the most recently processed batch for the given group.\n\t */\n\tgetLastEntityEventBatchForGroup(groupId: Id): Promise<Id | null>\n\n\t/**\n\t * Saved tha batch id of the most recently processed batch manually.\n\t *\n\t * Is needed when the cache is new but we want to make sure that the next time we will download from this moment, even if we don't receive any events.\n\t */\n\tsetLastEntityEventBatchForGroup(groupId: Id, batchId: Id): Promise<void>\n\n\t/**\n\t * Persist the last time client downloaded event batches. This is not the last *processed* item, merely when things were *downloaded*. We use it to\n\t * detect out-of-sync.\n\t */\n\trecordSyncTime(): Promise<void>\n\n\t/**\n\t * Fetch the time since last time we downloaded event batches.\n\t */\n\ttimeSinceLastSyncMs(): Promise<number | null>\n\n\t/**\n\t * Detect if out of sync based on stored \"lastUpdateTime\" and the current server time\n\t */\n\tisOutOfSync(): Promise<boolean>\n}\n\nexport type Range = { lower: Id; upper: Id }\n\nexport type LastUpdateTime = { type: \"recorded\"; time: number } | { type: \"never\" } | { type: \"uninitialized\" }\n\n/**\n * Part of the cache storage only with subset of CacheStorage functionality\n *\n * Separate from the rest of the cache as a narrow interface to not expose the whole storage for cases where we want to only get the cached part of the list to\n * display it even if we can't load the full page from the server or need some metadata.\n *\n * also exposes functions to repair an outdated cache in case we can't access the server without getting a new version of a cached entity\n * (mainly password changes)\n */\nexport interface ExposedCacheStorage {\n\tget<T extends SomeEntity>(typeRef: TypeRef<T>, listId: Id | null, id: Id): Promise<T | null>\n\n\t/**\n\t * Load range of entities. Does not include {@param start}.\n\t * If {@param reverse} is false then returns entities newer than {@param start} in ascending order sorted by\n\t * elementId.\n\t * If {@param reverse} is true then returns entities older than {@param start} in descending order sorted by\n\t * elementId.\n\t */\n\tprovideFromRange<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, start: Id, count: number, reverse: boolean): Promise<T[]>\n\n\t/**\n\t * Load a set of list element entities by id. Missing elements are not returned, no error is thrown.\n\t */\n\tprovideMultiple<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, elementIds: Id[]): Promise<Array<T>>\n\n\t/**\n\t * retrieve all list elements that are in the cache\n\t * @param typeRef\n\t * @param listId\n\t */\n\tgetWholeList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id): Promise<Array<T>>\n\n\tgetLastUpdateTime(): Promise<LastUpdateTime>\n\n\tclearExcludedData(): Promise<void>\n\n\t/**\n\t * remove an ElementEntity from the cache by typeRef and Id.\n\t * the exposed interface is intentionally more narrow than the internal cacheStorage because\n\t * we must maintain the integrity of our list ranges.\n\t * */\n\tdeleteIfExists<T extends SomeEntity>(typeRef: TypeRef<T>, listId: Id | null, id: Id): Promise<void>\n\n\t/** delete all instances of the given type that share {@param listId}. also deletes the range of that list. */\n\tdeleteWholeList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id): Promise<void>\n}\n\nexport interface CacheStorage extends ExposedCacheStorage {\n\t/**\n\t * Get a given entity from the cache, expects that you have already checked for existence\n\t */\n\tget<T extends SomeEntity>(typeRef: TypeRef<T>, listId: Id | null, id: Id): Promise<T | null>\n\n\t/**\n\t * get a map with cache handlers for the customId types this storage implementation supports\n\t * customId types that don't have a custom handler don't get served from the cache\n\t */\n\tgetCustomCacheHandlerMap(entityRestClient: EntityRestClient): CustomCacheHandlerMap\n\n\tisElementIdInCacheRange<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, id: Id): Promise<boolean>\n\n\tput(originalEntity: SomeEntity): Promise<void>\n\n\tgetRangeForList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id): Promise<Range | null>\n\n\tsetUpperRangeForList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, id: Id): Promise<void>\n\n\tsetLowerRangeForList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, id: Id): Promise<void>\n\n\t/**\n\t * Creates a new list cache if there is none. Resets everything but elements.\n\t * @param typeRef\n\t * @param listId\n\t * @param lower\n\t * @param upper\n\t */\n\tsetNewRangeForList<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, lower: Id, upper: Id): Promise<void>\n\n\tgetIdsInRange<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id): Promise<Array<Id>>\n\n\t/**\n\t * Persist the last processed batch for a given group id.\n\t */\n\tputLastBatchIdForGroup(groupId: Id, batchId: Id): Promise<void>\n\n\t/**\n\t * Retrieve the least processed batch id for a given group.\n\t */\n\tgetLastBatchIdForGroup(groupId: Id): Promise<Id | null>\n\n\tdeleteIfExists<T extends SomeEntity>(typeRef: TypeRef<T>, listId: Id | null, id: Id): Promise<void>\n\n\tpurgeStorage(): Promise<void>\n\n\tputLastUpdateTime(value: number): Promise<void>\n\n\tgetUserId(): Id\n\n\tdeleteAllOwnedBy(owner: Id): Promise<void>\n\n\t/**\n\t * We want to lock the access to the \"ranges\" db when updating / reading the\n\t * offline available mail list ranges for each mail list (referenced using the listId)\n\t * @param listId the mail list that we want to lock\n\t */\n\tlockRangesDbAccess(listId: Id): Promise<void>\n\n\t/**\n\t * This is the counterpart to the function \"lockRangesDbAccess(listId)\"\n\t * @param listId the mail list that we want to unlock\n\t */\n\tunlockRangesDbAccess(listId: Id): Promise<void>\n}\n\n/**\n * This implementation provides a caching mechanism to the rest chain.\n * It forwards requests to the entity rest client.\n * The cache works as follows:\n * If a read from the target fails, the request fails.\n * If a read from the target is successful, the cache is written and the element returned.\n * For LETs the cache stores one range per list id. if a range is requested starting in the stored range or at the range ends the missing elements are loaded from the server.\n * Only ranges with elements with generated ids are stored in the cache. Custom id elements are only stored as single element currently. If needed this has to be extended for ranges.\n * Range requests starting outside the stored range are only allowed if the direction is away from the stored range. In this case we load from the range end to avoid gaps in the stored range.\n * Requests for creating or updating elements are always forwarded and not directly stored in the cache.\n * On EventBusClient notifications updated elements are stored in the cache if the element already exists in the cache.\n * On EventBusClient notifications new elements are only stored in the cache if they are LETs and in the stored range.\n * On EventBusClient notifications deleted elements are removed from the cache.\n *\n * Range handling:\n * |          <|>        c d e f g h i j k      <|>             |\n * MIN_ID  lowerRangeId     ids in range    upperRangeId    MAX_ID\n * lowerRangeId may be anything from MIN_ID to c, upperRangeId may be anything from k to MAX_ID\n */\nexport class DefaultEntityRestCache implements EntityRestCache {\n\tconstructor(private readonly entityRestClient: EntityRestClient, private readonly storage: CacheStorage) {}\n\n\tasync load<T extends SomeEntity>(typeRef: TypeRef<T>, id: PropertyType<T, \"_id\">, opts: EntityRestClientLoadOptions = {}): Promise<T> {\n\t\tconst useCache = await this.shouldUseCache(typeRef, opts)\n\t\tif (!useCache) {\n\t\t\treturn await this.entityRestClient.load(typeRef, id, opts)\n\t\t}\n\n\t\tconst { listId, elementId } = expandId(id)\n\t\tconst cachingBehavior = getCacheModeBehavior(opts.cacheMode)\n\t\tconst cachedEntity = cachingBehavior.readsFromCache ? await this.storage.get(typeRef, listId, elementId) : null\n\n\t\tif (cachedEntity == null) {\n\t\t\tconst entity = await this.entityRestClient.load(typeRef, id, opts)\n\t\t\tif (cachingBehavior.writesToCache) {\n\t\t\t\tawait this.storage.put(entity)\n\t\t\t}\n\t\t\treturn entity\n\t\t}\n\n\t\treturn cachedEntity\n\t}\n\n\tasync loadMultiple<T extends SomeEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id | null,\n\t\tids: Array<Id>,\n\t\townerEncSessionKeyProvider?: OwnerEncSessionKeyProvider,\n\t\topts: EntityRestClientLoadOptions = {},\n\t): Promise<Array<T>> {\n\t\tconst useCache = await this.shouldUseCache(typeRef, opts)\n\t\tif (!useCache) {\n\t\t\treturn await this.entityRestClient.loadMultiple(typeRef, listId, ids, ownerEncSessionKeyProvider, opts)\n\t\t}\n\t\treturn await this._loadMultiple(typeRef, listId, ids, ownerEncSessionKeyProvider, opts)\n\t}\n\n\tsetup<T extends SomeEntity>(listId: Id | null, instance: T, extraHeaders?: Dict, options?: EntityRestClientSetupOptions): Promise<Id> {\n\t\treturn this.entityRestClient.setup(listId, instance, extraHeaders, options)\n\t}\n\n\tsetupMultiple<T extends SomeEntity>(listId: Id | null, instances: Array<T>): Promise<Array<Id>> {\n\t\treturn this.entityRestClient.setupMultiple(listId, instances)\n\t}\n\n\tupdate<T extends SomeEntity>(instance: T): Promise<void> {\n\t\treturn this.entityRestClient.update(instance)\n\t}\n\n\terase<T extends SomeEntity>(instance: T, options?: EntityRestClientEraseOptions): Promise<void> {\n\t\treturn this.entityRestClient.erase(instance, options)\n\t}\n\n\tgetLastEntityEventBatchForGroup(groupId: Id): Promise<Id | null> {\n\t\treturn this.storage.getLastBatchIdForGroup(groupId)\n\t}\n\n\tsetLastEntityEventBatchForGroup(groupId: Id, batchId: Id): Promise<void> {\n\t\treturn this.storage.putLastBatchIdForGroup(groupId, batchId)\n\t}\n\n\tpurgeStorage(): Promise<void> {\n\t\tconsole.log(\"Purging the user's offline database\")\n\t\treturn this.storage.purgeStorage()\n\t}\n\n\tasync isOutOfSync(): Promise<boolean> {\n\t\tconst timeSinceLastSync = await this.timeSinceLastSyncMs()\n\t\treturn timeSinceLastSync != null && timeSinceLastSync > ENTITY_EVENT_BATCH_EXPIRE_MS\n\t}\n\n\tasync recordSyncTime(): Promise<void> {\n\t\tconst timestamp = this.getServerTimestampMs()\n\t\tawait this.storage.putLastUpdateTime(timestamp)\n\t}\n\n\tasync timeSinceLastSyncMs(): Promise<number | null> {\n\t\tconst lastUpdate = await this.storage.getLastUpdateTime()\n\t\tlet lastUpdateTime: number\n\t\tswitch (lastUpdate.type) {\n\t\t\tcase \"recorded\":\n\t\t\t\tlastUpdateTime = lastUpdate.time\n\t\t\t\tbreak\n\t\t\tcase \"never\":\n\t\t\t\treturn null\n\t\t\tcase \"uninitialized\":\n\t\t\t\tthrow new ProgrammingError(\"Offline storage is not initialized\")\n\t\t}\n\t\tconst now = this.getServerTimestampMs()\n\t\treturn now - lastUpdateTime\n\t}\n\n\tprivate getServerTimestampMs(): number {\n\t\treturn this.entityRestClient.getRestClient().getServerTimestampMs()\n\t}\n\n\t/**\n\t * Delete a cached entity. Sometimes this is necessary to do to ensure you always load the new version\n\t */\n\tdeleteFromCacheIfExists<T extends SomeEntity>(typeRef: TypeRef<T>, listId: Id | null, elementId: Id): Promise<void> {\n\t\treturn this.storage.deleteIfExists(typeRef, listId, elementId)\n\t}\n\n\tprivate async _loadMultiple<T extends SomeEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id | null,\n\t\tids: Array<Id>,\n\t\townerEncSessionKeyProvider?: OwnerEncSessionKeyProvider,\n\t\topts: EntityRestClientLoadOptions = {},\n\t): Promise<Array<T>> {\n\t\tconst cachingBehavior = getCacheModeBehavior(opts.cacheMode)\n\t\tconst entitiesInCache: T[] = []\n\n\t\tlet idsToLoad: Id[]\n\t\tif (cachingBehavior.readsFromCache) {\n\t\t\tidsToLoad = []\n\t\t\tfor (const id of ids) {\n\t\t\t\tconst cachedEntity = await this.storage.get(typeRef, listId, id)\n\t\t\t\tif (cachedEntity != null) {\n\t\t\t\t\tentitiesInCache.push(cachedEntity)\n\t\t\t\t} else {\n\t\t\t\t\tidsToLoad.push(id)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tidsToLoad = ids\n\t\t}\n\n\t\tif (idsToLoad.length > 0) {\n\t\t\tconst entitiesFromServer = await this.entityRestClient.loadMultiple(typeRef, listId, idsToLoad, ownerEncSessionKeyProvider, opts)\n\t\t\tif (cachingBehavior.writesToCache) {\n\t\t\t\tfor (const entity of entitiesFromServer) {\n\t\t\t\t\tawait this.storage.put(entity)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn entitiesFromServer.concat(entitiesInCache)\n\t\t} else {\n\t\t\treturn entitiesInCache\n\t\t}\n\t}\n\n\tasync loadRange<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tstart: Id,\n\t\tcount: number,\n\t\treverse: boolean,\n\t\topts: EntityRestClientLoadOptions = {},\n\t): Promise<T[]> {\n\t\tconst customHandler = this.storage.getCustomCacheHandlerMap(this.entityRestClient).get(typeRef)\n\t\tif (customHandler && customHandler.loadRange) {\n\t\t\treturn await customHandler.loadRange(this.storage, listId, start, count, reverse)\n\t\t}\n\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\tconst useCache = (await this.shouldUseCache(typeRef, opts)) && isCachedRangeType(typeModel, typeRef)\n\n\t\tif (!useCache) {\n\t\t\treturn await this.entityRestClient.loadRange(typeRef, listId, start, count, reverse, opts)\n\t\t}\n\n\t\tconst behavior = getCacheModeBehavior(opts.cacheMode)\n\t\tif (!behavior.readsFromCache) {\n\t\t\tthrow new ProgrammingError(\"cannot write to cache without reading with range requests\")\n\t\t}\n\n\t\t// We lock access to the \"ranges\" db here in order to prevent race conditions when accessing the ranges database.\n\t\tawait this.storage.lockRangesDbAccess(listId)\n\n\t\ttry {\n\t\t\tconst range = await this.storage.getRangeForList(typeRef, listId)\n\n\t\t\tif (behavior.writesToCache) {\n\t\t\t\tif (range == null) {\n\t\t\t\t\tawait this.populateNewListWithRange(typeRef, listId, start, count, reverse, opts)\n\t\t\t\t} else if (isStartIdWithinRange(range, start, typeModel)) {\n\t\t\t\t\tawait this.extendFromWithinRange(typeRef, listId, start, count, reverse, opts)\n\t\t\t\t} else if (isRangeRequestAwayFromExistingRange(range, reverse, start, typeModel)) {\n\t\t\t\t\tawait this.extendAwayFromRange(typeRef, listId, start, count, reverse, opts)\n\t\t\t\t} else {\n\t\t\t\t\tawait this.extendTowardsRange(typeRef, listId, start, count, reverse, opts)\n\t\t\t\t}\n\t\t\t\treturn await this.storage.provideFromRange(typeRef, listId, start, count, reverse)\n\t\t\t} else {\n\t\t\t\tif (range && isStartIdWithinRange(range, start, typeModel)) {\n\t\t\t\t\tconst provided = await this.storage.provideFromRange(typeRef, listId, start, count, reverse)\n\t\t\t\t\tconst { newStart, newCount } = await this.recalculateRangeRequest(typeRef, listId, start, count, reverse)\n\t\t\t\t\tconst newElements = newCount > 0 ? await this.entityRestClient.loadRange(typeRef, listId, newStart, newCount, reverse) : []\n\t\t\t\t\treturn provided.concat(newElements)\n\t\t\t\t} else {\n\t\t\t\t\t// Since our starting ID is not in our range, we can't use the cache because we don't know exactly what\n\t\t\t\t\t// elements are missing.\n\t\t\t\t\t//\n\t\t\t\t\t// This can result in us re-retrieving elements we already have. Since we anyway must do a request,\n\t\t\t\t\t// this is fine.\n\t\t\t\t\treturn await this.entityRestClient.loadRange(typeRef, listId, start, count, reverse, opts)\n\t\t\t\t}\n\t\t\t}\n\t\t} finally {\n\t\t\t// We unlock access to the \"ranges\" db here. We lock it in order to prevent race conditions when accessing the \"ranges\" database.\n\t\t\tawait this.storage.unlockRangesDbAccess(listId)\n\t\t}\n\t}\n\n\t/**\n\t * Creates a new list range, reading everything from the server that it can\n\t * range:         (none)\n\t * request:       *--------->\n\t * range becomes: |---------|\n\t * @private\n\t */\n\tprivate async populateNewListWithRange<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tstart: Id,\n\t\tcount: number,\n\t\treverse: boolean,\n\t\topts: EntityRestClientLoadOptions,\n\t) {\n\t\t// Create a new range and load everything\n\t\tconst entities = await this.entityRestClient.loadRange(typeRef, listId, start, count, reverse, opts)\n\n\t\t// Initialize a new range for this list\n\t\tawait this.storage.setNewRangeForList(typeRef, listId, start, start)\n\n\t\t// The range bounds will be updated in here\n\t\tawait this.updateRangeInStorage(typeRef, listId, count, reverse, entities)\n\t}\n\n\t/**\n\t * Returns part of a request from the cache, and the remainder is loaded from the server\n\t * range:          |---------|\n\t * request:             *-------------->\n\t * range becomes: |--------------------|\n\t */\n\tprivate async extendFromWithinRange<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tstart: Id,\n\t\tcount: number,\n\t\treverse: boolean,\n\t\topts: EntityRestClientLoadOptions,\n\t) {\n\t\tconst { newStart, newCount } = await this.recalculateRangeRequest(typeRef, listId, start, count, reverse)\n\t\tif (newCount > 0) {\n\t\t\t// We will be able to provide some entities from the cache, so we just want to load the remaining entities from the server\n\t\t\tconst entities = await this.entityRestClient.loadRange(typeRef, listId, newStart, newCount, reverse, opts)\n\t\t\tawait this.updateRangeInStorage(typeRef, listId, newCount, reverse, entities)\n\t\t}\n\t}\n\n\t/**\n\t * Start was outside the range, and we are loading away from the range\n\t * Keeps loading elements from the end of the range in the direction of the startId.\n\t * Returns once all available elements have been loaded or the requested number is in cache\n\t * range:          |---------|\n\t * request:                     *------->\n\t * range becomes:  |--------------------|\n\t */\n\tprivate async extendAwayFromRange<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tstart: Id,\n\t\tcount: number,\n\t\treverse: boolean,\n\t\topts: EntityRestClientLoadOptions,\n\t) {\n\t\t// Start is outside the range, and we are loading away from the range, so we grow until we are able to provide enough\n\t\t// entities starting at startId\n\t\twhile (true) {\n\t\t\tconst range = assertNotNull(await this.storage.getRangeForList(typeRef, listId))\n\n\t\t\t// Which end of the range to start loading from\n\t\t\tconst loadStartId = reverse ? range.lower : range.upper\n\n\t\t\tconst requestCount = Math.max(count, EXTEND_RANGE_MIN_CHUNK_SIZE)\n\n\t\t\t// Load some entities\n\t\t\tconst entities = await this.entityRestClient.loadRange(typeRef, listId, loadStartId, requestCount, reverse, opts)\n\t\t\tawait this.updateRangeInStorage(typeRef, listId, requestCount, reverse, entities)\n\n\t\t\t// If we exhausted the entities from the server\n\t\t\tif (entities.length < requestCount) {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Try to get enough entities from cache\n\t\t\tconst entitiesFromCache = await this.storage.provideFromRange(typeRef, listId, start, count, reverse)\n\n\t\t\t// If cache is now capable of providing the whole request\n\t\t\tif (entitiesFromCache.length === count) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Loads all elements from the startId in the direction of the range\n\t * Once complete, returns as many elements as it can from the original request\n\t * range:         |---------|\n\t * request:                     <------*\n\t * range becomes: |--------------------|\n\t * or\n\t * range:              |---------|\n\t * request:       <-------------------*\n\t * range becomes: |--------------------|\n\t */\n\tprivate async extendTowardsRange<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tstart: Id,\n\t\tcount: number,\n\t\treverse: boolean,\n\t\topts: EntityRestClientLoadOptions,\n\t) {\n\t\twhile (true) {\n\t\t\tconst range = assertNotNull(await this.storage.getRangeForList(typeRef, listId))\n\n\t\t\tconst loadStartId = reverse ? range.upper : range.lower\n\n\t\t\tconst requestCount = Math.max(count, EXTEND_RANGE_MIN_CHUNK_SIZE)\n\n\t\t\tconst entities = await this.entityRestClient.loadRange(typeRef, listId, loadStartId, requestCount, !reverse, opts)\n\n\t\t\tawait this.updateRangeInStorage(typeRef, listId, requestCount, !reverse, entities)\n\n\t\t\t// The call to `updateRangeInStorage` will have set the range bounds to GENERATED_MIN_ID/GENERATED_MAX_ID\n\t\t\t// in the case that we have exhausted all elements from the server, so if that happens, we will also end up breaking here\n\t\t\tif (await this.storage.isElementIdInCacheRange(typeRef, listId, start)) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tawait this.extendFromWithinRange(typeRef, listId, start, count, reverse, opts)\n\t}\n\n\t/**\n\t * Given the parameters and result of a range request,\n\t * Inserts the result into storage, and updates the range bounds\n\t * based on number of entities requested and the actual amount that were received\n\t */\n\tprivate async updateRangeInStorage<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tcountRequested: number,\n\t\twasReverseRequest: boolean,\n\t\treceivedEntities: T[],\n\t) {\n\t\tconst isCustomId = isCustomIdType(await resolveTypeReference(typeRef))\n\t\tlet elementsToAdd = receivedEntities\n\t\tif (wasReverseRequest) {\n\t\t\t// Ensure that elements are cached in ascending (not reverse) order\n\t\t\telementsToAdd = receivedEntities.reverse()\n\t\t\tif (receivedEntities.length < countRequested) {\n\t\t\t\tconsole.log(\"finished loading, setting min id\")\n\t\t\t\tawait this.storage.setLowerRangeForList(typeRef, listId, isCustomId ? CUSTOM_MIN_ID : GENERATED_MIN_ID)\n\t\t\t} else {\n\t\t\t\t// After reversing the list the first element in the list is the lower range limit\n\t\t\t\tawait this.storage.setLowerRangeForList(typeRef, listId, getElementId(getFirstOrThrow(receivedEntities)))\n\t\t\t}\n\t\t} else {\n\t\t\t// Last element in the list is the upper range limit\n\t\t\tif (receivedEntities.length < countRequested) {\n\t\t\t\t// all elements have been loaded, so the upper range must be set to MAX_ID\n\t\t\t\tconsole.log(\"finished loading, setting max id\")\n\t\t\t\tawait this.storage.setUpperRangeForList(typeRef, listId, isCustomId ? CUSTOM_MAX_ID : GENERATED_MAX_ID)\n\t\t\t} else {\n\t\t\t\tawait this.storage.setUpperRangeForList(typeRef, listId, getElementId(lastThrow(receivedEntities)))\n\t\t\t}\n\t\t}\n\n\t\tawait Promise.all(elementsToAdd.map((element) => this.storage.put(element)))\n\t}\n\n\t/**\n\t * Calculates the new start value for the getElementRange request and the number of elements to read in\n\t * order to read no duplicate values.\n\t * @return returns the new start and count value. Important: count can be negative if everything is cached\n\t */\n\tprivate async recalculateRangeRequest<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tstart: Id,\n\t\tcount: number,\n\t\treverse: boolean,\n\t): Promise<{ newStart: string; newCount: number }> {\n\t\tlet allRangeList = await this.storage.getIdsInRange(typeRef, listId)\n\t\tlet elementsToRead = count\n\t\tlet startElementId = start\n\t\tconst range = await this.storage.getRangeForList(typeRef, listId)\n\t\tif (range == null) {\n\t\t\treturn { newStart: start, newCount: count }\n\t\t}\n\t\tconst { lower, upper } = range\n\t\tlet indexOfStart = allRangeList.indexOf(start)\n\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\t\tconst isCustomId = isCustomIdType(typeModel)\n\t\tif (\n\t\t\t(!reverse && (isCustomId ? upper === CUSTOM_MAX_ID : upper === GENERATED_MAX_ID)) ||\n\t\t\t(reverse && (isCustomId ? lower === CUSTOM_MIN_ID : lower === GENERATED_MIN_ID))\n\t\t) {\n\t\t\t// we have already loaded the complete range in the desired direction, so we do not have to load from server\n\t\t\telementsToRead = 0\n\t\t} else if (allRangeList.length === 0) {\n\t\t\t// Element range is empty, so read all elements\n\t\t\telementsToRead = count\n\t\t} else if (indexOfStart !== -1) {\n\t\t\t// Start element is located in allRange read only elements that are not in allRange.\n\t\t\tif (reverse) {\n\t\t\t\telementsToRead = count - indexOfStart\n\t\t\t\tstartElementId = allRangeList[0] // use the lowest id in allRange as start element\n\t\t\t} else {\n\t\t\t\telementsToRead = count - (allRangeList.length - 1 - indexOfStart)\n\t\t\t\tstartElementId = allRangeList[allRangeList.length - 1] // use the  highest id in allRange as start element\n\t\t\t}\n\t\t} else if (lower === start || (firstBiggerThanSecond(start, lower, typeModel) && firstBiggerThanSecond(allRangeList[0], start, typeModel))) {\n\t\t\t// Start element is not in allRange but has been used has start element for a range request, eg. EntityRestInterface.GENERATED_MIN_ID, or start is between lower range id and lowest element in range\n\t\t\tif (!reverse) {\n\t\t\t\t// if not reverse read only elements that are not in allRange\n\t\t\t\tstartElementId = allRangeList[allRangeList.length - 1] // use the  highest id in allRange as start element\n\t\t\t\telementsToRead = count - allRangeList.length\n\t\t\t}\n\t\t\t// if reverse read all elements\n\t\t} else if (\n\t\t\tupper === start ||\n\t\t\t(firstBiggerThanSecond(start, allRangeList[allRangeList.length - 1], typeModel) && firstBiggerThanSecond(upper, start, typeModel))\n\t\t) {\n\t\t\t// Start element is not in allRange but has been used has start element for a range request, eg. EntityRestInterface.GENERATED_MAX_ID, or start is between upper range id and highest element in range\n\t\t\tif (reverse) {\n\t\t\t\t// if not reverse read only elements that are not in allRange\n\t\t\t\tstartElementId = allRangeList[0] // use the  highest id in allRange as start element\n\t\t\t\telementsToRead = count - allRangeList.length\n\t\t\t}\n\t\t\t// if not reverse read all elements\n\t\t}\n\t\treturn { newStart: startElementId, newCount: elementsToRead }\n\t}\n\n\t/**\n\t * Resolves when the entity is loaded from the server if necessary\n\t * @pre The last call of this function must be resolved. This is needed to avoid that e.g. while\n\t * loading a created instance from the server we receive an update of that instance and ignore it because the instance is not in the cache yet.\n\t *\n\t * @return Promise, which resolves to the array of valid events (if response is NotFound or NotAuthorized we filter it out)\n\t */\n\tasync entityEventsReceived(batch: QueuedBatch): Promise<Array<EntityUpdate>> {\n\t\tawait this.recordSyncTime()\n\n\t\t// we handle post multiple create operations separately to optimize the number of requests with getMultiple\n\t\tconst createUpdatesForLETs: EntityUpdate[] = []\n\t\tconst regularUpdates: EntityUpdate[] = [] // all updates not resulting from post multiple requests\n\t\tconst updatesArray = batch.events\n\t\tfor (const update of updatesArray) {\n\t\t\tconst typeRef = new TypeRef(update.application, update.type)\n\n\t\t\t// monitor application is ignored\n\t\t\tif (update.application === \"monitor\") continue\n\t\t\t// mails are ignored because move operations are handled as a special event (and no post multiple is possible)\n\t\t\tif (update.operation === OperationType.CREATE && getUpdateInstanceId(update).instanceListId != null && !isSameTypeRef(typeRef, MailTypeRef)) {\n\t\t\t\tcreateUpdatesForLETs.push(update)\n\t\t\t} else {\n\t\t\t\tregularUpdates.push(update)\n\t\t\t\tawait this.checkForMailSetMigration(typeRef, update)\n\t\t\t}\n\t\t}\n\n\t\tconst createUpdatesForLETsPerList = groupBy(createUpdatesForLETs, (update) => update.instanceListId)\n\n\t\tconst postMultipleEventUpdates: EntityUpdate[][] = []\n\t\t// we first handle potential post multiple updates in get multiple requests\n\t\tfor (let [instanceListId, updates] of createUpdatesForLETsPerList) {\n\t\t\tconst firstUpdate = updates[0]\n\t\t\tconst typeRef = new TypeRef<ListElementEntity>(firstUpdate.application, firstUpdate.type)\n\t\t\tconst ids = updates.map((update) => update.instanceId)\n\n\t\t\t// We only want to load the instances that are in cache range\n\t\t\tconst customHandler = this.storage.getCustomCacheHandlerMap(this.entityRestClient).get(typeRef)\n\t\t\tconst idsInCacheRange =\n\t\t\t\tcustomHandler && customHandler.getElementIdsInCacheRange\n\t\t\t\t\t? await customHandler.getElementIdsInCacheRange(this.storage, instanceListId, ids)\n\t\t\t\t\t: await this.getElementIdsInCacheRange(typeRef, instanceListId, ids)\n\n\t\t\tif (idsInCacheRange.length === 0) {\n\t\t\t\tpostMultipleEventUpdates.push(updates)\n\t\t\t} else {\n\t\t\t\tconst updatesNotInCacheRange =\n\t\t\t\t\tidsInCacheRange.length === updates.length ? [] : updates.filter((update) => !idsInCacheRange.includes(update.instanceId))\n\n\t\t\t\ttry {\n\t\t\t\t\t// loadMultiple is only called to cache the elements and check which ones return errors\n\t\t\t\t\tconst returnedInstances = await this._loadMultiple(typeRef, instanceListId, idsInCacheRange, undefined, { cacheMode: CacheMode.WriteOnly })\n\t\t\t\t\t//We do not want to pass updates that caused an error\n\t\t\t\t\tif (returnedInstances.length !== idsInCacheRange.length) {\n\t\t\t\t\t\tconst returnedIds = returnedInstances.map((instance) => getElementId(instance))\n\t\t\t\t\t\tpostMultipleEventUpdates.push(updates.filter((update) => returnedIds.includes(update.instanceId)).concat(updatesNotInCacheRange))\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpostMultipleEventUpdates.push(updates)\n\t\t\t\t\t}\n\t\t\t\t} catch (e) {\n\t\t\t\t\tif (e instanceof NotAuthorizedError) {\n\t\t\t\t\t\t// return updates that are not in cache Range if NotAuthorizedError (for those updates that are in cache range)\n\t\t\t\t\t\tpostMultipleEventUpdates.push(updatesNotInCacheRange)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tthrow e\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tconst otherEventUpdates: EntityUpdate[] = []\n\t\tfor (let update of regularUpdates) {\n\t\t\tconst { operation, type, application } = update\n\t\t\tconst { instanceListId, instanceId } = getUpdateInstanceId(update)\n\t\t\tconst typeRef = new TypeRef<SomeEntity>(application, type)\n\n\t\t\tswitch (operation) {\n\t\t\t\tcase OperationType.UPDATE: {\n\t\t\t\t\tconst handledUpdate = await this.processUpdateEvent(typeRef, update)\n\t\t\t\t\tif (handledUpdate) {\n\t\t\t\t\t\totherEventUpdates.push(handledUpdate)\n\t\t\t\t\t}\n\t\t\t\t\tbreak // do break instead of continue to avoid ide warnings\n\t\t\t\t}\n\t\t\t\tcase OperationType.DELETE: {\n\t\t\t\t\tif (\n\t\t\t\t\t\tisSameTypeRef(MailTypeRef, typeRef) &&\n\t\t\t\t\t\tcontainsEventOfType(updatesArray as Readonly<EntityUpdateData[]>, OperationType.CREATE, instanceId)\n\t\t\t\t\t) {\n\t\t\t\t\t\t// move for mail is handled in create event.\n\t\t\t\t\t} else if (isSameTypeRef(MailTypeRef, typeRef)) {\n\t\t\t\t\t\t// delete mailDetails if they are available (as we don't send an event for this type)\n\t\t\t\t\t\tconst mail = await this.storage.get(MailTypeRef, instanceListId, instanceId)\n\t\t\t\t\t\tawait this.storage.deleteIfExists(typeRef, instanceListId, instanceId)\n\t\t\t\t\t\tif (mail?.mailDetails != null) {\n\t\t\t\t\t\t\tawait this.storage.deleteIfExists(MailDetailsBlobTypeRef, mail.mailDetails[0], mail.mailDetails[1])\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tawait this.storage.deleteIfExists(typeRef, instanceListId, instanceId)\n\t\t\t\t\t}\n\t\t\t\t\totherEventUpdates.push(update)\n\t\t\t\t\tbreak // do break instead of continue to avoid ide warnings\n\t\t\t\t}\n\t\t\t\tcase OperationType.CREATE: {\n\t\t\t\t\tconst handledUpdate = await this.processCreateEvent(typeRef, update, updatesArray)\n\t\t\t\t\tif (handledUpdate) {\n\t\t\t\t\t\totherEventUpdates.push(handledUpdate)\n\t\t\t\t\t}\n\t\t\t\t\tbreak // do break instead of continue to avoid ide warnings\n\t\t\t\t}\n\t\t\t\tdefault:\n\t\t\t\t\tthrow new ProgrammingError(\"Unknown operation type: \" + operation)\n\t\t\t}\n\t\t}\n\t\t// the whole batch has been written successfully\n\t\tawait this.storage.putLastBatchIdForGroup(batch.groupId, batch.batchId)\n\t\t// merge the results\n\t\treturn otherEventUpdates.concat(postMultipleEventUpdates.flat())\n\t}\n\n\t/** Returns {null} when the update should be skipped. */\n\tprivate async processCreateEvent(typeRef: TypeRef<any>, update: EntityUpdate, batch: ReadonlyArray<EntityUpdate>): Promise<EntityUpdate | null> {\n\t\t// do not return undefined to avoid implicit returns\n\t\tconst { instanceId, instanceListId } = getUpdateInstanceId(update)\n\n\t\t// We put new instances into cache only when it's a new instance in the cached range which is only for the list instances.\n\t\tif (instanceListId != null) {\n\t\t\tconst deleteEvent = getEventOfType(batch, OperationType.DELETE, instanceId)\n\n\t\t\tconst mail = deleteEvent && isSameTypeRef(MailTypeRef, typeRef) ? await this.storage.get(MailTypeRef, deleteEvent.instanceListId, instanceId) : null\n\t\t\t// avoid downloading new mail element for non-mailSet user.\n\t\t\t// can be removed once all mailbox have been migrated to mailSet (once lastNonOutdatedClientVersion is >= v242)\n\t\t\tif (deleteEvent != null && mail != null && isEmpty(mail.sets)) {\n\t\t\t\t// It is a move event for cached mail\n\t\t\t\tawait this.storage.deleteIfExists(typeRef, deleteEvent.instanceListId, instanceId)\n\t\t\t\tawait this.updateListIdOfMailAndUpdateCache(mail, instanceListId, instanceId)\n\t\t\t\treturn update\n\t\t\t} else {\n\t\t\t\t// If there is a custom handler we follow its decision.\n\t\t\t\t// Otherwise, we do a range check to see if we need to keep the range up-to-date.\n\t\t\t\tconst shouldLoad =\n\t\t\t\t\t(await this.storage.getCustomCacheHandlerMap(this.entityRestClient).get(typeRef)?.shouldLoadOnCreateEvent?.(update)) ??\n\t\t\t\t\t(await this.storage.isElementIdInCacheRange(typeRef, instanceListId, instanceId))\n\t\t\t\tif (shouldLoad) {\n\t\t\t\t\t// No need to try to download something that's not there anymore\n\t\t\t\t\t// We do not consult custom handlers here because they are only needed for list elements.\n\t\t\t\t\tconsole.log(\"downloading create event for\", getTypeId(typeRef), instanceListId, instanceId)\n\t\t\t\t\treturn this.entityRestClient\n\t\t\t\t\t\t.load(typeRef, [instanceListId, instanceId])\n\t\t\t\t\t\t.then((entity) => this.storage.put(entity))\n\t\t\t\t\t\t.then(() => update)\n\t\t\t\t\t\t.catch((e) => {\n\t\t\t\t\t\t\tif (isExpectedErrorForSynchronization(e)) {\n\t\t\t\t\t\t\t\treturn null\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tthrow e\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t})\n\t\t\t\t} else {\n\t\t\t\t\treturn update\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\treturn update\n\t\t}\n\t}\n\n\t/**\n\t * Updates the given mail with the new list id and add it to the cache.\n\t */\n\tprivate async updateListIdOfMailAndUpdateCache(mail: Mail, newListId: Id, elementId: Id) {\n\t\t// In case of a move operation we have to replace the list id always, as the mail is stored in another folder.\n\t\tmail._id = [newListId, elementId]\n\t\tif (mail.bucketKey != null) {\n\t\t\t// With the simplified permission system (MailDetails) we also have to update the bucketEncSessionKey for the mail,\n\t\t\t// which also references the mail list id. We need this for some cases when the move operation was executed\n\t\t\t// before the UpdateSessionKeyService has been executed, e.g. when using inbox rules.\n\t\t\t// The UpdateSessionKeyService would remove the bucketKey from the mail and there is no need to synchronize it anymore.\n\t\t\tconst mailSessionKey = mail.bucketKey.bucketEncSessionKeys.find((bucketEncSessionKey) => isSameId(bucketEncSessionKey.instanceId, elementId))\n\t\t\tif (mailSessionKey) {\n\t\t\t\tmailSessionKey.instanceList = newListId\n\t\t\t}\n\t\t}\n\t\tawait this.storage.put(mail)\n\t}\n\n\t/** Returns {null} when the update should be skipped. */\n\tprivate async processUpdateEvent(typeRef: TypeRef<SomeEntity>, update: EntityUpdate): Promise<EntityUpdate | null> {\n\t\tconst { instanceId, instanceListId } = getUpdateInstanceId(update)\n\t\tconst cached = await this.storage.get(typeRef, instanceListId, instanceId)\n\t\t// No need to try to download something that's not there anymore\n\t\tif (cached != null) {\n\t\t\ttry {\n\t\t\t\t// in case this is an update for the user instance: if the password changed we'll be logged out at this point\n\t\t\t\t// if we don't catch the expected NotAuthenticated Error that results from trying to load anything with\n\t\t\t\t// the old user.\n\t\t\t\t// Letting the NotAuthenticatedError propagate to the main thread instead of trying to handle it ourselves\n\t\t\t\t// or throwing out the update drops us onto the login page and into the session recovery flow if the user\n\t\t\t\t// clicks their saved credentials again, but lets them still use offline login if they try to use the\n\t\t\t\t// outdated credentials while not connected to the internet.\n\t\t\t\tconst newEntity = await this.entityRestClient.load(typeRef, collapseId(instanceListId, instanceId))\n\t\t\t\tif (isSameTypeRef(typeRef, UserTypeRef)) {\n\t\t\t\t\tawait this.handleUpdatedUser(cached, newEntity)\n\t\t\t\t}\n\t\t\t\tawait this.storage.put(newEntity)\n\t\t\t\treturn update\n\t\t\t} catch (e) {\n\t\t\t\t// If the entity is not there anymore we should evict it from the cache and not keep the outdated/nonexisting instance around.\n\t\t\t\t// Even for list elements this should be safe as the instance is not there anymore and is definitely not in this version\n\t\t\t\tif (isExpectedErrorForSynchronization(e)) {\n\t\t\t\t\tconsole.log(`Instance not found when processing update for ${JSON.stringify(update)}, deleting from the cache.`)\n\t\t\t\t\tawait this.storage.deleteIfExists(typeRef, instanceListId, instanceId)\n\t\t\t\t\treturn null\n\t\t\t\t} else {\n\t\t\t\t\tthrow e\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn update\n\t}\n\n\tprivate async handleUpdatedUser(cached: SomeEntity, newEntity: SomeEntity) {\n\t\t// When we are removed from a group we just get an update for our user\n\t\t// with no membership on it. We need to clean up all the entities that\n\t\t// belong to that group since we shouldn't be able to access them anymore\n\t\t// and we won't get any update or another chance to clean them up.\n\t\tconst oldUser = cached as User\n\t\tif (oldUser._id !== this.storage.getUserId()) {\n\t\t\treturn\n\t\t}\n\t\tconst newUser = newEntity as User\n\t\tconst removedShips = difference(oldUser.memberships, newUser.memberships, (l, r) => l._id === r._id)\n\t\tfor (const ship of removedShips) {\n\t\t\tconsole.log(\"Lost membership on \", ship._id, ship.groupType)\n\t\t\tawait this.storage.deleteAllOwnedBy(ship.group)\n\t\t}\n\t}\n\n\t/**\n\t *\n\t * @returns {Array<Id>} the ids that are in cache range and therefore should be cached\n\t */\n\tprivate async getElementIdsInCacheRange<T extends ListElementEntity>(typeRef: TypeRef<T>, listId: Id, ids: Id[]): Promise<Id[]> {\n\t\tconst ret: Id[] = []\n\t\tfor (let i = 0; i < ids.length; i++) {\n\t\t\tif (await this.storage.isElementIdInCacheRange(typeRef, listId, ids[i])) {\n\t\t\t\tret.push(ids[i])\n\t\t\t}\n\t\t}\n\t\treturn ret\n\t}\n\n\t/**\n\t * to avoid excessive entity updates and inconsistent offline storages, we don't send entity updates for each mail set migrated mail.\n\t * instead we detect the mail set migration for each folder and drop its whole list from offline.\n\t */\n\tprivate async checkForMailSetMigration(typeRef: TypeRef<unknown>, update: EntityUpdate): Promise<void> {\n\t\tif (update.operation !== OperationType.UPDATE || !isSameTypeRef(typeRef, MailFolderTypeRef)) return\n\t\t// load the old version of the folder now to check if it was migrated to mail set\n\t\tconst oldFolder = await this.storage.get(MailFolderTypeRef, update.instanceListId, update.instanceId)\n\t\t// if it already is a mail set, we're done.\n\t\t// we also delete the mails in the case where we don't have the folder itself in the cache.\n\t\t// because we cache after loading the folder, we won't do it again on the next update event.\n\t\tif (oldFolder != null && oldFolder.isMailSet) return\n\t\tconst updatedFolder = await this.entityRestClient.load(MailFolderTypeRef, [update.instanceListId, update.instanceId])\n\t\tif (!updatedFolder.isMailSet) return\n\t\tawait this.storage.deleteWholeList(MailTypeRef, updatedFolder.mails)\n\t\tawait this.storage.put(updatedFolder)\n\t}\n\n\t/**\n\t * Check if the given request should use the cache\n\t * @param typeRef typeref of the type\n\t * @param opts entity rest client options, if any\n\t * @return true if the cache can be used, false if a direct network request should be performed\n\t */\n\tprivate shouldUseCache(typeRef: TypeRef<any>, opts?: EntityRestClientLoadOptions): boolean {\n\t\t// some types won't be cached\n\t\tif (isIgnoredType(typeRef)) {\n\t\t\treturn false\n\t\t}\n\n\t\t// if a specific version is requested we have to load again and do not want to store it in the cache\n\t\treturn opts?.queryParams?.version == null\n\t}\n}\n\n/**\n * Returns whether the error is expected for the cases where our local state might not be up-to-date with the server yet. E.g. we might be processing an update\n * for the instance that was already deleted. Normally this would be optimized away but it might still happen due to timing.\n */\nfunction isExpectedErrorForSynchronization(e: Error): boolean {\n\treturn e instanceof NotFoundError || e instanceof NotAuthorizedError\n}\n\nexport function expandId(id: Id | IdTuple): { listId: Id | null; elementId: Id } {\n\tif (typeof id === \"string\") {\n\t\treturn {\n\t\t\tlistId: null,\n\t\t\telementId: id,\n\t\t}\n\t} else {\n\t\tconst [listId, elementId] = id\n\t\treturn {\n\t\t\tlistId,\n\t\t\telementId,\n\t\t}\n\t}\n}\n\nexport function collapseId(listId: Id | null, elementId: Id): Id | IdTuple {\n\tif (listId != null) {\n\t\treturn [listId, elementId]\n\t} else {\n\t\treturn elementId\n\t}\n}\n\nexport function getUpdateInstanceId(update: EntityUpdate): { instanceListId: Id | null; instanceId: Id } {\n\tlet instanceListId\n\tif (update.instanceListId === \"\") {\n\t\tinstanceListId = null\n\t} else {\n\t\tinstanceListId = update.instanceListId\n\t}\n\treturn { instanceListId, instanceId: update.instanceId }\n}\n\n/**\n * Check if a range request begins inside an existing range\n */\nfunction isStartIdWithinRange(range: Range, startId: Id, typeModel: TypeModel): boolean {\n\treturn !firstBiggerThanSecond(startId, range.upper, typeModel) && !firstBiggerThanSecond(range.lower, startId, typeModel)\n}\n\n/**\n * Check if a range request is going away from an existing range\n * Assumes that the range request doesn't start inside the range\n */\nfunction isRangeRequestAwayFromExistingRange(range: Range, reverse: boolean, start: string, typeModel: TypeModel) {\n\treturn reverse ? firstBiggerThanSecond(range.lower, start, typeModel) : firstBiggerThanSecond(start, range.upper, typeModel)\n}\n\n/**\n * some types are completely ignored by the cache and always served from a request.\n * Note:\n * isCachedRangeType(ref) ---> !isIgnoredType(ref) but\n * isIgnoredType(ref) -/-> !isCachedRangeType(ref) because of opted-in CustomId types.\n */\nfunction isIgnoredType(typeRef: TypeRef<unknown>): boolean {\n\treturn typeRef.app === \"monitor\" || IGNORED_TYPES.some((ref) => isSameTypeRef(typeRef, ref))\n}\n\n/**\n * Checks if for the given type, that contains a customId,  caching is enabled.\n */\nfunction isCachableCustomIdType(typeRef: TypeRef<unknown>): boolean {\n\treturn CACHEABLE_CUSTOMID_TYPES.some((ref) => isSameTypeRef(typeRef, ref))\n}\n\n/**\n * Ranges for customId types are normally not cached, but some are opted in.\n * Note:\n * isCachedRangeType(ref) ---> !isIgnoredType(ref) but\n * isIgnoredType(ref) -/-> !isCachedRangeType(ref)\n */\nfunction isCachedRangeType(typeModel: TypeModel, typeRef: TypeRef<unknown>): boolean {\n\treturn (!isIgnoredType(typeRef) && isGeneratedIdType(typeModel)) || isCachableCustomIdType(typeRef)\n}\n\nfunction isGeneratedIdType(typeModel: TypeModel): boolean {\n\treturn typeModel.values._id.type === ValueType.GeneratedId\n}\n","import { RestClient, SuspensionBehavior } from \"./RestClient\"\nimport type { CryptoFacade } from \"../crypto/CryptoFacade\"\nimport { _verifyType, HttpMethod, MediaType, resolveTypeReference } from \"../../common/EntityFunctions\"\nimport { SessionKeyNotFoundError } from \"../../common/error/SessionKeyNotFoundError\"\nimport type { EntityUpdate } from \"../../entities/sys/TypeRefs.js\"\nimport { PushIdentifierTypeRef } from \"../../entities/sys/TypeRefs.js\"\nimport {\n\tConnectionError,\n\tInternalServerError,\n\tNotAuthenticatedError,\n\tNotAuthorizedError,\n\tNotFoundError,\n\tPayloadTooLargeError,\n} from \"../../common/error/RestError\"\nimport type { lazy } from \"@tutao/tutanota-utils\"\nimport { isSameTypeRef, Mapper, ofClass, promiseMap, splitInChunks, TypeRef } from \"@tutao/tutanota-utils\"\nimport { assertWorkerOrNode } from \"../../common/Env\"\nimport type { ListElementEntity, SomeEntity, TypeModel } from \"../../common/EntityTypes\"\nimport { getElementId, LOAD_MULTIPLE_LIMIT, POST_MULTIPLE_LIMIT } from \"../../common/utils/EntityUtils\"\nimport { Type } from \"../../common/EntityConstants.js\"\nimport { SetupMultipleError } from \"../../common/error/SetupMultipleError\"\nimport { expandId } from \"./DefaultEntityRestCache.js\"\nimport { InstanceMapper } from \"../crypto/InstanceMapper\"\nimport { QueuedBatch } from \"../EventQueue.js\"\nimport { AuthDataProvider } from \"../facades/UserFacade\"\nimport { LoginIncompleteError } from \"../../common/error/LoginIncompleteError.js\"\nimport { BlobServerUrl } from \"../../entities/storage/TypeRefs.js\"\nimport { BlobAccessTokenFacade } from \"../facades/BlobAccessTokenFacade.js\"\nimport { AesKey } from \"@tutao/tutanota-crypto\"\nimport { isOfflineError } from \"../../common/utils/ErrorUtils.js\"\nimport { VersionedEncryptedKey, VersionedKey } from \"../crypto/CryptoWrapper.js\"\n\nassertWorkerOrNode()\n\nexport function typeRefToPath(typeRef: TypeRef<any>): string {\n\treturn `/rest/${typeRef.app}/${typeRef.type.toLowerCase()}`\n}\n\nexport interface EntityRestClientSetupOptions {\n\tbaseUrl?: string\n\t/** Use this key to encrypt session key instead of trying to resolve the owner key based on the ownerGroup. */\n\townerKey?: VersionedKey\n}\n\nexport interface EntityRestClientUpdateOptions {\n\tbaseUrl?: string\n\t/** Use the key provided by this to decrypt the existing ownerEncSessionKey instead of trying to resolve the owner key based on the ownerGroup. */\n\townerKeyProvider?: OwnerKeyProvider\n}\n\nexport interface EntityRestClientEraseOptions {\n\textraHeaders?: Dict\n}\n\n/**\n * Determines how to handle caching behavior (i.e. reading/writing).\n *\n * Use {@link getCacheModeBehavior} to programmatically check the behavior of the cache mode.\n */\nexport const enum CacheMode {\n\t/** Prefer cached value if it's there, or fall back to network and write it to cache. */\n\tReadAndWrite,\n\n\t/**\n\t * Always retrieve from the network, but still save to cache.\n\t *\n\t * NOTE: This cannot be used with ranged requests.\n\t */\n\tWriteOnly,\n\n\t/** Prefer cached value, but in case of a cache miss, retrieve the value from network without writing it to cache. */\n\tReadOnly,\n}\n\n/**\n * Get the behavior of the cache mode for the options\n * @param cacheMode cache mode to check, or if `undefined`, check the default cache mode ({@link CacheMode.ReadAndWrite})\n */\nexport function getCacheModeBehavior(cacheMode: CacheMode | undefined): {\n\treadsFromCache: boolean\n\twritesToCache: boolean\n} {\n\tswitch (cacheMode ?? CacheMode.ReadAndWrite) {\n\t\tcase CacheMode.ReadAndWrite:\n\t\t\treturn { readsFromCache: true, writesToCache: true }\n\t\tcase CacheMode.WriteOnly:\n\t\t\treturn { readsFromCache: false, writesToCache: true }\n\t\tcase CacheMode.ReadOnly:\n\t\t\treturn { readsFromCache: true, writesToCache: false }\n\t}\n}\n\nexport interface EntityRestClientLoadOptions {\n\tqueryParams?: Dict\n\textraHeaders?: Dict\n\t/** Use the key provided by this to decrypt the existing ownerEncSessionKey instead of trying to resolve the owner key based on the ownerGroup. */\n\townerKeyProvider?: OwnerKeyProvider\n\t/** Defaults to {@link CacheMode.ReadAndWrite }*/\n\tcacheMode?: CacheMode\n\tbaseUrl?: string\n\tsuspensionBehavior?: SuspensionBehavior\n}\n\nexport interface OwnerEncSessionKeyProvider {\n\t(instanceElementId: Id): Promise<VersionedEncryptedKey>\n}\n\nexport interface OwnerKeyProvider {\n\t(ownerKeyVersion: number): Promise<AesKey>\n}\n\n/**\n * The EntityRestInterface provides a convenient interface for invoking server side REST services.\n */\nexport interface EntityRestInterface {\n\t/**\n\t * Reads a single element from the server (or cache). Entities are decrypted before they are returned.\n\t * @param ownerKey Use this key to decrypt session key instead of trying to resolve the owner key based on the ownerGroup.\n\t */\n\tload<T extends SomeEntity>(typeRef: TypeRef<T>, id: PropertyType<T, \"_id\">, loadOptions?: EntityRestClientLoadOptions): Promise<T>\n\n\t/**\n\t * Reads a range of elements from the server (or cache). Entities are decrypted before they are returned.\n\t */\n\tloadRange<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tstart: Id,\n\t\tcount: number,\n\t\treverse: boolean,\n\t\tloadOptions?: EntityRestClientLoadOptions,\n\t): Promise<T[]>\n\n\t/**\n\t * Reads multiple elements from the server (or cache). Entities are decrypted before they are returned.\n\t * @param ownerEncSessionKeyProvider use this to resolve the instances session key in case instance.ownerEncSessionKey is not defined (which might be undefined for MailDetails / Files)\n\t */\n\tloadMultiple<T extends SomeEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id | null,\n\t\telementIds: Array<Id>,\n\t\townerEncSessionKeyProvider?: OwnerEncSessionKeyProvider,\n\t\tloadOptions?: EntityRestClientLoadOptions,\n\t): Promise<Array<T>>\n\n\t/**\n\t * Creates a single element on the server. Entities are encrypted before they are sent.\n\t */\n\tsetup<T extends SomeEntity>(listId: Id | null, instance: T, extraHeaders?: Dict, options?: EntityRestClientSetupOptions): Promise<Id>\n\n\t/**\n\t * Creates multiple elements on the server. Entities are encrypted before they are sent.\n\t */\n\tsetupMultiple<T extends SomeEntity>(listId: Id | null, instances: ReadonlyArray<T>): Promise<Array<Id>>\n\n\t/**\n\t * Modifies a single element on the server. Entities are encrypted before they are sent.\n\t * @param instance\n\t * @param options\n\t */\n\tupdate<T extends SomeEntity>(instance: T, options?: EntityRestClientUpdateOptions): Promise<void>\n\n\t/**\n\t * Deletes a single element on the server.\n\t */\n\terase<T extends SomeEntity>(instance: T, options?: EntityRestClientEraseOptions): Promise<void>\n\n\t/**\n\t * Must be called when entity events are received.\n\t * @param batch The entity events that were received.\n\t * @return Similar to the events in the data parameter, but reduced by the events which are obsolete.\n\t */\n\tentityEventsReceived(batch: QueuedBatch): Promise<Array<EntityUpdate>>\n}\n\n/**\n * Retrieves the instances from the backend (db) and converts them to entities.\n *\n * Part of this process is\n * * the decryption for the returned instances (GET) and the encryption of all instances before they are sent (POST, PUT)\n * * the injection of aggregate instances for the returned instances (GET)\n * * caching for retrieved instances (GET)\n *\n */\nexport class EntityRestClient implements EntityRestInterface {\n\tget _crypto(): CryptoFacade {\n\t\treturn this.lazyCrypto()\n\t}\n\n\tconstructor(\n\t\tprivate readonly authDataProvider: AuthDataProvider,\n\t\tprivate readonly restClient: RestClient,\n\t\tprivate readonly lazyCrypto: lazy<CryptoFacade>,\n\t\tprivate readonly instanceMapper: InstanceMapper,\n\t\tprivate readonly blobAccessTokenFacade: BlobAccessTokenFacade,\n\t) {}\n\n\tasync load<T extends SomeEntity>(typeRef: TypeRef<T>, id: PropertyType<T, \"_id\">, opts: EntityRestClientLoadOptions = {}): Promise<T> {\n\t\tconst { listId, elementId } = expandId(id)\n\t\tconst { path, queryParams, headers, typeModel } = await this._validateAndPrepareRestRequest(\n\t\t\ttypeRef,\n\t\t\tlistId,\n\t\t\telementId,\n\t\t\topts.queryParams,\n\t\t\topts.extraHeaders,\n\t\t\topts.ownerKeyProvider,\n\t\t)\n\t\tconst json = await this.restClient.request(path, HttpMethod.GET, {\n\t\t\tqueryParams,\n\t\t\theaders,\n\t\t\tresponseType: MediaType.Json,\n\t\t\tbaseUrl: opts.baseUrl,\n\t\t})\n\t\tconst entity = JSON.parse(json)\n\t\tconst migratedEntity = await this._crypto.applyMigrations(typeRef, entity)\n\t\tconst sessionKey = await this.resolveSessionKey(opts.ownerKeyProvider, migratedEntity, typeModel)\n\n\t\tconst instance = await this.instanceMapper.decryptAndMapToInstance<T>(typeModel, migratedEntity, sessionKey)\n\t\treturn this._crypto.applyMigrationsForInstance(instance)\n\t}\n\n\tprivate async resolveSessionKey(ownerKeyProvider: OwnerKeyProvider | undefined, migratedEntity: Record<string, any>, typeModel: TypeModel) {\n\t\ttry {\n\t\t\tif (ownerKeyProvider && migratedEntity._ownerEncSessionKey) {\n\t\t\t\tconst ownerKey = await ownerKeyProvider(Number(migratedEntity._ownerKeyVersion ?? 0))\n\t\t\t\treturn this._crypto.resolveSessionKeyWithOwnerKey(migratedEntity, ownerKey)\n\t\t\t} else {\n\t\t\t\treturn await this._crypto.resolveSessionKey(typeModel, migratedEntity)\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tif (e instanceof SessionKeyNotFoundError) {\n\t\t\t\tconsole.log(`could not resolve session key for instance of type ${typeModel.app}/${typeModel.name}`, e)\n\t\t\t\treturn null\n\t\t\t} else {\n\t\t\t\tthrow e\n\t\t\t}\n\t\t}\n\t}\n\n\tasync loadRange<T extends ListElementEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id,\n\t\tstart: Id,\n\t\tcount: number,\n\t\treverse: boolean,\n\t\topts: EntityRestClientLoadOptions = {},\n\t): Promise<T[]> {\n\t\tconst rangeRequestParams = {\n\t\t\tstart: String(start),\n\t\t\tcount: String(count),\n\t\t\treverse: String(reverse),\n\t\t}\n\t\tconst { path, headers, typeModel, queryParams } = await this._validateAndPrepareRestRequest(\n\t\t\ttypeRef,\n\t\t\tlistId,\n\t\t\tnull,\n\t\t\tObject.assign(rangeRequestParams, opts.queryParams),\n\t\t\topts.extraHeaders,\n\t\t\topts.ownerKeyProvider,\n\t\t)\n\t\t// This should never happen if type checking is not bypassed with any\n\t\tif (typeModel.type !== Type.ListElement) throw new Error(\"only ListElement types are permitted\")\n\t\tconst json = await this.restClient.request(path, HttpMethod.GET, {\n\t\t\tqueryParams,\n\t\t\theaders,\n\t\t\tresponseType: MediaType.Json,\n\t\t\tbaseUrl: opts.baseUrl,\n\t\t\tsuspensionBehavior: opts.suspensionBehavior,\n\t\t})\n\t\treturn this._handleLoadMultipleResult(typeRef, JSON.parse(json))\n\t}\n\n\tasync loadMultiple<T extends SomeEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tlistId: Id | null,\n\t\telementIds: Array<Id>,\n\t\townerEncSessionKeyProvider?: OwnerEncSessionKeyProvider,\n\t\topts: EntityRestClientLoadOptions = {},\n\t): Promise<Array<T>> {\n\t\tconst { path, headers } = await this._validateAndPrepareRestRequest(typeRef, listId, null, opts.queryParams, opts.extraHeaders, opts.ownerKeyProvider)\n\t\tconst idChunks = splitInChunks(LOAD_MULTIPLE_LIMIT, elementIds)\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\n\t\tconst loadedChunks = await promiseMap(idChunks, async (idChunk) => {\n\t\t\tlet queryParams = {\n\t\t\t\tids: idChunk.join(\",\"),\n\t\t\t}\n\t\t\tlet json: string\n\t\t\tif (typeModel.type === Type.BlobElement) {\n\t\t\t\tjson = await this.loadMultipleBlobElements(listId, queryParams, headers, path, typeRef, opts.suspensionBehavior)\n\t\t\t} else {\n\t\t\t\tjson = await this.restClient.request(path, HttpMethod.GET, {\n\t\t\t\t\tqueryParams,\n\t\t\t\t\theaders,\n\t\t\t\t\tresponseType: MediaType.Json,\n\t\t\t\t\tbaseUrl: opts.baseUrl,\n\t\t\t\t\tsuspensionBehavior: opts.suspensionBehavior,\n\t\t\t\t})\n\t\t\t}\n\t\t\treturn this._handleLoadMultipleResult(typeRef, JSON.parse(json), ownerEncSessionKeyProvider)\n\t\t})\n\t\treturn loadedChunks.flat()\n\t}\n\n\tprivate async loadMultipleBlobElements(\n\t\tarchiveId: Id | null,\n\t\tqueryParams: { ids: string },\n\t\theaders: Dict | undefined,\n\t\tpath: string,\n\t\ttypeRef: TypeRef<any>,\n\t\tsuspensionBehavior?: SuspensionBehavior,\n\t): Promise<string> {\n\t\tif (archiveId == null) {\n\t\t\tthrow new Error(\"archiveId must be set to load BlobElementTypes\")\n\t\t}\n\t\tconst doBlobRequest = async () => {\n\t\t\tconst blobServerAccessInfo = await this.blobAccessTokenFacade.requestReadTokenArchive(archiveId)\n\t\t\tconst additionalRequestParams = Object.assign(\n\t\t\t\t{},\n\t\t\t\theaders, // prevent CORS request due to non standard header usage\n\t\t\t\tqueryParams,\n\t\t\t)\n\t\t\tconst allParams = await this.blobAccessTokenFacade.createQueryParams(blobServerAccessInfo, additionalRequestParams, typeRef)\n\t\t\treturn tryServers(\n\t\t\t\tblobServerAccessInfo.servers,\n\t\t\t\tasync (serverUrl) =>\n\t\t\t\t\tthis.restClient.request(path, HttpMethod.GET, {\n\t\t\t\t\t\tqueryParams: allParams,\n\t\t\t\t\t\theaders: {}, // prevent CORS request due to non standard header usage\n\t\t\t\t\t\tresponseType: MediaType.Json,\n\t\t\t\t\t\tbaseUrl: serverUrl,\n\t\t\t\t\t\tnoCORS: true,\n\t\t\t\t\t\tsuspensionBehavior,\n\t\t\t\t\t}),\n\t\t\t\t`can't load instances from server `,\n\t\t\t)\n\t\t}\n\t\tconst doEvictToken = () => this.blobAccessTokenFacade.evictArchiveToken(archiveId)\n\n\t\treturn doBlobRequestWithRetry(doBlobRequest, doEvictToken)\n\t}\n\n\tasync _handleLoadMultipleResult<T extends SomeEntity>(\n\t\ttypeRef: TypeRef<T>,\n\t\tloadedEntities: Array<any>,\n\t\townerEncSessionKeyProvider?: OwnerEncSessionKeyProvider,\n\t): Promise<Array<T>> {\n\t\tconst model = await resolveTypeReference(typeRef)\n\n\t\t// PushIdentifier was changed in the system model v43 to encrypt the name.\n\t\t// We check here to check the type only once per array and not for each element.\n\t\tif (isSameTypeRef(typeRef, PushIdentifierTypeRef)) {\n\t\t\tawait promiseMap(loadedEntities, (instance) => this._crypto.applyMigrations(typeRef, instance), {\n\t\t\t\tconcurrency: 5,\n\t\t\t})\n\t\t}\n\n\t\treturn promiseMap(\n\t\t\tloadedEntities,\n\t\t\t(instance) => {\n\t\t\t\treturn this._decryptMapAndMigrate(instance, model, ownerEncSessionKeyProvider)\n\t\t\t},\n\t\t\t{ concurrency: 5 },\n\t\t)\n\t}\n\n\tasync _decryptMapAndMigrate<T>(instance: any, model: TypeModel, ownerEncSessionKeyProvider?: OwnerEncSessionKeyProvider): Promise<T> {\n\t\tlet sessionKey: AesKey | null\n\t\tif (ownerEncSessionKeyProvider) {\n\t\t\tsessionKey = await this._crypto.decryptSessionKey(instance, await ownerEncSessionKeyProvider(getElementId(instance)))\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tsessionKey = await this._crypto.resolveSessionKey(model, instance)\n\t\t\t} catch (e) {\n\t\t\t\tif (e instanceof SessionKeyNotFoundError) {\n\t\t\t\t\tconsole.log(\"could not resolve session key\", e, e.message, e.stack)\n\t\t\t\t\tsessionKey = null // will result in _errors being set on the instance\n\t\t\t\t} else {\n\t\t\t\t\tthrow e\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tconst decryptedInstance = await this.instanceMapper.decryptAndMapToInstance<T>(model, instance, sessionKey)\n\t\treturn this._crypto.applyMigrationsForInstance<T>(decryptedInstance)\n\t}\n\n\tasync setup<T extends SomeEntity>(listId: Id | null, instance: T, extraHeaders?: Dict, options?: EntityRestClientSetupOptions): Promise<Id> {\n\t\tconst typeRef = instance._type\n\t\tconst { typeModel, path, headers, queryParams } = await this._validateAndPrepareRestRequest(\n\t\t\ttypeRef,\n\t\t\tlistId,\n\t\t\tnull,\n\t\t\tundefined,\n\t\t\textraHeaders,\n\t\t\toptions?.ownerKey,\n\t\t)\n\n\t\tif (typeModel.type === Type.ListElement) {\n\t\t\tif (!listId) throw new Error(\"List id must be defined for LETs\")\n\t\t} else {\n\t\t\tif (listId) throw new Error(\"List id must not be defined for ETs\")\n\t\t}\n\n\t\tconst sk = await this._crypto.setNewOwnerEncSessionKey(typeModel, instance, options?.ownerKey)\n\n\t\tconst encryptedEntity = await this.instanceMapper.encryptAndMapToLiteral(typeModel, instance, sk)\n\t\tconst persistencePostReturn = await this.restClient.request(path, HttpMethod.POST, {\n\t\t\tbaseUrl: options?.baseUrl,\n\t\t\tqueryParams,\n\t\t\theaders,\n\t\t\tbody: JSON.stringify(encryptedEntity),\n\t\t\tresponseType: MediaType.Json,\n\t\t})\n\t\treturn JSON.parse(persistencePostReturn).generatedId\n\t}\n\n\tasync setupMultiple<T extends SomeEntity>(listId: Id | null, instances: Array<T>): Promise<Array<Id>> {\n\t\tconst count = instances.length\n\n\t\tif (count < 1) {\n\t\t\treturn []\n\t\t}\n\n\t\tconst instanceChunks = splitInChunks(POST_MULTIPLE_LIMIT, instances)\n\t\tconst typeRef = instances[0]._type\n\t\tconst { typeModel, path, headers } = await this._validateAndPrepareRestRequest(typeRef, listId, null, undefined, undefined, undefined)\n\n\t\tif (typeModel.type === Type.ListElement) {\n\t\t\tif (!listId) throw new Error(\"List id must be defined for LETs\")\n\t\t} else {\n\t\t\tif (listId) throw new Error(\"List id must not be defined for ETs\")\n\t\t}\n\n\t\tconst errors: Error[] = []\n\t\tconst failedInstances: T[] = []\n\t\tconst idChunks: Array<Array<Id>> = await promiseMap(instanceChunks, async (instanceChunk) => {\n\t\t\ttry {\n\t\t\t\tconst encryptedEntities = await promiseMap(instanceChunk, async (e) => {\n\t\t\t\t\tconst sk = await this._crypto.setNewOwnerEncSessionKey(typeModel, e)\n\n\t\t\t\t\treturn this.instanceMapper.encryptAndMapToLiteral(typeModel, e, sk)\n\t\t\t\t})\n\t\t\t\t// informs the server that this is a POST_MULTIPLE request\n\t\t\t\tconst queryParams = {\n\t\t\t\t\tcount: String(instanceChunk.length),\n\t\t\t\t}\n\t\t\t\tconst persistencePostReturn = await this.restClient.request(path, HttpMethod.POST, {\n\t\t\t\t\tqueryParams,\n\t\t\t\t\theaders,\n\t\t\t\t\tbody: JSON.stringify(encryptedEntities),\n\t\t\t\t\tresponseType: MediaType.Json,\n\t\t\t\t})\n\t\t\t\treturn this.parseSetupMultiple(persistencePostReturn)\n\t\t\t} catch (e) {\n\t\t\t\tif (e instanceof PayloadTooLargeError) {\n\t\t\t\t\t// If we try to post too many large instances then we get PayloadTooLarge\n\t\t\t\t\t// So we fall back to posting single instances\n\t\t\t\t\tconst returnedIds = await promiseMap(instanceChunk, (instance) => {\n\t\t\t\t\t\treturn this.setup(listId, instance).catch((e) => {\n\t\t\t\t\t\t\terrors.push(e)\n\t\t\t\t\t\t\tfailedInstances.push(instance)\n\t\t\t\t\t\t})\n\t\t\t\t\t})\n\t\t\t\t\treturn returnedIds.filter(Boolean) as Id[]\n\t\t\t\t} else {\n\t\t\t\t\terrors.push(e)\n\t\t\t\t\tfailedInstances.push(...instanceChunk)\n\t\t\t\t\treturn [] as Id[]\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\n\t\tif (errors.length) {\n\t\t\tif (errors.some(isOfflineError)) {\n\t\t\t\tthrow new ConnectionError(\"Setup multiple entities failed\")\n\t\t\t}\n\t\t\tthrow new SetupMultipleError<T>(\"Setup multiple entities failed\", errors, failedInstances)\n\t\t} else {\n\t\t\treturn idChunks.flat()\n\t\t}\n\t}\n\n\tasync update<T extends SomeEntity>(instance: T, options?: EntityRestClientUpdateOptions): Promise<void> {\n\t\tif (!instance._id) throw new Error(\"Id must be defined\")\n\t\tconst { listId, elementId } = expandId(instance._id)\n\t\tconst { path, queryParams, headers, typeModel } = await this._validateAndPrepareRestRequest(\n\t\t\tinstance._type,\n\t\t\tlistId,\n\t\t\telementId,\n\t\t\tundefined,\n\t\t\tundefined,\n\t\t\toptions?.ownerKeyProvider,\n\t\t)\n\t\tconst sessionKey = await this.resolveSessionKey(options?.ownerKeyProvider, instance, typeModel)\n\t\tconst encryptedEntity = await this.instanceMapper.encryptAndMapToLiteral(typeModel, instance, sessionKey)\n\t\tawait this.restClient.request(path, HttpMethod.PUT, {\n\t\t\tbaseUrl: options?.baseUrl,\n\t\t\tqueryParams,\n\t\t\theaders,\n\t\t\tbody: JSON.stringify(encryptedEntity),\n\t\t\tresponseType: MediaType.Json,\n\t\t})\n\t}\n\n\tasync erase<T extends SomeEntity>(instance: T, options?: EntityRestClientEraseOptions): Promise<void> {\n\t\tconst { listId, elementId } = expandId(instance._id)\n\t\tconst { path, queryParams, headers } = await this._validateAndPrepareRestRequest(\n\t\t\tinstance._type,\n\t\t\tlistId,\n\t\t\telementId,\n\t\t\tundefined,\n\t\t\toptions?.extraHeaders,\n\t\t\tundefined,\n\t\t)\n\t\tawait this.restClient.request(path, HttpMethod.DELETE, {\n\t\t\tqueryParams,\n\t\t\theaders,\n\t\t})\n\t}\n\n\tasync _validateAndPrepareRestRequest(\n\t\ttypeRef: TypeRef<any>,\n\t\tlistId: Id | null,\n\t\telementId: Id | null,\n\t\tqueryParams: Dict | undefined,\n\t\textraHeaders: Dict | undefined,\n\t\townerKey: OwnerKeyProvider | VersionedKey | undefined,\n\t): Promise<{\n\t\tpath: string\n\t\tqueryParams: Dict | undefined\n\t\theaders: Dict | undefined\n\t\ttypeModel: TypeModel\n\t}> {\n\t\tconst typeModel = await resolveTypeReference(typeRef)\n\n\t\t_verifyType(typeModel)\n\n\t\tif (ownerKey == undefined && !this.authDataProvider.isFullyLoggedIn() && typeModel.encrypted) {\n\t\t\t// Short-circuit before we do an actual request which we can't decrypt\n\t\t\tthrow new LoginIncompleteError(`Trying to do a network request with encrypted entity but is not fully logged in yet, type: ${typeModel.name}`)\n\t\t}\n\n\t\tlet path = typeRefToPath(typeRef)\n\n\t\tif (listId) {\n\t\t\tpath += \"/\" + listId\n\t\t}\n\n\t\tif (elementId) {\n\t\t\tpath += \"/\" + elementId\n\t\t}\n\n\t\tconst headers = Object.assign({}, this.authDataProvider.createAuthHeaders(), extraHeaders)\n\n\t\tif (Object.keys(headers).length === 0) {\n\t\t\tthrow new NotAuthenticatedError(\"user must be authenticated for entity requests\")\n\t\t}\n\n\t\theaders.v = typeModel.version\n\t\treturn {\n\t\t\tpath,\n\t\t\tqueryParams,\n\t\t\theaders,\n\t\t\ttypeModel,\n\t\t}\n\t}\n\n\t/**\n\t * for the admin area (no cache available)\n\t */\n\tentityEventsReceived(batch: QueuedBatch): Promise<Array<EntityUpdate>> {\n\t\treturn Promise.resolve(batch.events)\n\t}\n\n\tgetRestClient(): RestClient {\n\t\treturn this.restClient\n\t}\n\n\tprivate parseSetupMultiple(result: any): Id[] {\n\t\ttry {\n\t\t\treturn JSON.parse(result).map((r: any) => r.generatedId)\n\t\t} catch (e) {\n\t\t\tthrow new Error(`Invalid response: ${result}, ${e}`)\n\t\t}\n\t}\n}\n\n/**\n * Tries to run the mapper action against a list of servers. If the action resolves\n * successfully, the result is returned. In case of an ConnectionError and errors\n * that might occur only for a single blob server, the next server is tried.\n * Throws in all other cases.\n */\nexport async function tryServers<T>(servers: BlobServerUrl[], mapper: Mapper<string, T>, errorMsg: string): Promise<T> {\n\tlet index = 0\n\tlet error: Error | null = null\n\tfor (const server of servers) {\n\t\ttry {\n\t\t\treturn await mapper(server.url, index)\n\t\t} catch (e) {\n\t\t\t// InternalServerError is returned when accessing a corrupted archive, so we retry\n\t\t\tif (e instanceof ConnectionError || e instanceof InternalServerError || e instanceof NotFoundError) {\n\t\t\t\tconsole.log(`${errorMsg} ${server.url}`, e)\n\t\t\t\terror = e\n\t\t\t} else {\n\t\t\t\tthrow e\n\t\t\t}\n\t\t}\n\t\tindex++\n\t}\n\tthrow error\n}\n\n/**\n * Do a blob request and retry it in case of a NotAuthorizedError, performing some cleanup before retrying.\n *\n * This is useful for blob requests to handle expired tokens, which cah occur if the requests take a long time, the client gets suspended or paused by the OS.\n * @param doBlobRequest\n * @param doEvictTokenBeforeRetry\n */\nexport async function doBlobRequestWithRetry<T>(doBlobRequest: () => Promise<T>, doEvictTokenBeforeRetry: () => void): Promise<T> {\n\treturn doBlobRequest().catch(\n\t\t// in case one of the chunks could not be uploaded because of an invalid/expired token we upload all chunks again in order to guarantee that they are uploaded to the same archive.\n\t\t// we don't have to take care of already uploaded chunks, as they are unreferenced and will be cleaned up by the server automatically.\n\t\tofClass(NotAuthorizedError, (e) => {\n\t\t\tdoEvictTokenBeforeRetry()\n\t\t\treturn doBlobRequest()\n\t\t}),\n\t)\n}\n\nexport function getIds(\n\tinstance: any,\n\ttypeModel: TypeModel,\n): {\n\tlistId: string | null\n\tid: string\n} {\n\tif (!instance._id) throw new Error(\"Id must be defined\")\n\tlet listId = null\n\tlet id\n\n\tif (typeModel.type === Type.ListElement) {\n\t\tlistId = instance._id[0]\n\t\tid = instance._id[1]\n\t} else {\n\t\tid = instance._id\n\t}\n\n\treturn {\n\t\tlistId,\n\t\tid,\n\t}\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAIa,0BAAN,MAA0D;CAChE,AAAiB;CAEjB,YAA6BA,iBAAkDC,WAAmB;EAgBlG,KAhB6B;EAgB5B,KAhB8E;AAC9E,OAAK,MAAM,gBAAgB,gBAAgB,UAAU;CACrD;CAED,MAAM,SAASC,QAAgB;AAC9B,QAAM,KAAK,gBAAgB,mBAAmB,MAAM,KAAK,KAAK,OAAO;CACrE;CAED,MAAM,cAAcC,aAAqB;AACxC,QAAM,KAAK,gBAAgB,mBAAmB,MAAM,KAAK,KAAK,KAAK,YAAY,YAAY;CAC3F;CAED,MAAM,YAAY;AACjB,QAAM,KAAK,gBAAgB,mBAAmB,MAAM,KAAK,KAAK,KAAK,UAAU;CAC7E;AACD;;;;ICJY,qBAAN,MAAkI;CACxI,YAA6BC,QAA6C;EAU1E,KAV6B;CAA+C;CAE5E,YAAYC,SAA6C;AACxD,SAAO,KAAK,OAAO,YAAY,QAAQ;CACvC;CAED,kBAAkBC,SAA6D;AAC9E,OAAK,OAAO,YAAY,CAACC,OAAY,QAAQ,SAAS,GAAG,KAAK,CAAC;CAC/D;AACD;;;;ACbM,SAAS,aAAgBC,eAA2C;CAE1E,MAAM,cAAc,IAAI,MACvB,CAAE,GACF,EACC,KAAK,CAACC,GAAWC,aAAqB;AACrC,SAAO,YAAY,eAAe,SAAS;CAC3C,EACD;AAEF,QAAO,SAAY,YAAY;AAC/B;AAiCM,SAAS,mBACfC,OAC0D;AAC1D,QAAO,OAAOC,YAA0C;EACvD,MAAM,CAAC,QAAQ,IAAI,KAAK,GAAG,QAAQ;EACnC,MAAM,OAAO,SAAS,MAAM,CAAC;AAE7B,MAAI,QAAQ,KACX,OAAM,IAAI,kBAAkB,yBAAyB,OAAO,GAAG,GAAG;EAGnE,MAAM,OAAO,MAAM,MAAM;AACzB,MAAI,QAAQ,KACX,OAAM,IAAI,kBAAkB,sBAAsB,OAAO,GAAG,GAAG;AAGhE,SAAO,SAAS,KAAK,CAAC,IAAI,GAAG,KAAK;CAClC;AACD;;;;AAKD,SAAS,YAAYJ,eAAwCK,YAAoB;AAChF,QAAO,IAAI,MACV,CAAE,GACF,EACC,KAAK,CAACJ,GAAWC,aAAqB;AAKrC,MAAI,aAAa,OAChB,QAAO;IAEP,QAAO,CAAC,GAAG,SAAgB;GAC1B,MAAM,UAAU,IAAI,QAAQ,UAAmB;IAAC;IAAY;IAAU;GAAK;AAC3E,UAAO,cAAc,QAAQ;EAC7B;CAEF,EACD;AAEF;;;;ACvFD,kBAAkB;IAKA,kDAAX;AACN;AACA;AACA;;AACA;IAEY,eAAN,MAAmB;CACzB,AAAQ,uBAA6C,OAAO;CAC5D,AAAQ,iBAA0B;CAElC,AAAQ;CAER,cAAc;AACb,OAAK,YAAY,KAAK,MAAM;AAC3B,QAAK,iBAAiB;EACtB,EAAC;CACF;CAED,IAAI,cAA6B;AAChC,SAAO,KAAK,qBAAqB;CACjC;CAED,MAAM,KAAKI,SAAuC;AACjD,MAAI,IAAI,SAAS,QAAQ;GACxB,MAAM,EAAE,mBAAmB,GAAG,OAAO,MAAM;GAK3C,MAAM,YAAY,oBAAoB;GACtC,MAAM,SAAS,IAAI,OAAO,WAAW,EAAE,MAAM,SAAU;AACvD,QAAK,cAAc,IAAI,kBAAkB,IAAI,mBAAmB,SAAS,KAAK,cAAc,QAAQ,EAAE;AACtG,SAAM,KAAK,YAAY,YAAY,IAAI,QAAQ,SAAS;IAAC,OAAO;IAAK,KAAK,mBAAmB;IAAE,OAAO,aAAa;GAAC,GAAE;AAEtH,UAAO,UAAU,CAACC,MAAW;AAC5B,UAAM,IAAI,OAAO,0BAA0B,EAAE,KAAK,GAAG,EAAE,MAAM,GAAG,EAAE,QAAQ,GAAG,EAAE;GAC/E;EACD,OAAM;GAIN,MAAM,aAAa,WAAW;GAC9B,MAAM,aAAa,IAAI,WAAW,MAAM;AACxC,SAAM,WAAW,KAAK,OAAO,aAAa,CAAC;AAC3C,cAAW,OAAO,aAAa,EAC9B,aAAa,CAACC,QAAa,KAAK,YAAY,cAAc,IAAI,CAC9D;AACD,QAAK,cAAc,IAAI,kBACtB,EACC,aAAa,SAAUA,KAAU;AAChC,eAAW,OAAO,cAAc,IAAI;GACpC,EACD,GACD,KAAK,cAAc,QAAQ,EAC3B;EAED;AAED,OAAK,qBAAqB,SAAS;CACnC;CAED,cAAcF,SAAmD;AAChE,SAAO;GACN,YAAY,CAACG,YAAyB,QAAQ,OAAO,aAAa,SAAS,QAAQ,KAAK,GAAG,EAAE,SAAS,QAAQ,KAAK,GAAG,CAAC;GACvH,OAAO,CAACA,YAAyB;AAChC,wBAAoB,WAAW,QAAQ,KAAK,GAAG,CAAC;AAChD,WAAO,QAAQ,SAAS;GACxB;GACD,QAAQ,mBAAiE;IACxE,MAAM,gBAAgB;AACrB,YAAO,QAAQ;IACf;IACD,MAAM,yBAAyB;AAC9B,YAAO,QAAQ;IACf;IACD,MAAM,kBAAkB;AACvB,YAAO,QAAQ;IACf;IACD,MAAM,kBAAkB;AACvB,YAAO,QAAQ;IACf;IACD,MAAM,2BAA2B;AAChC,YAAO,QAAQ;IACf;IACD,MAAM,qBAAqB;AAC1B,YAAO,QAAQ;IACf;GACD,EAAC;EACF;CACD;CAED,qBAA4C;AAC3C,SAAO,aAAoC,OAAO,YAAY,KAAK,aAAa,QAAQ,CAAC;CACzF;CAED,YAAY,GAAG,MAA8D;AAC5E,SAAO,KAAK,aAAa,IAAI,QAAQ,eAAe,MAAM;CAC1D;;CAGD,MAAM,aAAaC,KAA+C;AACjE,QAAM,KAAK;AACX,SAAO,KAAK,YAAY,YAAY,IAAI;CACxC;CAED,QAAuB;AACtB,SAAO,KAAK,aAAa,IAAI,QAAQ,SAAS,CAAE,GAAE;CAClD;;;;CAKD,AAAQ,oBAA6C;EACpD,MAAM,YAAY,IAAI,YAAY;AAClC,SAAO,gBAAgB,UAAU;EACjC,MAAMC,UAAmC,CAAE;AAE3C,OAAK,IAAI,IAAI,GAAG,IAAI,UAAU,QAAQ,IAErC,SAAQ,KAAK;GACZ,QAAQ;GACR,SAAS;GACT,MAAM,UAAU;EAChB,EAAC;AAGH,SAAO;CACP;AACD;AAEM,SAAS,gBAAgBL,SAAsC;CACrE,MAAM,SAAS,IAAI;CACnB,MAAM,QAAQ,KAAK,KAAK;AACxB,QAAO,KAAK,QAAQ,CAAC,KAAK,MAAM,QAAQ,IAAI,0BAA0B,KAAK,KAAK,GAAG,MAAM,CAAC;AAC1F,QAAO;AACP;;;;ACjHD,oBAAoB;IAEF,0CAAX;AACN;AAEA;AAEA;;AACA;MAGY,+BAA+B;AAC5C,MAAM,2CAA2C;AACjD,MAAM,6BAA6B;;;;;;AAMnC,MAAM,qBAAqB,OAAO,OAAO;CACxC,OAAO,CAAC,GAAG,EAAG;CACd,QAAQ,CAAC,IAAI,EAAG;CAChB,OAAO,CAAC,IAAI,GAAI;AAChB,EAAU;AAIX,MAAM,6BAA6B;;AAGnC,IAAW,sCAAX;AACC;AACA;AACA;AACA;;AACA,EALU;IAOO,sCAAX;AACN;AACA;;AACA;IAmBY,iBAAN,MAAqB;CAC3B,AAAQ;CACR,AAAQ;CACR,AAAQ,qBAA8B;;;;;;;;CAStC,AAAQ;;;;CAKR,AAAQ;CAER,AAAQ,4BAAuC;;CAG/C,AAAiB;;CAGjB,AAAiB;CACjB,AAAQ;CACR,AAAQ;;;;CAKR,AAAQ,0BAAgD;CACxD,AAAQ,2BAAmC;CAE3C,YACkBM,UACAC,OACAC,YACAC,QACAC,gBACAC,eACAC,eACAC,iBAChB;EA8iBF,KAtjBkB;EAsjBjB,KArjBiB;EAqjBhB,KApjBgB;EAojBf,KAnjBe;EAmjBd,KAljBc;EAkjBb,KAjjBa;EAijBZ,KAhjBY;EAgjBX,KA/iBW;AAGjB,OAAK,QAAQ,cAAc;AAC3B,OAAK,qBAAqB,IAAI;AAC9B,OAAK,yBAAyB,IAAI;AAClC,OAAK,SAAS;AACd,OAAK,iBAAiB;AACtB,OAAK,eAAe;AACpB,OAAK,aAAa,IAAI,WAAW,UAAU,MAAM,CAAC,iBAAiB,KAAK,mBAAmB,aAAa;AACxG,OAAK,2BAA2B,IAAI,WAAW,UAAU,OAAO,CAAC,UAAU,KAAK,iCAAiC,MAAM;AACvH,OAAK,OAAO;CACZ;CAED,AAAQ,QAAQ;AACf,OAAK,qBAAqB;AAE1B,OAAK,mBAAmB,OAAO;AAE/B,OAAK,uBAAuB,OAAO;AAEnC,OAAK,WAAW,OAAO;AAEvB,OAAK,WAAW,OAAO;AAEvB,OAAK,0BAA0B;CAC/B;;;;;CAMD,QAAQC,aAA0B;AACjC,UAAQ,IAAI,yBAAyB,gBAAgB,YAAY,WAAW,UAAU,KAAK,MAAM;AAEjG,OAAK,0BAA0B;AAE/B,OAAK,SAAS,wBAAwB,kBAAkB,WAAW;AAEnE,OAAK,QAAQ,cAAc;AAC3B,OAAK,eAAe;EAEpB,MAAM,cAAc,KAAK,WAAW,mBAAmB;EAGvD,MAAM,YACL,mBACAC,oBAAa,UACb,MACAC,kBAAkB,UAClB,oBACA,IAAI,gBACJ,aACA,KAAK,WAAW,iBAAiB,CAAC,MAClC,kBACA,YAAY,eACX,KAAK,4BAA4B,4BAA4B,KAAK,4BAA4B;EAChG,MAAM,OAAO,YAAY;AAEzB,OAAK,6BAA6B;AAElC,OAAK,SAAS,KAAK,cAAc,KAAK;AACtC,OAAK,OAAO,SAAS,MAAM,KAAK,OAAO,YAAY;AACnD,OAAK,OAAO,UAAU,CAACC,UAAsB,KAAK,QAAQ,MAAM;AAChE,OAAK,OAAO,UAAU,CAACC,UAAe,KAAK,QAAQ,MAAM;AACzD,OAAK,OAAO,YAAY,CAACC,YAAkC,KAAK,UAAU,QAAQ;AAElF,OAAK,cAAc,MAAM,MAAM;AAC9B,WAAQ,IAAI,qCAAqC;AACjD,QAAK,aAAa,MAAM,KAAK;EAC7B,EAAC;CACF;;;;;CAMD,MAAM,MAAMC,aAAiD;AAC5D,UAAQ,IAAI,0BAA0B,aAAa,UAAU,KAAK,MAAM;AAExE,UAAQ,aAAR;AACC,QAAK,oBAAoB;AACxB,SAAK,WAAW;AAEhB;AAED,QAAK,oBAAoB;AACxB,SAAK,QAAQ,cAAc;AAE3B,SAAK,SAAS,wBAAwB,kBAAkB,WAAW;AAEnE;AAED,QAAK,oBAAoB;AACxB,SAAK,SAAS,wBAAwB,kBAAkB,WAAW;AAEnE;EACD;AAED,OAAK,QAAQ,OAAO;CACpB;CAED,MAAM,aAAaC,aAAsBC,sBAA+BC,UAAuB,MAAqB;AACnH,UAAQ,IAAI,gCAAgC,aAAa,yBAAyB,sBAAsB,UAAUC,QAAM;AAExH,MAAI,KAAK,gBAAgB;AAExB,gBAAa,KAAK,eAAe;AACjC,QAAK,iBAAiB;EACtB;AAED,OAAKA,QACJ,MAAK,UAAU,aAAa,qBAAqB;IAEjD,MAAK,iBAAiB,WAAW,MAAM,KAAK,UAAU,aAAa,qBAAqB,EAAEA,QAAM;CAEjG;CAGD,AAAQ,OAAOV,aAAyC;AACvD,OAAK,2BAA2B;AAChC,UAAQ,IAAI,kBAAkB,KAAK,MAAM;EAEzC,MAAM,IAAI,KAAK,iBAAiB,YAAY;AAE5C,OAAK,SAAS,wBAAwB,kBAAkB,UAAU;AAElE,SAAO;CACP;CAED,AAAQ,QAAQI,OAAY;AAC3B,UAAQ,IAAI,aAAa,OAAO,KAAK,UAAU,MAAM,EAAE,UAAU,KAAK,MAAM;CAC5E;CAED,MAAc,UAAUC,SAA8C;EACrE,MAAM,CAAC,MAAM,MAAM,GAAG,QAAQ,KAAK,MAAM,IAAI;AAE7C,UAAQ,MAAR;AACC,QAAK,YAAY,cAAc;IAC9B,MAAM,EAAE,cAAc,iBAAiB,YAAiC,GAAG,MAAM,KAAK,eAAe,wBACpG,MAAM,qBAAqB,2BAA2B,EACtD,KAAK,MAAM,MAAM,EACjB,KACA;IACD,MAAM,wBAAwB,MAAM,KAAK,mBAAmB,WAAW;AACvE,SAAK,yBAAyB,IAAI,cAAc,iBAAiB,sBAAsB;AACvF;GACA;AACD,QAAK,YAAY,qBAAqB;IACrC,MAAMM,cAAoC,MAAM,KAAK,eAAe,wBACnE,MAAM,qBAAqB,4BAA4B,EACvD,KAAK,MAAM,MAAM,EACjB,KACA;AACD,SAAK,SAAS,iBAAiB,YAAY;AAC3C;GACA;AACD,QAAK,YAAY,iBAAiB;IACjC,MAAMC,OAAoC,MAAM,KAAK,eAAe,wBACnE,MAAM,qBAAqB,mCAAmC,EAC9D,KAAK,MAAM,MAAM,EACjB,KACA;AACD,SAAK,4BAA4B,KAAK;AACtC,SAAK,SAAS,0BAA0B,KAAK,QAAQ;AACrD;GACA;AACD,QAAK,YAAY,cAAc;IAC9B,MAAMC,OAA8B,MAAM,KAAK,eAAe,wBAC7D,MAAM,qBAAqB,6BAA6B,EACxD,KAAK,MAAM,MAAM,EACjB,KACA;AACD,UAAM,KAAK,WAAW,gBAAgB,KAAK;AAC3C,UAAM,KAAK,SAAS,sBAAsB,KAAK;AAC/C;GACA;AACD;AACC,YAAQ,IAAI,gCAAgC,KAAK;AACjD;EACD;CACD;;;;;CAMD,MAAc,mBAAmBC,YAAqD;AACrF,SAAO,cAAc,YAAY,OAAO,iBAAiB;GACxD,MAAM,UAAU,IAAI,QAAQ,aAAa,aAAa,aAAa;AACnE,OAAI;AACH,UAAM,qBAAqB,QAAQ;AACnC,WAAO;GACP,SAAQ,QAAQ;AAChB,YAAQ,KAAK,2DAA2D,UAAU,QAAQ,CAAC;AAC3F,WAAO;GACP;EACD,EAAC;CACF;CAED,AAAQ,QAAQX,OAAmB;AAClC,OAAK;AACL,UAAQ,IAAI,mBAAmB,OAAO,UAAU,KAAK,MAAM;AAE3D,OAAK,WAAW,gBACf,4BAA4B,EAC3B,cAAc,MACd,EAAC,CACF;AAED,OAAK,cAAc,MAAM;EAKzB,MAAM,aAAa,MAAM,OAAO;AAEhC,MAAI;GAAC,mBAAmB;GAAM,uBAAuB;GAAM,mBAAmB;EAAK,EAAC,SAAS,WAAW,EAAE;AACzG,QAAK,WAAW;AAChB,QAAK,SAAS,QAAQ,gBAAgB,YAAY,oBAAoB,MAAM,KAAK,CAAC;EAClF,WAAU,eAAe,oBAAoB,MAAM;AAEnD,QAAK,QAAQ,cAAc;AAC3B,QAAK,SAAS,wBAAwB,kBAAkB,WAAW;EACnE,WAAU,KAAK,UAAU,cAAc,aAAa,KAAK,WAAW,iBAAiB,EAAE;AACvF,QAAK,SAAS,wBAAwB,kBAAkB,WAAW;AAEnE,OAAI,KAAK,oBAAoB;AAC5B,SAAK,qBAAqB;AAC1B,SAAK,aAAa,OAAO,MAAM;GAC/B,OAAM;IACN,IAAIY;AAEJ,QAAI,eAAe,2BAClB,wBAAuB,mBAAmB;SAChC,KAAK,6BAA6B,EAC5C,wBAAuB,mBAAmB;SAChC,KAAK,6BAA6B,EAC5C,wBAAuB,mBAAmB;IAE1C,wBAAuB,mBAAmB;AAG3C,SAAK,aAAa,OAAO,OAAO,YAAY,sBAAsB,qBAAqB,IAAI,qBAAqB,GAAG,CAAC;GACpH;EACD;CACD;CAED,MAAc,iBAAiBf,aAAyC;AAEvE,OAAK,yBAAyB,OAAO;AAGrC,OAAK,WAAW,OAAO;EAEvB,MAAM,qBAAqB,eAAe,YAAY,aAAa,KAAK,mBAAmB,OAAO;EAClG,MAAM,IAAI,qBAAqB,KAAK,uBAAuB,KAAK,WAAW,GAAG,KAAK,qBAAqB;AAExG,SAAO,EACL,KAAK,MAAM;AACX,QAAK,yBAAyB,QAAQ;AACtC,QAAK,WAAW,QAAQ;EACxB,EAAC,CACD,MACA,QAAQ,iBAAiB,CAAC,MAAM;AAC/B,WAAQ,IAAI,kDAAkD,EAAE;AAChE,QAAK,MAAM,oBAAoB,UAAU;EACzC,EAAC,CACF,CACA,MACA,QAAQ,gBAAgB,MAAM;AAE7B,WAAQ,IAAI,2DAA2D;EACvE,EAAC,CACF,CACA,MACA,QAAQ,yBAAyB,OAAO,MAAM;AAK7C,QAAK,mBACJ,MAAK,mBAAmB,OAAO;AAGhC,WAAQ,IAAI,mCAAmC,0CAA0C,EAAE;GAC3F,IAAI,UAAU,MAAM,yCAAyC,CAAC,KAAK,MAAM;AAExE,QAAI,KAAK,4BAA4B,SAAS;AAC7C,aAAQ,IAAI,sCAAsC;AAClD,YAAO,KAAK,iBAAiB,YAAY;IACzC,MACA,SAAQ,IAAI,uCAAuC;GAEpD,EAAC;AACF,QAAK,0BAA0B;AAC/B,UAAO;EACP,EAAC,CACF,CACA,MACA,QAAQ,gBAAgB,OAAO,MAAM;AAGpC,SAAM,KAAK,MAAM,cAAc;AAE/B,SAAM;EACN,EAAC,CACF,CACA,MAAM,CAAC,MAAM;AACb,QAAK,yBAAyB,QAAQ;AAEtC,QAAK,WAAW,QAAQ;AAExB,QAAK,SAAS,QAAQ,EAAE;EACxB,EAAC;CACH;CAED,MAAc,sBAAsB;EACnC,MAAM,EAAE,SAAS,mBAAmB,GAAG,MAAM,KAAK,4BAA4B;AAI9E,OAAK,qBAAqB;AAG1B,MAAI,kBAGH,OAAM,KAAK,uBAAuB,KAAK,WAAW;IAIlD,OAAM,KAAK,MAAM,gBAAgB;CAElC;;;;;CAMD,MAAc,6BAAmG;EAEhH,MAAMgB,UAA8B,IAAI;EACxC,IAAI,oBAAoB;AACxB,OAAK,MAAM,WAAW,KAAK,aAAa,EAAE;GACzC,MAAM,gBAAgB,MAAM,KAAK,MAAM,gCAAgC,QAAQ;AAC/E,OAAI,iBAAiB,MAAM;AAC1B,YAAQ,IAAI,SAAS,CAAC,aAAc,EAAC;AACrC,wBAAoB;GACpB,OAAM;IACN,MAAM,UAAU,MAAM,KAAK,OAAO,UAAU,yBAAyB,SAAS,kBAAkB,GAAG,KAAK;IACxG,MAAM,UAAU,QAAQ,WAAW,IAAI,aAAa,QAAQ,GAAG,GAAG;AAClE,YAAQ,IAAI,SAAS,CAAC,OAAQ,EAAC;AAE/B,UAAM,KAAK,MAAM,gCAAgC,SAAS,QAAQ;GAClE;EACD;AAED,SAAO;GAAE;GAAS;EAAmB;CACrC;;;;;CAMD,MAAM,uBAAuBC,YAAuC;AACnE,OAAK,KAAK,WAAW,iBAAiB,CACrC;AAGD,QAAM,KAAK,gBAAgB;EAE3B,IAAIC,eAAmC,CAAE;AACzC,OAAK,IAAI,WAAW,KAAK,aAAa,EAAE;GACvC,MAAM,qBAAqB,MAAM,KAAK,yBAAyB,QAAQ;AACvE,kBAAe,aAAa,OAAO,mBAAmB;EACtD;EAED,MAAM,yBAAyB,aAAa,KAAK,CAAC,GAAG,MAAM,mBAAmB,aAAa,EAAE,EAAE,aAAa,EAAE,CAAC,CAAC;EAEhH,IAAI,uBAAuB;AAC3B,OAAK,MAAM,SAAS,wBAAwB;GAC3C,MAAM,wBAAwB,MAAM,KAAK,mBAAmB,MAAM,OAAO;GACzE,MAAM,uBAAuB,KAAK,SAAS,aAAa,MAAM,EAAE,UAAU,MAAM,EAAE,uBAAuB,WAAW;AACpH,OAAI,qBACH;EAED;EAID,MAAM,kBAAkB,IAAI,wBAAwB,KAAK,iBAAiB,uBAAuB;AACjG,UAAQ,IAAI,OAAO,2BAA2B,qBAAqB,SAAS;AAC5E,QAAM,gBAAgB,SAAS,EAAE;AACjC,aAAW,mBAAmB,gBAAgB;AAI9C,QAAM,KAAK,MAAM,gBAAgB;CACjC;CAED,MAAc,yBAAyBC,SAA0C;AAChF,MAAI;AACH,UAAO,MAAM,KAAK,OAAO,QAAQ,yBAAyB,SAAS,KAAK,mCAAmC,QAAQ,CAAC;EACpH,SAAQ,GAAG;AACX,OAAI,aAAa,oBAAoB;AACpC,YAAQ,IAAI,wDAAwD;AACpE,WAAO,CAAE;GACT,MACA,OAAM;EAEP;CACD;CAED,MAAc,iBAAiB;AAG9B,MAAI,MAAM,KAAK,MAAM,aAAa,CAEjC,OAAM,IAAI,eAAe;CAE1B;CAED,MAAc,mBAAmBC,cAA0C;AAC1E,MAAI;AACH,SAAM,KAAK,kBAAkB,aAAa;EAC1C,SAAQ,GAAG;AACX,WAAQ,IAAI,2CAA2C,EAAE;AACzD,QAAK,SAAS,QAAQ,EAAE;AACxB,SAAM;EACN;CACD;CAED,MAAc,iCAAiCC,OAAmC;AACjF,OAAK,SAAS,MAAM,SAAS,MAAM,SAAS,MAAM,QAAQ,KAAK,WAAW;AAC1E,OAAK,WAAW,QAAQ;CACxB;CAED,AAAQ,8BAA8B;AACrC,MAAI,KAAK,OAER,MAAK,OAAO,SAAS,KAAK,OAAO,UAAU,KAAK,OAAO,UAAU,KAAK,OAAO,YAAY;CAE1F;CAED,MAAc,YAA2B;AACxC,OAAK,QAAQ,cAAc;AAE3B,OAAK,OAAO;AAEZ,OAAK,SAAS,wBAAwB,kBAAkB,WAAW;CACnE;;;;CAKD,AAAQ,UAAUd,aAAsBC,sBAA+B;AACtE,UAAQ,IACP,mFAAmF,KAAK,SAAS,KAAK,OAAO,aAAa,SAC1H,UACA,KAAK,OACL,gBACA,aACA,yBACA,qBACA;AAED,MAAI,KAAK,UAAU,cAAc,cAAc,qBAC9C,MAAK,QAAQ,cAAc;AAG5B,MAAI,eAAe,KAAK,UAAU,KAAK,OAAO,eAAe,UAAU,MAAM;AAC5E,QAAK,qBAAqB;AAC1B,QAAK,OAAO,OAAO;EACnB,YACC,KAAK,UAAU,QAAQ,KAAK,OAAO,eAAe,UAAU,UAAU,KAAK,OAAO,eAAe,UAAU,YAC5G,KAAK,UAAU,cAAc,cAC7B,KAAK,WAAW,iBAAiB,EAChC;AAGD,OAAI,KAAK,aACR,cAAa,KAAK,aAAa;AAGhC,QAAK,eAAe,WAAW,MAAM,KAAK,QAAQ,YAAY,UAAU,EAAE,IAAI;EAC9E;CACD;CAED,AAAQ,SAASc,SAAaH,SAAaI,QAAqCN,YAAiC;EAChH,MAAM,eAAe,KAAK,mBAAmB,IAAI,QAAQ,IAAI,CAAE;EAE/D,MAAM,QAAQ,aAAa,cAAc,SAAS,mBAAmB;EACrE,IAAI;AAEJ,MAAI,QAAQ,GAAG;AACd,gBAAa,QAAQ,OAAO,GAAG,QAAQ;AAEvC,cAAW,WAAW,IAAI,SAAS,SAAS,OAAO;EACnD,MACA,YAAW;AAGZ,MAAI,aAAa,SAAS,2BACzB,cAAa,OAAO;AAGrB,OAAK,mBAAmB,IAAI,SAAS,aAAa;AAElD,MAAI,SACH,MAAK,uBAAuB,IAAI,SAAS,QAAQ;AAElD,SAAO;CACP;CAED,MAAc,kBAAkBI,OAAmC;AAClE,MAAI;AACH,OAAI,KAAK,cAAc,CAAE;GACzB,MAAM,iBAAiB,MAAM,KAAK,MAAM,qBAAqB,MAAM;AACnE,QAAK,KAAK,cAAc,CAAE,OAAM,KAAK,SAAS,uBAAuB,gBAAgB,MAAM,SAAS,MAAM,QAAQ;EAClH,SAAQ,GAAG;AACX,OAAI,aAAa,yBAAyB;AAEzC,YAAQ,IAAI,oCAAoC,EAAE;IAClD,MAAM,eAAe,MAAM,yCAAyC,CAAC,KAAK,MAAM;AAE/E,SAAI,KAAK,4BAA4B,aACpC,QAAO,KAAK,kBAAkB,MAAM;IAEpC,OAAM,IAAI,eAAe;IAE1B,EAAC;AACF,SAAK,0BAA0B;AAC/B,WAAO;GACP,OAAM;AACN,YAAQ,IAAI,SAAS,SAAS,EAAE;AAChC,UAAM;GACN;EACD;CACD;CAED,AAAQ,mCAAmCF,SAAiB;EAC3D,MAAM,UAAU,KAAK,mBAAmB,IAAI,QAAQ;AAEpD,SAAO,WAAW,QAAQ,SAAS,IAAI,UAAU,QAAQ,GAAG;CAC5D;CAED,AAAQ,eAAe;AACtB,SAAO,KAAK,UAAU,cAAc;CACpC;CAED,AAAQ,cAAoB;AAC3B,SAAO,KAAK,WACV,iBAAiB,CACjB,YAAY,OAAO,CAAC,eAAe,WAAW,cAAc,UAAU,YAAY,CAClF,IAAI,CAAC,eAAe,WAAW,MAAM,CACrC,OAAO,KAAK,WAAW,iBAAiB,CAAC,UAAU,MAAM;CAC3D;AACD;;;;ACzrBD,MAAM,UAAU;CACd;CACA;CACA;CACA;AACD;AAED,MAAM,kBAAkB;CACtB;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;AACD;;;;;AAMD,SAAS,GAAI,OAAO;AAClB,KAAI,UAAU,KACZ,QAAO;AAET,KAAI,UAAU,UACZ,QAAO;AAET,KAAI,UAAU,QAAQ,UAAU,MAC9B,QAAO;CAET,MAAM,gBAAgB;AACtB,KAAI,QAAQ,SAAS,OAAO,CAC1B,QAAO;AAIT,KAAI,WAAW,WACb,QAAO;AAET,KAAI,MAAM,QAAQ,MAAM,CACtB,QAAO;AAET,KAAI,WAAW,MAAM,CACnB,QAAO;CAET,MAAM,aAAa,cAAc,MAAM;AACvC,KAAI,WACF,QAAO;AAGT,QAAO;AACR;;;;;AAMD,SAAS,WAAY,OAAO;AAC1B,QAAO,SAAS,MAAM,eAAe,MAAM,YAAY,YAAY,MAAM,YAAY,SAAS,KAAK,MAAM,MAAM;AAChH;;;;;AAMD,SAAS,cAAe,OAAO;CAC7B,MAAM,iBAAiB,OAAO,UAAU,SAAS,KAAK,MAAM,CAAC,MAAM,GAAG,GAAG;AACzE,KAAI,gBAAgB,SAAS,eAAe,CAC1C,QAAO;AAGT,QAAO;AACR;IAEKK,SAAN,MAAW;;;;;;CAMT,YAAa,OAAO,MAAM,UAAU;AAClC,OAAK,QAAQ;AACb,OAAK,eAAe,SAAS;AAC7B,OAAK,OAAO;AACZ,OAAK,WAAW;CACjB;CAGD,WAAY;AACV,UAAQ,OAAO,KAAK,MAAM,IAAI,KAAK,KAAK;CACzC;;;;;CAMD,QAAS,KAAK;AAEZ,SAAO,KAAK,QAAQ,IAAI,QAAQ,KAAK,KAAK,QAAQ,IAAI,QAAQ,IAAI;CACnE;AACF;AAGD,OAAK,OAAO,IAAIA,OAAK,GAAG,QAAQ;AAChC,OAAK,SAAS,IAAIA,OAAK,GAAG,UAAU;AACpC,OAAK,QAAQ,IAAIA,OAAK,GAAG,SAAS;AAClC,OAAK,SAAS,IAAIA,OAAK,GAAG,UAAU;AACpC,OAAK,QAAQ,IAAIA,OAAK,GAAG,SAAS;AAClC,OAAK,MAAM,IAAIA,OAAK,GAAG,OAAO;AAC9B,OAAK,MAAM,IAAIA,OAAK,GAAG,OAAO;AAC9B,OAAK,QAAQ,IAAIA,OAAK,GAAG,SAAS;AAClC,OAAK,QAAQ,IAAIA,OAAK,GAAG,SAAS;AAClC,OAAK,OAAO,IAAIA,OAAK,GAAG,QAAQ;AAChC,OAAK,OAAO,IAAIA,OAAK,GAAG,QAAQ;AAChC,OAAK,YAAY,IAAIA,OAAK,GAAG,aAAa;AAC1C,OAAK,QAAQ,IAAIA,OAAK,GAAG,SAAS;IAG5B,QAAN,MAAY;;;;;;CAMV,YAAa,MAAM,OAAO,eAAe;AACvC,OAAK,OAAO;AACZ,OAAK,QAAQ;AACb,OAAK,gBAAgB;;AAErB,OAAK,eAAe;;AAEpB,OAAK,YAAY;CAClB;CAGD,WAAY;AACV,UAAQ,QAAQ,KAAK,KAAK,IAAI,KAAK,MAAM;CAC1C;AACF;AAMD,MAAM,YAAY,WAAW,YAE1B,WAAW,QAAQ,WAEpB,WAAW,iBAEJ,WAAW,OAAO,aAAa;AAExC,MAAM,cAAc,IAAI;AACxB,MAAM,cAAc,IAAI;;;;;AAMxB,SAAS,SAAUC,OAAK;AAEtB,QAAO,aAAa,WAAW,OAAO,SAASA,MAAI;AACpD;;;;;AAMD,SAAS,MAAOA,OAAK;AAEnB,OAAMA,iBAAe,YACnB,QAAO,WAAW,KAAKA,MAAI;AAE7B,QAAO,SAASA,MAAI,GAAG,IAAI,WAAWA,MAAI,QAAQA,MAAI,YAAYA,MAAI,cAAcA;AACrF;AAED,MAAM,WAAW,YAOb,CAAC,OAAO,OAAO,QAAQ;AACrB,QAAO,MAAM,QAAQ,KAGnB,WAAW,OAAO,KAAK,MAAM,SAAS,OAAO,IAAI,CAAC,CAAC,SAAS,OAAO,GACjE,UAAU,OAAO,OAAO,IAAI;AACjC,IAQD,CAAC,OAAO,OAAO,QAAQ;AACrB,QAAO,MAAM,QAAQ,KACjB,YAAY,OAAO,MAAM,SAAS,OAAO,IAAI,CAAC,GAC9C,UAAU,OAAO,OAAO,IAAI;AACjC;AAEL,MAAM,aAAa,YAKf,CAAC,WAAW;AACV,QAAO,OAAO,SAAS,KAGrB,WAAW,OAAO,KAAK,OAAO,GAC5B,YAAY,OAAO;AACxB,IAMD,CAAC,WAAW;AACV,QAAO,OAAO,SAAS,KAAK,YAAY,OAAO,OAAO,GAAG,YAAY,OAAO;AAC7E;;;;;;AAOL,MAAM,YAAY,CAAC,QAAQ;AACzB,QAAO,WAAW,KAAK,IAAI;AAC5B;AAED,MAAM,QAAQ,YAOV,CAAC,OAAO,OAAO,QAAQ;AACrB,KAAI,SAAS,MAAM,CACjB,QAAO,IAAI,WAAW,MAAM,SAAS,OAAO,IAAI;AAElD,QAAO,MAAM,MAAM,OAAO,IAAI;AAC/B,IAQD,CAAC,OAAO,OAAO,QAAQ;AACrB,QAAO,MAAM,MAAM,OAAO,IAAI;AAC/B;AAEL,MAAM,SAAS,YAOX,CAAC,QAAQ,WAAW;AAGlB,UAAS,OAAO,IAAI,CAAC,MAAM,aAAa,aACpC,IAKF,WAAW,OAAO,KAAK,EAAE,CAAC;AAE5B,QAAO,MAAM,WAAW,OAAO,OAAO,QAAQ,OAAO,CAAC;AACvD,IAQD,CAAC,QAAQ,WAAW;CAClB,MAAM,MAAM,IAAI,WAAW;CAC3B,IAAI,MAAM;AACV,MAAK,IAAI,KAAK,QAAQ;AACpB,MAAI,MAAM,EAAE,SAAS,IAAI,OAEvB,KAAI,EAAE,SAAS,GAAG,IAAI,SAAS,IAAI;AAErC,MAAI,IAAI,GAAG,IAAI;AACf,SAAO,EAAE;CACV;AACD,QAAO;AACR;AAEL,MAAM,QAAQ,YAMV,CAAC,SAAS;AAGR,QAAO,WAAW,OAAO,YAAY,KAAK;AAC3C,IAOD,CAAC,SAAS;AACR,QAAO,IAAI,WAAW;AACvB;;;;;;AAOL,SAAS,QAAS,IAAI,IAAI;AAExB,KAAI,SAAS,GAAG,IAAI,SAAS,GAAG,CAG9B,QAAO,GAAG,QAAQ,GAAG;AAEvB,MAAK,IAAI,IAAI,GAAG,IAAI,GAAG,QAAQ,KAAK;AAClC,MAAI,GAAG,OAAO,GAAG,GACf;AAEF,SAAO,GAAG,KAAK,GAAG,KAAK,KAAK;CAC7B;AACD,QAAO;AACR;;;;;AASD,SAAS,YAAa,KAAK;CACzB,MAAM,MAAM,CAAE;CACd,IAAI,IAAI;AACR,MAAK,IAAI,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK;EACnC,IAAI,IAAI,IAAI,WAAW,EAAE;AACzB,MAAI,IAAI,IACN,KAAI,OAAO;SACF,IAAI,MAAM;AACnB,OAAI,OAAQ,KAAK,IAAK;AACtB,OAAI,OAAQ,IAAI,KAAM;EACvB,YACG,IAAI,WAAY,SAAY,IAAI,IAAK,IAAI,WACzC,IAAI,WAAW,IAAI,EAAE,GAAG,WAAY,OAAS;AAE/C,OAAI,UAAY,IAAI,SAAW,OAAO,IAAI,WAAW,EAAE,EAAE,GAAG;AAC5D,OAAI,OAAQ,KAAK,KAAM;AACvB,OAAI,OAAS,KAAK,KAAM,KAAM;AAC9B,OAAI,OAAS,KAAK,IAAK,KAAM;AAC7B,OAAI,OAAQ,IAAI,KAAM;EACvB,OAAM;AACL,OAAI,OAAQ,KAAK,KAAM;AACvB,OAAI,OAAS,KAAK,IAAK,KAAM;AAC7B,OAAI,OAAQ,IAAI,KAAM;EACvB;CACF;AACD,QAAO;AACR;;;;;;;AAWD,SAAS,UAAWA,OAAK,QAAQ,KAAK;CACpC,MAAM,MAAM,CAAE;AAEd,QAAO,SAAS,KAAK;EACnB,MAAM,YAAYA,MAAI;EACtB,IAAI,YAAY;EAChB,IAAI,mBAAoB,YAAY,MAAQ,IAAK,YAAY,MAAQ,IAAK,YAAY,MAAQ,IAAI;AAElG,MAAI,SAAS,oBAAoB,KAAK;GACpC,IAAI,YAAY,WAAW,YAAY;AAEvC,WAAQ,kBAAR;AACE,SAAK;AACH,SAAI,YAAY,IACd,aAAY;AAEd;AACF,SAAK;AACH,kBAAaA,MAAI,SAAS;AAC1B,UAAK,aAAa,SAAU,KAAM;AAChC,uBAAiB,YAAY,OAAS,IAAO,aAAa;AAC1D,UAAI,gBAAgB,IAClB,aAAY;KAEf;AACD;AACF,SAAK;AACH,kBAAaA,MAAI,SAAS;AAC1B,iBAAYA,MAAI,SAAS;AACzB,UAAK,aAAa,SAAU,QAAS,YAAY,SAAU,KAAM;AAC/D,uBAAiB,YAAY,OAAQ,MAAO,aAAa,OAAS,IAAO,YAAY;AAErF,UAAI,gBAAgB,SAAU,gBAAgB,SAAU,gBAAgB,OACtE,aAAY;KAEf;AACD;AACF,SAAK;AACH,kBAAaA,MAAI,SAAS;AAC1B,iBAAYA,MAAI,SAAS;AACzB,kBAAaA,MAAI,SAAS;AAC1B,UAAK,aAAa,SAAU,QAAS,YAAY,SAAU,QAAS,aAAa,SAAU,KAAM;AAC/F,uBAAiB,YAAY,OAAQ,MAAQ,aAAa,OAAS,MAAO,YAAY,OAAS,IAAO,aAAa;AACnH,UAAI,gBAAgB,SAAU,gBAAgB,QAC5C,aAAY;KAEf;GACJ;EACF;AAGD,MAAI,cAAc,MAAM;AAGtB,eAAY;AACZ,sBAAmB;EACpB,WAAU,YAAY,OAAQ;AAE7B,gBAAa;AACb,OAAI,KAAK,cAAc,KAAK,OAAQ,MAAO;AAC3C,eAAY,QAAS,YAAY;EAClC;AAED,MAAI,KAAK,UAAU;AACnB,YAAU;CACX;AAED,QAAO,sBAAsB,IAAI;AAClC;AAKD,MAAM,uBAAuB;;;;;AAM7B,SAAS,sBAAuB,YAAY;CAC1C,MAAM,MAAM,WAAW;AACvB,KAAI,OAAO,qBACT,QAAO,OAAO,aAAa,MAAM,QAAQ,WAAW;CAItD,IAAI,MAAM;CACV,IAAI,IAAI;AACR,QAAO,IAAI,IACT,QAAO,OAAO,aAAa,MACzB,QACA,WAAW,MAAM,GAAG,KAAK,qBAAqB,CAC/C;AAEH,QAAO;AACR;;;;;;;;;;;;;;;;;AAwBD,MAAM,mBAAmB;IAEnB,KAAN,MAAS;;;;CAIP,YAAa,YAAY,kBAAkB;AACzC,OAAK,YAAY;;AAEjB,OAAK,SAAS;;AAEd,OAAK,YAAY;;AAEjB,OAAK,SAAS,CAAE;;AAGhB,OAAK,kBAAkB;CACxB;CAED,QAAS;AACP,OAAK,SAAS;AACd,OAAK,YAAY;AACjB,MAAI,KAAK,OAAO,OACd,MAAK,SAAS,CAAE;AAElB,MAAI,KAAK,oBAAoB,MAAM;AACjC,QAAK,OAAO,KAAK,KAAK,gBAAgB;AACtC,QAAK,YAAY,KAAK,gBAAgB,SAAS;EAChD;CACF;;;;CAKD,KAAM,OAAO;EACX,IAAI,WAAW,KAAK,OAAO,KAAK,OAAO,SAAS;EAChD,MAAM,SAAS,KAAK,SAAS,MAAM;AACnC,MAAI,UAAU,KAAK,YAAY,GAAG;GAEhC,MAAM,WAAW,SAAS,UAAU,KAAK,YAAY,KAAK,UAAU;AAEpE,YAAS,IAAI,OAAO,SAAS;EAC9B,OAAM;AAEL,OAAI,UAAU;IAEZ,MAAM,WAAW,SAAS,UAAU,KAAK,YAAY,KAAK,UAAU;AACpE,QAAI,WAAW,SAAS,QAAQ;AAE9B,UAAK,OAAO,KAAK,OAAO,SAAS,KAAK,SAAS,SAAS,GAAG,SAAS;AACpE,UAAK,YAAY,KAAK,SAAS;IAChC;GACF;AACD,OAAI,MAAM,SAAS,MAAM,MAAM,SAAS,KAAK,WAAW;AAEtD,eAAW,MAAM,KAAK,UAAU;AAChC,SAAK,OAAO,KAAK,SAAS;AAC1B,SAAK,aAAa,SAAS;AAC3B,QAAI,KAAK,oBAAoB,KAC3B,MAAK,kBAAkB;AAGzB,aAAS,IAAI,OAAO,EAAE;GACvB,OAAM;AAEL,SAAK,OAAO,KAAK,MAAM;AACvB,SAAK,aAAa,MAAM;GACzB;EACF;AACD,OAAK,UAAU,MAAM;CACtB;;;;;CAMD,QAAS,QAAQ,OAAO;EACtB,IAAI;AACJ,MAAI,KAAK,OAAO,WAAW,GAAG;GAC5B,MAAM,QAAQ,KAAK,OAAO;AAC1B,OAAI,SAAS,KAAK,SAAS,MAAM,SAAS,GAAG;AAG3C,WAAO,KAAK,WAAW,MAAM,SAAS,QAAQ,MAAM,SAAS,GAAG,KAAK,OAAO;AAC5E,SAAK,kBAAkB;AACvB,SAAK,SAAS,CAAE;GACjB,MAEC,QAAO,MAAM,OAAO,GAAG,KAAK,OAAO;EAEtC,MAEC,QAAO,OAAO,KAAK,QAAQ,KAAK,OAAO;AAEzC,MAAI,MACF,MAAK,OAAO;AAEd,SAAO;CACR;AACF;AAED,MAAM,kBAAkB;AACxB,MAAM,kBAAkB;;;;;;AAOxB,SAAS,iBAAkB,MAAM,KAAK,MAAM;AAC1C,KAAI,KAAK,SAAS,MAAM,KACtB,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAEtC;AAKD,MAAM,iBAAiB;CAAC;CAAI;CAAK;CAAO;CAAY,OAAO,uBAAuB;AAAC;;;;;;;;;;;AAanF,SAAS,UAAW,MAAM,QAAQ,SAAS;AACzC,kBAAiB,MAAM,QAAQ,EAAE;CACjC,MAAM,QAAQ,KAAK;AACnB,KAAI,QAAQ,WAAW,QAAQ,QAAQ,eAAe,GACpD,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO;AACR;;;;;;;AAQD,SAAS,WAAY,MAAM,QAAQ,SAAS;AAC1C,kBAAiB,MAAM,QAAQ,EAAE;CACjC,MAAM,QAAS,KAAK,WAAW,IAAK,KAAK,SAAS;AAClD,KAAI,QAAQ,WAAW,QAAQ,QAAQ,eAAe,GACpD,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO;AACR;;;;;;;AAQD,SAAS,WAAY,MAAM,QAAQ,SAAS;AAC1C,kBAAiB,MAAM,QAAQ,EAAE;CACjC,MAAM,QAAS,KAAK,UAAU,YAA2B,KAAK,SAAS,MAAM,OAAO,KAAK,SAAS,MAAM,KAAK,KAAK,SAAS;AAC3H,KAAI,QAAQ,WAAW,QAAQ,QAAQ,eAAe,GACpD,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO;AACR;;;;;;;AAQD,SAAS,WAAY,MAAM,QAAQ,SAAS;AAE1C,kBAAiB,MAAM,QAAQ,EAAE;CACjC,MAAM,KAAM,KAAK,UAAU,YAA2B,KAAK,SAAS,MAAM,OAAO,KAAK,SAAS,MAAM,KAAK,KAAK,SAAS;CACxH,MAAM,KAAM,KAAK,SAAS,KAAK,YAA2B,KAAK,SAAS,MAAM,OAAO,KAAK,SAAS,MAAM,KAAK,KAAK,SAAS;CAC5H,MAAM,SAAS,OAAO,GAAG,IAAI,OAAO,GAAG,IAAI,OAAO,GAAG;AACrD,KAAI,QAAQ,WAAW,QAAQ,QAAQ,eAAe,GACpD,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,KAAI,SAAS,OAAO,iBAClB,QAAO,OAAO,MAAM;AAEtB,KAAI,QAAQ,gBAAgB,KAC1B,QAAO;AAET,OAAM,IAAI,OAAO,EAAE,gBAAgB;AACpC;;;;;;;;AAgBD,SAAS,YAAa,MAAM,KAAK,QAAQ,SAAS;AAChD,QAAO,IAAI,MAAMD,OAAK,MAAM,UAAU,MAAM,MAAM,GAAG,QAAQ,EAAE;AAChE;;;;;;;;AASD,SAAS,aAAc,MAAM,KAAK,QAAQ,SAAS;AACjD,QAAO,IAAI,MAAMA,OAAK,MAAM,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE;AACjE;;;;;;;;AASD,SAAS,aAAc,MAAM,KAAK,QAAQ,SAAS;AACjD,QAAO,IAAI,MAAMA,OAAK,MAAM,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE;AACjE;;;;;;;;AASD,SAAS,aAAc,MAAM,KAAK,QAAQ,SAAS;AACjD,QAAO,IAAI,MAAMA,OAAK,MAAM,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE;AACjE;;;;;AAMD,SAAS,WAAYC,OAAK,OAAO;AAC/B,QAAO,gBAAgBA,OAAK,GAAG,MAAM,MAAM;AAC5C;;;;;;AAOD,SAAS,gBAAiBA,OAAK,OAAO,MAAM;AAC1C,KAAI,OAAO,eAAe,IAAI;EAC5B,MAAM,QAAQ,OAAO,KAAK;AAE1B,QAAI,KAAK,CAAC,QAAQ,KAAM,EAAC;CAC1B,WAAU,OAAO,eAAe,IAAI;EACnC,MAAM,QAAQ,OAAO,KAAK;AAE1B,QAAI,KAAK,CAAC,QAAQ,IAAI,KAAM,EAAC;CAC9B,WAAU,OAAO,eAAe,IAAI;EACnC,MAAM,QAAQ,OAAO,KAAK;AAE1B,QAAI,KAAK;GAAC,QAAQ;GAAI,UAAU;GAAG,QAAQ;EAAK,EAAC;CAClD,WAAU,OAAO,eAAe,IAAI;EACnC,MAAM,QAAQ,OAAO,KAAK;AAE1B,QAAI,KAAK;GAAC,QAAQ;GAAK,UAAU,KAAM;GAAO,UAAU,KAAM;GAAO,UAAU,IAAK;GAAM,QAAQ;EAAK,EAAC;CACzG,OAAM;EACL,MAAM,QAAQ,OAAO,KAAK;AAC1B,MAAI,QAAQ,eAAe,IAAI;GAE7B,MAAM,MAAM;IAAC,QAAQ;IAAI;IAAG;IAAG;IAAG;IAAG;IAAG;IAAG;GAAE;GAE7C,IAAI,KAAK,OAAO,QAAQ,OAAO,WAAW,CAAC;GAC3C,IAAI,KAAK,OAAO,SAAS,OAAO,GAAG,GAAG,OAAO,WAAW,CAAC;AACzD,OAAI,KAAK,KAAK;AACd,QAAK,MAAM;AACX,OAAI,KAAK,KAAK;AACd,QAAK,MAAM;AACX,OAAI,KAAK,KAAK;AACd,QAAK,MAAM;AACX,OAAI,KAAK,KAAK;AACd,OAAI,KAAK,KAAK;AACd,QAAK,MAAM;AACX,OAAI,KAAK,KAAK;AACd,QAAK,MAAM;AACX,OAAI,KAAK,KAAK;AACd,QAAK,MAAM;AACX,OAAI,KAAK,KAAK;AACd,SAAI,KAAK,IAAI;EACd,MACC,OAAM,IAAI,OAAO,EAAE,gBAAgB;CAEtC;AACF;;;;;AAMD,WAAW,cAAc,SAAS,YAAa,OAAO;AACpD,QAAO,gBAAgB,YAAY,MAAM,MAAM;AAChD;;;;;AAMD,gBAAgB,cAAc,SAAS,YAAa,MAAM;AACxD,KAAI,OAAO,eAAe,GACxB,QAAO;AAET,KAAI,OAAO,eAAe,GACxB,QAAO;AAET,KAAI,OAAO,eAAe,GACxB,QAAO;AAET,KAAI,OAAO,eAAe,GACxB,QAAO;AAET,QAAO;AACR;;;;;;AAOD,WAAW,gBAAgB,SAAS,cAAe,MAAM,MAAM;AAC7D,QAAO,KAAK,QAAQ,KAAK,QAAQ,KAAK,KAAK,QAAQ,KAAK,QAAQ,IAAyB;AAC1F;;;;;;;;;;;;AAiBD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,IAAI,MAAMD,OAAK,QAAQ,KAAK,UAAU,MAAM,MAAM,GAAG,QAAQ,EAAE;AACvE;;;;;;;;AASD,SAAS,eAAgB,MAAM,KAAK,QAAQ,SAAS;AACnD,QAAO,IAAI,MAAMA,OAAK,QAAQ,KAAK,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE;AACxE;;;;;;;;AASD,SAAS,eAAgB,MAAM,KAAK,QAAQ,SAAS;AACnD,QAAO,IAAI,MAAMA,OAAK,QAAQ,KAAK,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE;AACxE;AAED,MAAM,QAAQ,OAAO,GAAG;AACxB,MAAM,QAAQ,OAAO,EAAE;;;;;;;;AASvB,SAAS,eAAgB,MAAM,KAAK,QAAQ,SAAS;CACnD,MAAM,MAAM,WAAW,MAAM,MAAM,GAAG,QAAQ;AAC9C,YAAW,QAAQ,UAAU;EAC3B,MAAM,QAAQ,KAAK;AACnB,MAAI,SAAS,OAAO,iBAClB,QAAO,IAAI,MAAMA,OAAK,QAAQ,OAAO;CAExC;AACD,KAAI,QAAQ,gBAAgB,KAC1B,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,IAAI,MAAMA,OAAK,QAAQ,QAAQ,OAAO,IAAI,EAAE;AACpD;;;;;AAMD,SAAS,aAAcC,OAAK,OAAO;CACjC,MAAM,SAAS,MAAM;CACrB,MAAM,kBAAmB,WAAW,WAAY,SAAS,QAAQ,QAAU,SAAS,KAAK;AACzF,iBAAgBA,OAAK,MAAM,KAAK,cAAc,SAAS;AACxD;;;;;AAMD,aAAa,cAAc,SAAS,YAAa,OAAO;CACtD,MAAM,SAAS,MAAM;CACrB,MAAM,kBAAmB,WAAW,WAAY,SAAS,QAAQ,QAAU,SAAS,KAAK;AAGzF,KAAI,WAAW,eAAe,GAC5B,QAAO;AAET,KAAI,WAAW,eAAe,GAC5B,QAAO;AAET,KAAI,WAAW,eAAe,GAC5B,QAAO;AAET,KAAI,WAAW,eAAe,GAC5B,QAAO;AAET,QAAO;AACR;;;;;;AAOD,aAAa,gBAAgB,SAAS,cAAe,MAAM,MAAM;AAE/D,QAAO,KAAK,QAAQ,KAAK,QAAQ,IAAI,KAAK,QAAQ,KAAK,QAAQ,KAA0B;AAC1F;;;;;;;;;;;;AAcD,SAAS,UAAW,MAAM,KAAK,QAAQ,QAAQ;AAC7C,kBAAiB,MAAM,KAAK,SAAS,OAAO;CAC5C,MAAMA,QAAM,MAAM,MAAM,MAAM,QAAQ,MAAM,SAAS,OAAO;AAC5D,QAAO,IAAI,MAAMD,OAAK,OAAOC,OAAK,SAAS;AAC5C;;;;;;;;AASD,SAAS,mBAAoB,MAAM,KAAK,OAAO,UAAU;AACvD,QAAO,UAAU,MAAM,KAAK,GAAG,MAAM;AACtC;;;;;;;;AASD,SAAS,aAAc,MAAM,KAAK,QAAQ,SAAS;AACjD,QAAO,UAAU,MAAM,KAAK,GAAG,UAAU,MAAM,MAAM,GAAG,QAAQ,CAAC;AAClE;;;;;;;;AASD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,UAAU,MAAM,KAAK,GAAG,WAAW,MAAM,MAAM,GAAG,QAAQ,CAAC;AACnE;;;;;;;;AASD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,UAAU,MAAM,KAAK,GAAG,WAAW,MAAM,MAAM,GAAG,QAAQ,CAAC;AACnE;;;;;;;;AAUD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;CAClD,MAAM,IAAI,WAAW,MAAM,MAAM,GAAG,QAAQ;AAC5C,YAAW,MAAM,SACf,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,UAAU,MAAM,KAAK,GAAG,EAAE;AAClC;;;;;;;AAQD,SAAS,WAAY,OAAO;AAC1B,KAAI,MAAM,iBAAiB,UACzB,OAAM,eAAe,MAAM,SAASD,OAAK,SAAS,WAAW,MAAM,MAAM,GAAG,MAAM;AAGpF,QAAO,MAAM;AACd;;;;;AAMD,SAAS,YAAaC,OAAK,OAAO;CAChC,MAAM,QAAQ,WAAW,MAAM;AAC/B,iBAAgBA,OAAK,MAAM,KAAK,cAAc,MAAM,OAAO;AAC3D,OAAI,KAAK,MAAM;AAChB;;;;;AAMD,YAAY,cAAc,SAAS,YAAa,OAAO;CACrD,MAAM,QAAQ,WAAW,MAAM;AAC/B,QAAO,gBAAgB,YAAY,MAAM,OAAO,GAAG,MAAM;AAC1D;;;;;;AAOD,YAAY,gBAAgB,SAAS,cAAe,MAAM,MAAM;AAC9D,QAAO,aAAa,WAAW,KAAK,EAAE,WAAW,KAAK,CAAC;AACxD;;;;;;AAOD,SAAS,aAAc,IAAI,IAAI;AAC7B,QAAO,GAAG,SAAS,GAAG,SAAS,KAAK,GAAG,SAAS,GAAG,SAAS,IAAI,QAAQ,IAAI,GAAG;AAChF;;;;;;;;;;;;;AAeD,SAAS,UAAW,MAAM,KAAK,QAAQ,QAAQ,SAAS;CACtD,MAAM,YAAY,SAAS;AAC3B,kBAAiB,MAAM,KAAK,UAAU;CACtC,MAAM,MAAM,IAAI,MAAMD,OAAK,QAAQ,SAAS,MAAM,MAAM,QAAQ,MAAM,UAAU,EAAE;AAClF,KAAI,QAAQ,sBAAsB,KAChC,KAAI,YAAY,MAAM,MAAM,MAAM,QAAQ,MAAM,UAAU;AAE5D,QAAO;AACR;;;;;;;;AASD,SAAS,oBAAqB,MAAM,KAAK,OAAO,SAAS;AACvD,QAAO,UAAU,MAAM,KAAK,GAAG,OAAO,QAAQ;AAC/C;;;;;;;;AASD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,UAAU,MAAM,KAAK,GAAG,UAAU,MAAM,MAAM,GAAG,QAAQ,EAAE,QAAQ;AAC3E;;;;;;;;AASD,SAAS,eAAgB,MAAM,KAAK,QAAQ,SAAS;AACnD,QAAO,UAAU,MAAM,KAAK,GAAG,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE,QAAQ;AAC5E;;;;;;;;AASD,SAAS,eAAgB,MAAM,KAAK,QAAQ,SAAS;AACnD,QAAO,UAAU,MAAM,KAAK,GAAG,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE,QAAQ;AAC5E;;;;;;;;AAUD,SAAS,eAAgB,MAAM,KAAK,QAAQ,SAAS;CACnD,MAAM,IAAI,WAAW,MAAM,MAAM,GAAG,QAAQ;AAC5C,YAAW,MAAM,SACf,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,UAAU,MAAM,KAAK,GAAG,GAAG,QAAQ;AAC3C;AAED,MAAM,eAAe;;;;;;;;;;;;AAcrB,SAAS,UAAW,OAAO,MAAM,QAAQ,QAAQ;AAC/C,QAAO,IAAI,MAAMA,OAAK,OAAO,QAAQ;AACtC;;;;;;;;AASD,SAAS,mBAAoB,MAAM,KAAK,OAAO,UAAU;AACvD,QAAO,UAAU,MAAM,KAAK,GAAG,MAAM;AACtC;;;;;;;;AASD,SAAS,aAAc,MAAM,KAAK,QAAQ,SAAS;AACjD,QAAO,UAAU,MAAM,KAAK,GAAG,UAAU,MAAM,MAAM,GAAG,QAAQ,CAAC;AAClE;;;;;;;;AASD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,UAAU,MAAM,KAAK,GAAG,WAAW,MAAM,MAAM,GAAG,QAAQ,CAAC;AACnE;;;;;;;;AASD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,UAAU,MAAM,KAAK,GAAG,WAAW,MAAM,MAAM,GAAG,QAAQ,CAAC;AACnE;;;;;;;;AAUD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;CAClD,MAAM,IAAI,WAAW,MAAM,MAAM,GAAG,QAAQ;AAC5C,YAAW,MAAM,SACf,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,UAAU,MAAM,KAAK,GAAG,EAAE;AAClC;;;;;;;;AASD,SAAS,sBAAuB,MAAM,KAAK,QAAQ,SAAS;AAC1D,KAAI,QAAQ,oBAAoB,MAC9B,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,UAAU,MAAM,KAAK,GAAG,SAAS;AACzC;;;;;AAMD,SAAS,YAAaC,OAAK,OAAO;AAChC,iBAAgBA,OAAKD,OAAK,MAAM,cAAc,MAAM,MAAM;AAC3D;AAID,YAAY,gBAAgB,WAAW;;;;;AAMvC,YAAY,cAAc,SAAS,YAAa,OAAO;AACrD,QAAO,gBAAgB,YAAY,MAAM,MAAM;AAChD;;;;;;;;;;;;AAcD,SAAS,QAAS,OAAO,MAAM,QAAQ,QAAQ;AAC7C,QAAO,IAAI,MAAMA,OAAK,KAAK,QAAQ;AACpC;;;;;;;;AASD,SAAS,iBAAkB,MAAM,KAAK,OAAO,UAAU;AACrD,QAAO,QAAQ,MAAM,KAAK,GAAG,MAAM;AACpC;;;;;;;;AASD,SAAS,WAAY,MAAM,KAAK,QAAQ,SAAS;AAC/C,QAAO,QAAQ,MAAM,KAAK,GAAG,UAAU,MAAM,MAAM,GAAG,QAAQ,CAAC;AAChE;;;;;;;;AASD,SAAS,YAAa,MAAM,KAAK,QAAQ,SAAS;AAChD,QAAO,QAAQ,MAAM,KAAK,GAAG,WAAW,MAAM,MAAM,GAAG,QAAQ,CAAC;AACjE;;;;;;;;AASD,SAAS,YAAa,MAAM,KAAK,QAAQ,SAAS;AAChD,QAAO,QAAQ,MAAM,KAAK,GAAG,WAAW,MAAM,MAAM,GAAG,QAAQ,CAAC;AACjE;;;;;;;;AAUD,SAAS,YAAa,MAAM,KAAK,QAAQ,SAAS;CAChD,MAAM,IAAI,WAAW,MAAM,MAAM,GAAG,QAAQ;AAC5C,YAAW,MAAM,SACf,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,QAAQ,MAAM,KAAK,GAAG,EAAE;AAChC;;;;;;;;AASD,SAAS,oBAAqB,MAAM,KAAK,QAAQ,SAAS;AACxD,KAAI,QAAQ,oBAAoB,MAC9B,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,QAAQ,MAAM,KAAK,GAAG,SAAS;AACvC;;;;;AAMD,SAAS,UAAWC,OAAK,OAAO;AAC9B,iBAAgBA,OAAKD,OAAK,IAAI,cAAc,MAAM,MAAM;AACzD;AAID,UAAU,gBAAgB,WAAW;;;;;AAMrC,UAAU,cAAc,SAAS,YAAa,OAAO;AACnD,QAAO,gBAAgB,YAAY,MAAM,MAAM;AAChD;;;;;;;;;;;;AAcD,SAAS,iBAAkB,OAAO,MAAM,OAAO,UAAU;AACvD,QAAO,IAAI,MAAMA,OAAK,KAAK,OAAO;AACnC;;;;;;;;AASD,SAAS,WAAY,MAAM,KAAK,QAAQ,SAAS;AAC/C,QAAO,IAAI,MAAMA,OAAK,KAAK,UAAU,MAAM,MAAM,GAAG,QAAQ,EAAE;AAC/D;;;;;;;;AASD,SAAS,YAAa,MAAM,KAAK,QAAQ,SAAS;AAChD,QAAO,IAAI,MAAMA,OAAK,KAAK,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE;AAChE;;;;;;;;AASD,SAAS,YAAa,MAAM,KAAK,QAAQ,SAAS;AAChD,QAAO,IAAI,MAAMA,OAAK,KAAK,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE;AAChE;;;;;;;;AASD,SAAS,YAAa,MAAM,KAAK,QAAQ,SAAS;AAChD,QAAO,IAAI,MAAMA,OAAK,KAAK,WAAW,MAAM,MAAM,GAAG,QAAQ,EAAE;AAChE;;;;;AAMD,SAAS,UAAWC,OAAK,OAAO;AAC9B,iBAAgBA,OAAKD,OAAK,IAAI,cAAc,MAAM,MAAM;AACzD;AAED,UAAU,gBAAgB,WAAW;;;;;AAMrC,UAAU,cAAc,SAAS,YAAa,OAAO;AACnD,QAAO,gBAAgB,YAAY,MAAM,MAAM;AAChD;;;;;;AAYD,MAAM,cAAc;AACpB,MAAM,aAAa;AACnB,MAAM,aAAa;AACnB,MAAM,kBAAkB;;;;;;;;AASxB,SAAS,gBAAiB,OAAO,MAAM,QAAQ,SAAS;AACtD,KAAI,QAAQ,mBAAmB,MAC7B,OAAM,IAAI,OAAO,EAAE,gBAAgB;SAC1B,QAAQ,0BAA0B,KAC3C,QAAO,IAAI,MAAMA,OAAK,MAAM,MAAM;AAEpC,QAAO,IAAI,MAAMA,OAAK,WAAW,WAAW;AAC7C;;;;;;;;AASD,SAAS,YAAa,OAAO,MAAM,QAAQ,SAAS;AAClD,KAAI,QAAQ,oBAAoB,MAC9B,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,IAAI,MAAMA,OAAK,OAAO,WAAW;AACzC;;;;;;;AAQD,SAAS,YAAa,OAAO,OAAO,SAAS;AAC3C,KAAI,SAAS;AACX,MAAI,QAAQ,aAAa,SAAS,OAAO,MAAM,MAAM,CACnD,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,MAAI,QAAQ,kBAAkB,UAAU,UAAU,YAAY,UAAU,WACtE,OAAM,IAAI,OAAO,EAAE,gBAAgB;CAEtC;AACD,QAAO,IAAI,MAAMA,OAAK,OAAO,OAAO;AACrC;;;;;;;;AASD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,YAAY,YAAY,MAAM,MAAM,EAAE,EAAE,GAAG,QAAQ;AAC3D;;;;;;;;AASD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,YAAY,YAAY,MAAM,MAAM,EAAE,EAAE,GAAG,QAAQ;AAC3D;;;;;;;;AASD,SAAS,cAAe,MAAM,KAAK,QAAQ,SAAS;AAClD,QAAO,YAAY,YAAY,MAAM,MAAM,EAAE,EAAE,GAAG,QAAQ;AAC3D;;;;;;AAOD,SAAS,YAAaC,OAAK,OAAO,SAAS;CACzC,MAAM,QAAQ,MAAM;AAEpB,KAAI,UAAU,MACZ,OAAI,KAAK,CAACD,OAAK,MAAM,eAAe,WAAY,EAAC;SACxC,UAAU,KACnB,OAAI,KAAK,CAACA,OAAK,MAAM,eAAe,UAAW,EAAC;SACvC,UAAU,KACnB,OAAI,KAAK,CAACA,OAAK,MAAM,eAAe,UAAW,EAAC;SACvC,UAAU,UACnB,OAAI,KAAK,CAACA,OAAK,MAAM,eAAe,eAAgB,EAAC;KAChD;EACL,IAAI;EACJ,IAAI,UAAU;AACd,OAAK,WAAW,QAAQ,YAAY,MAAM;AACxC,iBAAc,MAAM;AACpB,aAAU,YAAY,MAAM,EAAE;AAC9B,OAAI,UAAU,WAAW,OAAO,MAAM,MAAM,EAAE;AAC5C,SAAK,KAAK;AACV,UAAI,KAAK,KAAK,MAAM,GAAG,EAAE,CAAC;AAC1B,cAAU;GACX,OAAM;AACL,kBAAc,MAAM;AACpB,cAAU,YAAY,MAAM,EAAE;AAC9B,QAAI,UAAU,SAAS;AACrB,UAAK,KAAK;AACV,WAAI,KAAK,KAAK,MAAM,GAAG,EAAE,CAAC;AAC1B,eAAU;IACX;GACF;EACF;AACD,OAAK,SAAS;AACZ,iBAAc,MAAM;AACpB,aAAU,YAAY,MAAM,EAAE;AAC9B,QAAK,KAAK;AACV,SAAI,KAAK,KAAK,MAAM,GAAG,EAAE,CAAC;EAC3B;CACF;AACF;;;;;;AAOD,YAAY,cAAc,SAAS,YAAa,OAAO,SAAS;CAC9D,MAAM,QAAQ,MAAM;AAEpB,KAAI,UAAU,SAAS,UAAU,QAAQ,UAAU,QAAQ,UAAU,UACnE,QAAO;AAGT,MAAK,WAAW,QAAQ,YAAY,MAAM;AACxC,gBAAc,MAAM;EACpB,IAAI,UAAU,YAAY,MAAM,EAAE;AAClC,MAAI,UAAU,WAAW,OAAO,MAAM,MAAM,CAC1C,QAAO;AAET,gBAAc,MAAM;AACpB,YAAU,YAAY,MAAM,EAAE;AAC9B,MAAI,UAAU,QACZ,QAAO;CAEV;AACD,QAAO;AACR;AAED,MAAM,SAAS,IAAI,YAAY;AAC/B,MAAM,WAAW,IAAI,SAAS,QAAQ;AACtC,MAAM,OAAO,IAAI,WAAW,QAAQ;;;;AAKpC,SAAS,cAAe,KAAK;AAC3B,KAAI,QAAQ,SACV,UAAS,UAAU,GAAG,OAAQ,MAAM;SAC3B,QAAQ,UACjB,UAAS,UAAU,GAAG,OAAQ,MAAM;SAC3B,OAAO,MAAM,IAAI,CAC1B,UAAS,UAAU,GAAG,OAAQ,MAAM;KAC/B;AACL,WAAS,WAAW,GAAG,IAAI;EAC3B,MAAM,SAAS,SAAS,UAAU,EAAE;EACpC,MAAM,YAAY,SAAS,eAAe;EAC1C,MAAM,WAAW,SAAS;AAG1B,MAAI,aAAa,IAEf,UAAS,UAAU,GAAG,OAAQ,MAAM;SAC3B,aAAa,EAEtB,UAAS,UAAU,IAAK,MAAM,eAAe,KAAO,YAAY,IAAK,MAAM;KACtE;GAEL,MAAM,kBAAkB,WAAW;AAGnC,OAAI,kBAAkB,IAKpB,UAAS,UAAU,GAAG,EAAE;SACf,kBAAkB,IAI3B,UAAS,UAAU,IAAK,SAAS,eAAe,KAAsB,KAAM,KAAK,iBAAmB,MAAM;IAE1G,UAAS,UAAU,IAAK,SAAS,eAAe,KAAQ,kBAAkB,MAAO,KAAO,YAAY,IAAK,MAAM;EAElH;CACF;AACF;;;;;;AAOD,SAAS,YAAaE,QAAM,KAAK;AAC/B,KAAIA,OAAK,SAAS,MAAM,EACtB,OAAM,IAAI,OAAO,EAAE,gBAAgB;CAGrC,MAAM,QAAQA,OAAK,QAAQ,KAAKA,OAAK,MAAM;AAC3C,KAAI,SAAS,MACX,QAAO;AAET,KAAI,SAAS,MACX,QAAO;AAET,KAAI,SAAS,MACX,QAAO;CAET,MAAM,MAAO,QAAQ,KAAM;CAC3B,MAAM,OAAO,OAAO;CACpB,IAAI;AACJ,KAAI,QAAQ,EACV,OAAM,OAAQ;SACL,QAAQ,GACjB,QAAO,OAAO,QAAS,MAAM,MAAM;IAInC,OAAM,SAAS,IAAI,WAAW;AAEhC,QAAQ,OAAO,SAAW,MAAM;AACjC;;;;AAKD,SAAS,cAAe,KAAK;AAC3B,UAAS,WAAW,GAAG,KAAK,MAAM;AACnC;;;;;;AAOD,SAAS,YAAaA,QAAM,KAAK;AAC/B,KAAIA,OAAK,SAAS,MAAM,EACtB,OAAM,IAAI,OAAO,EAAE,gBAAgB;CAErC,MAAM,UAAUA,OAAK,cAAc,KAAK;AACxC,QAAO,IAAI,SAASA,OAAK,QAAQ,QAAQ,GAAG,WAAW,GAAG,MAAM;AACjE;;;;AAKD,SAAS,cAAe,KAAK;AAC3B,UAAS,WAAW,GAAG,KAAK,MAAM;AACnC;;;;;;AAOD,SAAS,YAAaA,QAAM,KAAK;AAC/B,KAAIA,OAAK,SAAS,MAAM,EACtB,OAAM,IAAI,OAAO,EAAE,gBAAgB;CAErC,MAAM,UAAUA,OAAK,cAAc,KAAK;AACxC,QAAO,IAAI,SAASA,OAAK,QAAQ,QAAQ,GAAG,WAAW,GAAG,MAAM;AACjE;;;;;;AAOD,YAAY,gBAAgB,WAAW;;;;;;;;;AAiBvC,SAAS,aAAc,MAAM,KAAK,OAAO;AACvC,OAAM,IAAI,OAAO,EAAE,gBAAgB,8BAA8B,MAAM,cAAc,KAAK,SAAS,EAAE;AACtG;;;;;AAMD,SAAS,QAAS,KAAK;AACrB,QAAO,MAAM;AAAE,QAAM,IAAI,OAAO,EAAE,gBAAgB,GAAG,IAAI;CAAI;AAC9D;;AAGD,MAAM,OAAO,CAAE;AAGf,KAAK,IAAI,IAAI,GAAG,KAAK,IAAM,IACzB,MAAK,KAAK;AAEZ,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AAEb,KAAK,IAAI,IAAI,IAAM,KAAK,IAAM,IAC5B,MAAK,KAAK;AAEZ,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AAEb,KAAK,IAAI,IAAI,IAAM,KAAK,IAAM,IAC5B,MAAK,KAAK;AAEZ,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ;AACb,KAAK,MAAQ,QAAQ,oDAAoD;AAEzE,KAAK,IAAI,IAAI,IAAM,KAAK,KAAM,IAC5B,MAAK,KAAK;AAEZ,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ,QAAQ,oDAAoD;AAEzE,KAAK,IAAI,IAAI,KAAM,KAAK,KAAM,IAC5B,MAAK,KAAK;AAEZ,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AAEb,KAAK,IAAI,IAAI,KAAM,KAAK,KAAM,IAC5B,MAAK,KAAK;AAEZ,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AAEb,KAAK,IAAI,IAAI,KAAM,KAAK,KAAM,IAC5B,MAAK,KAAK;AAEZ,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AAEb,KAAK,IAAI,IAAI,KAAM,KAAK,KAAM,IAC5B,MAAK,KAAK,QAAQ,kCAAkC;AAEtD,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ,QAAQ,kCAAkC;AACvD,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;AACb,KAAK,OAAQ;;AAGb,MAAM,QAAQ,CAAE;AAEhB,KAAK,IAAI,IAAI,GAAG,IAAI,IAAI,IACtB,OAAM,KAAK,IAAI,MAAMF,OAAK,MAAM,GAAG;AAGrC,KAAK,IAAI,IAAI,IAAI,KAAK,KAAK,IACzB,OAAM,KAAK,KAAK,IAAI,MAAMA,OAAK,QAAQ,GAAG;AAG5C,MAAM,MAAQ,IAAI,MAAMA,OAAK,OAAO,IAAI,WAAW,IAAI;AAEvD,MAAM,MAAQ,IAAI,MAAMA,OAAK,QAAQ,IAAI;AAEzC,MAAM,OAAQ,IAAI,MAAMA,OAAK,OAAO,GAAG;AAEvC,MAAM,OAAQ,IAAI,MAAMA,OAAK,KAAK,GAAG;AAErC,MAAM,OAAQ,IAAI,MAAMA,OAAK,OAAO,OAAO;AAE3C,MAAM,OAAQ,IAAI,MAAMA,OAAK,MAAM,MAAM;AAEzC,MAAM,OAAQ,IAAI,MAAMA,OAAK,MAAM,MAAM;;;;;AAMzC,SAAS,iBAAkB,OAAO;AAChC,SAAQ,MAAM,MAAd;AACE,OAAKA,OAAK,MACR,QAAO,UAAU,CAAC,GAAK,EAAC;AAC1B,OAAKA,OAAK,KACR,QAAO,UAAU,CAAC,GAAK,EAAC;AAC1B,OAAKA,OAAK,KACR,QAAO,UAAU,CAAC,GAAK,EAAC;AAC1B,OAAKA,OAAK;AACR,QAAK,MAAM,MAAM,OACf,QAAO,UAAU,CAAC,EAAK,EAAC;AAE1B;AACF,OAAKA,OAAK;AACR,OAAI,MAAM,UAAU,GAClB,QAAO,UAAU,CAAC,EAAK,EAAC;AAE1B;AACF,OAAKA,OAAK;AACR,OAAI,MAAM,UAAU,EAClB,QAAO,UAAU,CAAC,GAAK,EAAC;AAI1B;AACF,OAAKA,OAAK;AACR,OAAI,MAAM,UAAU,EAClB,QAAO,UAAU,CAAC,GAAK,EAAC;AAI1B;AACF,OAAKA,OAAK;AACR,OAAI,MAAM,QAAQ,GAChB,QAAO,UAAU,CAAC,OAAO,MAAM,MAAM,AAAC,EAAC;AAEzC;AACF,OAAKA,OAAK,OACR,KAAI,MAAM,SAAS,IACjB,QAAO,UAAU,CAAC,KAAK,OAAO,MAAM,MAAM,AAAC,EAAC;CAEjD;AACF;;;;;;;;;;AAYD,MAAM,uBAAuB;CAC3B,SAAS;CACT;CACA;AACD;;AAGD,SAAS,mBAAoB;CAC3B,MAAM,WAAW,CAAE;AACnB,UAASA,OAAK,KAAK,SAAS;AAC5B,UAASA,OAAK,OAAO,SAAS;AAC9B,UAASA,OAAK,MAAM,SAAS;AAC7B,UAASA,OAAK,OAAO,SAAS;AAC9B,UAASA,OAAK,MAAM,SAAS;AAC7B,UAASA,OAAK,IAAI,SAAS;AAC3B,UAASA,OAAK,IAAI,SAAS;AAC3B,UAASA,OAAK,MAAM,SAAS;AAC7B,QAAO;AACR;AAED,MAAM,eAAe,kBAAkB;AAEvC,MAAM,MAAM,IAAI;IAGV,MAAN,MAAM,IAAI;;;;;CAKR,YAAa,KAAK,QAAQ;AACxB,OAAK,MAAM;AACX,OAAK,SAAS;CACf;;;;;CAMD,SAAU,KAAK;;EAEb,IAAI,IAAI;AACR;AACE,OAAI,EAAE,QAAQ,IACZ,QAAO;SAEF,IAAI,EAAE;AACf,SAAO;CACR;;;;;;CAOD,OAAO,YAAa,OAAO,KAAK;AAC9B,MAAI,SAAS,MAAM,SAAS,IAAI,CAC9B,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,SAAO,IAAI,IAAI,KAAK;CACrB;AACF;AAED,MAAM,eAAe;CACnB,MAAM,IAAI,MAAMA,OAAK,MAAM;CAC3B,WAAW,IAAI,MAAMA,OAAK,WAAW;CACrC,MAAM,IAAI,MAAMA,OAAK,MAAM;CAC3B,OAAO,IAAI,MAAMA,OAAK,OAAO;CAC7B,YAAY,IAAI,MAAMA,OAAK,OAAO;CAClC,UAAU,IAAI,MAAMA,OAAK,KAAK;AAC/B;;AAGD,MAAM,eAAe;CAQnB,OAAQ,KAAK,MAAM,UAAU,WAAW;AACtC,OAAK,OAAO,UAAU,IAAI,KAAK,OAAO,cAAc,IAAI,CACtD,QAAO,IAAI,MAAMA,OAAK,OAAO;SACpB,OAAO,EAChB,QAAO,IAAI,MAAMA,OAAK,MAAM;IAE5B,QAAO,IAAI,MAAMA,OAAK,QAAQ;CAEjC;CASD,OAAQ,KAAK,MAAM,UAAU,WAAW;AACtC,MAAI,OAAO,OAAO,EAAE,CAClB,QAAO,IAAI,MAAMA,OAAK,MAAM;IAE5B,QAAO,IAAI,MAAMA,OAAK,QAAQ;CAEjC;CASD,WAAY,KAAK,MAAM,UAAU,WAAW;AAC1C,SAAO,IAAI,MAAMA,OAAK,OAAO;CAC9B;CASD,OAAQ,KAAK,MAAM,UAAU,WAAW;AACtC,SAAO,IAAI,MAAMA,OAAK,QAAQ;CAC/B;CASD,QAAS,KAAK,MAAM,UAAU,WAAW;AACvC,SAAO,MAAM,aAAa,OAAO,aAAa;CAC/C;CASD,KAAM,MAAM,MAAM,UAAU,WAAW;AACrC,SAAO,aAAa;CACrB;CASD,UAAW,MAAM,MAAM,UAAU,WAAW;AAC1C,SAAO,aAAa;CACrB;CASD,YAAa,KAAK,MAAM,UAAU,WAAW;AAC3C,SAAO,IAAI,MAAMA,OAAK,OAAO,IAAI,WAAW;CAC7C;CASD,SAAU,KAAK,MAAM,UAAU,WAAW;AACxC,SAAO,IAAI,MAAMA,OAAK,OAAO,IAAI,WAAW,IAAI,QAAQ,IAAI,YAAY,IAAI;CAC7E;CASD,MAAO,KAAK,MAAM,SAAS,UAAU;AACnC,OAAK,IAAI,QAAQ;AACf,OAAI,QAAQ,mBAAmB,KAC7B,QAAO,CAAC,aAAa,YAAY,IAAI,MAAMA,OAAK,MAAO;AAEzD,UAAO,aAAa;EACrB;AACD,aAAW,IAAI,YAAY,UAAU,IAAI;EACzC,MAAM,UAAU,CAAE;EAClB,IAAI,IAAI;AACR,OAAK,MAAM,KAAK,IACd,SAAQ,OAAO,eAAe,GAAG,SAAS,SAAS;AAErD,MAAI,QAAQ,eACV,QAAO;GAAC,IAAI,MAAMA,OAAK,OAAO,IAAI;GAAS;GAAS,IAAI,MAAMA,OAAK;EAAO;AAE5E,SAAO,CAAC,IAAI,MAAMA,OAAK,OAAO,IAAI,SAAS,OAAQ;CACpD;CASD,OAAQ,KAAK,KAAK,SAAS,UAAU;EAEnC,MAAM,QAAQ,QAAQ;EAEtB,MAAM,OAAO,QAAQ,IAAI,MAAM,GAAG,OAAO,KAAK,IAAI;EAClD,MAAM,SAAS,QAAQ,IAAI,OAAO,KAAK;AACvC,OAAK,QAAQ;AACX,OAAI,QAAQ,mBAAmB,KAC7B,QAAO,CAAC,aAAa,UAAU,IAAI,MAAMA,OAAK,MAAO;AAEvD,UAAO,aAAa;EACrB;AACD,aAAW,IAAI,YAAY,UAAU,IAAI;;EAEzC,MAAM,UAAU,CAAE;EAClB,IAAI,IAAI;AACR,OAAK,MAAM,OAAO,KAChB,SAAQ,OAAO,CACb,eAAe,KAAK,SAAS,SAAS,EACtC,eAAe,QAAQ,IAAI,IAAI,IAAI,GAAG,IAAI,MAAM,SAAS,SAAS,AACnE;AAEH,iBAAe,SAAS,QAAQ;AAChC,MAAI,QAAQ,eACV,QAAO;GAAC,IAAI,MAAMA,OAAK,KAAK;GAAS;GAAS,IAAI,MAAMA,OAAK;EAAO;AAEtE,SAAO,CAAC,IAAI,MAAMA,OAAK,KAAK,SAAS,OAAQ;CAC9C;AACF;AAED,aAAa,MAAM,aAAa;AAChC,aAAa,SAAS,aAAa;AACnC,KAAK,MAAM,OAAO,iFAAiF,MAAM,IAAI,CAC3G,eAAc,EAAE,IAAI,UAAU,aAAa;;;;;;;AAS7C,SAAS,eAAgB,KAAK,UAAU,CAAE,GAAE,UAAU;CACpD,MAAM,MAAM,GAAG,IAAI;CACnB,MAAM,oBAAqB,WAAW,QAAQ,gBAAmD,QAAQ,aAAa,QAAS,aAAa;AAC5I,YAAW,sBAAsB,YAAY;EAC3C,MAAM,SAAS,kBAAkB,KAAK,KAAK,SAAS,SAAS;AAC7D,MAAI,UAAU,KACZ,QAAO;CAEV;CACD,MAAM,cAAc,aAAa;AACjC,MAAK,YACH,OAAM,IAAI,OAAO,EAAE,gBAAgB,qBAAqB,IAAI;AAE9D,QAAO,YAAY,KAAK,KAAK,SAAS,SAAS;AAChD;;;;;AAyED,SAAS,eAAgB,SAAS,SAAS;AACzC,KAAI,QAAQ,UACV,SAAQ,KAAK,QAAQ,UAAU;AAElC;;;;;;AAOD,SAAS,UAAW,IAAI,IAAI;CAI1B,MAAM,YAAY,MAAM,QAAQ,GAAG,GAAG,GAAG,GAAG,GAAG,KAAK,GAAG;CACvD,MAAM,YAAY,MAAM,QAAQ,GAAG,GAAG,GAAG,GAAG,GAAG,KAAK,GAAG;AAGvD,KAAI,UAAU,SAAS,UAAU,KAC/B,QAAO,UAAU,KAAK,QAAQ,UAAU,KAAK;CAG/C,MAAM,QAAQ,UAAU,KAAK;CAE7B,MAAM,OAAO,aAAa,OAAO,cAAc,WAAW,UAAU;AAEpE,KAAI,SAAS,EAGX,SAAQ,KAAK,wEAAwE;AAEvF,QAAO;AACR;;;;;;;AAQD,SAAS,gBAAiBC,OAAK,QAAQ,UAAU,SAAS;AACxD,KAAI,MAAM,QAAQ,OAAO,CACvB,MAAK,MAAM,SAAS,OAClB,iBAAgBA,OAAK,OAAO,UAAU,QAAQ;IAGhD,UAAS,OAAO,KAAK,OAAOA,OAAK,QAAQ,QAAQ;AAEpD;;;;;;;AAQD,SAAS,aAAc,MAAM,UAAU,SAAS;CAC9C,MAAM,SAAS,eAAe,MAAM,QAAQ;AAC5C,MAAK,MAAM,QAAQ,OAAO,IAAI,QAAQ,kBAAkB;EACtD,MAAM,aAAa,QAAQ,iBAAiB,OAAO;AACnD,MAAI,WACF,QAAO;EAET,MAAM,UAAU,SAAS,OAAO,KAAK;AACrC,MAAI,QAAQ,aAAa;GACvB,MAAM,OAAO,QAAQ,YAAY,QAAQ,QAAQ;GACjD,MAAMA,QAAM,IAAI,GAAG;AACnB,WAAQA,OAAK,QAAQ,QAAQ;AAG7B,OAAIA,MAAI,OAAO,WAAW,EACxB,OAAM,IAAI,OAAO,8CAA8C,OAAO;AAExE,UAAO,MAAMA,MAAI,OAAO,GAAG;EAC5B;CACF;AACD,KAAI,OAAO;AACX,iBAAgB,KAAK,QAAQ,UAAU,QAAQ;AAC/C,QAAO,IAAI,QAAQ,KAAK;AACzB;;;;;;AAOD,SAAS,OAAQ,MAAM,SAAS;AAC9B,WAAU,OAAO,OAAO,CAAE,GAAE,sBAAsB,QAAQ;AAC1D,QAAO,aAAa,MAAM,cAAc,QAAQ;AACjD;;;;;;AAQD,MAAM,uBAAuB;CAC3B,QAAQ;CACR,iBAAiB;CACjB,gBAAgB;CAChB,aAAa;AACd;IAKK,YAAN,MAAgB;;;;;CAKd,YAAa,MAAM,UAAU,CAAE,GAAE;AAC/B,OAAK,OAAO;AACZ,OAAK,OAAO;AACZ,OAAK,UAAU;CAChB;CAED,MAAO;AACL,SAAO,KAAK;CACb;CAED,OAAQ;AACN,SAAO,KAAK,QAAQ,KAAK,KAAK;CAC/B;CAED,OAAQ;EACN,MAAM,MAAM,KAAK,KAAK,KAAK;EAC3B,IAAI,QAAQ,MAAM;AAClB,MAAI,UAAU,WAAW;GACvB,MAAM,UAAU,KAAK;AAGrB,QAAK,QACH,OAAM,IAAI,OAAO,EAAE,gBAAgB,6BAA6B,QAAQ,EAAE,WAAW,IAAI,SAAS,GAAG,CAAC,SAAS,GAAG,IAAI,CAAC;GAEzH,MAAM,QAAQ,MAAM;AACpB,WAAQ,QAAQ,KAAK,MAAM,KAAK,MAAM,OAAO,KAAK,QAAQ;EAC3D;AAED,OAAK,QAAQ,MAAM;AACnB,SAAO;CACR;AACF;AAED,MAAM,OAAO,OAAO,IAAI,OAAO;AAC/B,MAAM,QAAQ,OAAO,IAAI,QAAQ;;;;;;;AAQjC,SAAS,aAAc,OAAO,WAAW,SAAS;CAChD,MAAM,MAAM,CAAE;AACd,MAAK,IAAI,IAAI,GAAG,IAAI,MAAM,OAAO,KAAK;EACpC,MAAM,QAAQ,eAAe,WAAW,QAAQ;AAChD,MAAI,UAAU,OAAO;AACnB,OAAI,MAAM,UAAU,SAElB;AAEF,SAAM,IAAI,OAAO,EAAE,gBAAgB;EACpC;AACD,MAAI,UAAU,KACZ,OAAM,IAAI,OAAO,EAAE,gBAAgB,2CAA2C,EAAE,aAAa,MAAM,MAAM;AAE3G,MAAI,KAAK;CACV;AACD,QAAO;AACR;;;;;;;AAQD,SAAS,WAAY,OAAO,WAAW,SAAS;CAC9C,MAAM,UAAU,QAAQ,YAAY;CACpC,MAAM,MAAM,UAAU,YAAY,CAAE;CACpC,MAAM,IAAI,UAAU,IAAI,QAAQ;AAChC,MAAK,IAAI,IAAI,GAAG,IAAI,MAAM,OAAO,KAAK;EACpC,MAAM,MAAM,eAAe,WAAW,QAAQ;AAC9C,MAAI,QAAQ,OAAO;AACjB,OAAI,MAAM,UAAU,SAElB;AAEF,SAAM,IAAI,OAAO,EAAE,gBAAgB;EACpC;AACD,MAAI,QAAQ,KACV,OAAM,IAAI,OAAO,EAAE,gBAAgB,yCAAyC,EAAE,sBAAsB,MAAM,MAAM;AAElH,MAAI,YAAY,eAAe,QAAQ,SACrC,OAAM,IAAI,OAAO,EAAE,gBAAgB,6CAA6C,IAAI;AAEtF,MAAI,QAAQ,2BAA2B,MAErC;OAAK,WAAW,EAAE,IAAI,IAAI,KAAO,WAAY,OAAO,IAClD,OAAM,IAAI,OAAO,EAAE,gBAAgB,yBAAyB,IAAI;EACjE;EAEH,MAAM,QAAQ,eAAe,WAAW,QAAQ;AAChD,MAAI,UAAU,KACZ,OAAM,IAAI,OAAO,EAAE,gBAAgB,yCAAyC,EAAE,wBAAwB,MAAM,MAAM;AAEpH,MAAI,QAEF,GAAE,IAAI,KAAK,MAAM;IAGjB,KAAI,OAAO;CAEd;AAED,QAAO,UAAU,IAAI;AACtB;;;;;;AAOD,SAAS,eAAgB,WAAW,SAAS;AAG3C,KAAI,UAAU,MAAM,CAClB,QAAO;CAGT,MAAM,QAAQ,UAAU,MAAM;AAE9B,KAAI,MAAM,SAASD,OAAK,MACtB,QAAO;AAGT,KAAI,MAAM,KAAK,SACb,QAAO,MAAM;AAGf,KAAI,MAAM,SAASA,OAAK,MACtB,QAAO,aAAa,OAAO,WAAW,QAAQ;AAGhD,KAAI,MAAM,SAASA,OAAK,IACtB,QAAO,WAAW,OAAO,WAAW,QAAQ;AAG9C,KAAI,MAAM,SAASA,OAAK,KAAK;AAC3B,MAAI,QAAQ,eAAe,QAAQ,KAAK,MAAM,WAAW,YAAY;GACnE,MAAM,SAAS,eAAe,WAAW,QAAQ;AACjD,UAAO,QAAQ,KAAK,MAAM,OAAO,OAAO;EACzC;AACD,QAAM,IAAI,OAAO,EAAE,gBAAgB,sBAAsB,MAAM,MAAM;CACtE;AAED,OAAM,IAAI,MAAM;AACjB;;;;;;AAOD,SAAS,YAAa,MAAM,SAAS;AACnC,OAAM,gBAAgB,YACpB,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,WAAU,OAAO,OAAO,CAAE,GAAE,sBAAsB,QAAQ;CAC1D,MAAM,YAAY,QAAQ,aAAa,IAAI,UAAU,MAAM;CAC3D,MAAM,UAAU,eAAe,WAAW,QAAQ;AAClD,KAAI,YAAY,KACd,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,KAAI,YAAY,MACd,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO,CAAC,SAAS,KAAK,SAAS,UAAU,KAAK,CAAC,AAAC;AACjD;;;;;;AAOD,SAAS,OAAQ,MAAM,SAAS;CAC9B,MAAM,CAAC,SAAS,UAAU,GAAG,YAAY,MAAM,QAAQ;AACvD,KAAI,UAAU,SAAS,EACrB,OAAM,IAAI,OAAO,EAAE,gBAAgB;AAErC,QAAO;AACR;;;;ICzjFY,wBAAN,MAA4B;CAClC,AAAiB;CAEjB,YAAY,GAAG,MAAgD;EAC9D,MAAMG,WAA+D,IAAI;AACzE,OAAK,MAAM,EAAE,KAAK,SAAS,IAAI,MAAM;GACpC,MAAM,MAAM,UAAU,IAAI;AAC1B,YAAS,IAAI,KAAK,QAAQ;EAC1B;AACD,OAAK,WAAW,UAAU,SAAS;CACnC;CAED,IAAiCC,SAAwD;EACxF,MAAM,SAAS,UAAU,QAAQ;AAEjC,SAAO,KAAK,SAAS,IAAI,OAAO;CAChC;AACD;IAkBY,kCAAN,MAAmF;CACzF,YAA6BC,kBAAoC;EAiEjE,KAjE6B;CAAsC;CAEnE,MAAM,UAAUC,SAAuBC,QAAYC,OAAWC,OAAeC,SAA4C;EACxH,MAAM,QAAQ,MAAM,QAAQ,gBAAgB,sBAAsB,OAAO;EAGzE,IAAIC,UAAgC,CAAE;AACtC,MAAI,SAAS,MAAM;GAClB,IAAIC,QAA8B,CAAE;GACpC,IAAI,aAAa;AACjB,UAAO,MAAM;AACZ,YAAQ,MAAM,KAAK,iBAAiB,UAAU,sBAAsB,QAAQ,YAAY,qBAAqB,MAAM;AACnH,YAAQ,KAAK,GAAG,MAAM;AACtB,QAAI,MAAM,SAAS,oBAAqB;AACxC,iBAAa,aAAa,MAAM,MAAM,SAAS,GAAG;GAClD;AACD,QAAK,MAAM,SAAS,QACnB,OAAM,QAAQ,IAAI,MAAM;AAIzB,SAAM,QAAQ,mBAAmB,sBAAsB,QAAQ,eAAe,cAAc;EAC5F,OAAM;AACN,QAAK,mBAAmB,MAAM;AAC9B,aAAU,MAAM,QAAQ,aAAa,sBAAsB,OAAO;AAClE,WAAQ,KAAK,qBAAqB,OAAO,OAAO,QAAQ,OAAO,SAAS;EACxE;EACD,MAAM,YAAY,MAAM,qBAAqB,qBAAqB;EAClE,MAAM,aAAa,UAChB,QACC,OAAO,CAAC,kBAAkB,sBAAsB,OAAO,aAAa,cAAc,EAAE,UAAU,CAAC,CAC/F,KAAK,CAAC,GAAG,MAAO,sBAAsB,aAAa,EAAE,EAAE,aAAa,EAAE,EAAE,UAAU,GAAG,IAAI,GAAI,GAC9F,QACC,OAAO,CAAC,kBAAkB,sBAAsB,aAAa,cAAc,EAAE,OAAO,UAAU,CAAC,CAC/F,KAAK,CAAC,GAAG,MAAO,sBAAsB,aAAa,EAAE,EAAE,aAAa,EAAE,EAAE,UAAU,GAAG,IAAI,GAAI;AACjG,SAAO,WAAW,MAAM,GAAG,MAAM;CACjC;CAED,AAAQ,mBAAmBC,OAAc;AACxC,MAAI,MAAM,UAAU,iBAAiB,MAAM,UAAU,cACpD,OAAM,IAAI,kBAAkB,mCAAmC,KAAK,UAAU,MAAM,CAAC;CAEtF;CAED,MAAM,0BAA0BP,SAAuBC,QAAYO,KAAoC;EACtG,MAAM,QAAQ,MAAM,QAAQ,gBAAgB,sBAAsB,OAAO;AACzE,MAAI,OAAO;AACV,QAAK,mBAAmB,MAAM;AAE9B,UAAO;EACP,MACA,QAAO,CAAE;CAEV;AACD;IAEY,8BAAN,MAAsE;CAC5E,MAAM,0BAA4C;AAKjD,SAAO;CACP;AACD;;;;;;;;ACjGD,MAAM,oBAAoB;AAE1B,SAAS,YAAYC,MAAYC,KAAaC,SAAoD;CACjG,MAAM,OAAO,KAAK,SAAS;AAC3B,QAAO,CAEN,IAAI,MAAMC,OAAK,KAAK,MACpB,IAAI,MAAM,OAAO,IAAIA,OAAK,SAASA,OAAK,MAAM,KAC9C;AACD;AAED,SAAS,YAAYC,OAAqB;AACzC,QAAO,IAAI,KAAK;AAChB;MAEYC,qBAAiE,OAAO,OAAO,EAC3F,MAAM,YACN,EAAC;MAGWC,qBAAyC,CAAC,MAAM;CAC5D,MAAMC,OAA2B,CAAE;AACnC,MAAK,OAAO;AACZ,QAAO;AACP,IAAG;AAmBJ,MAAM,mBAAmB,OAAO,OAAO;CAEtC,eACC;CAED,kBAAkB;CAClB,QAAQ;CACR,6BAA6B;CAC7B,UAAU;CACV,uBACC;AACD,EAAU;IAWE,iBAAN,MAAkE;CACxE,AAAQ,qBAAmD;CAC3D,AAAQ,SAAoB;CAC5B,AAAQ,gBAA+B;CAEvC,YACkBC,iBACAC,wBACAC,cACAC,UACAC,SAChB;EAkyBF,KAvyBkB;EAuyBjB,KAtyBiB;EAsyBhB,KAryBgB;EAqyBf,KApyBe;EAoyBd,KAnyBc;AAEjB,SAAO,2BAA2B,IAAI,QAAQ,EAAE,oCAAoC;CACpF;;;;CAKD,MAAM,KAAK,EAAE,QAAQ,aAAa,eAAe,kBAA0C,EAAoB;AAC9G,OAAK,SAAS;AACd,OAAK,gBAAgB;AACrB,MAAI,kBAAkB;AACrB,OAAI,WAAW,CACd,OAAM,KAAK,uBAAuB,yBAAyB,OAAO;AAEnE,SAAM,KAAK,gBAAgB,SAAS,OAAO;EAC3C;AAED,QAAM,KAAK,gBAAgB,OAAO,QAAQ,YAAY;AACtD,QAAM,KAAK,cAAc;AAEzB,MAAI;AACH,SAAM,KAAK,SAAS,QAAQ,MAAM,KAAK,gBAAgB;EACvD,SAAQ,GAAG;AACX,OAAI,aAAa,gBAAgB;AAChC,YAAQ,KAAK,8BAA8B,EAAE;AAC7C,UAAM,KAAK,eAAe,QAAQ,YAAY;AAC9C,UAAM,KAAK,SAAS,QAAQ,MAAM,KAAK,gBAAgB;GACvD,MACA,OAAM;EAEP;AAED,UAAQ,MAAM,KAAK,mBAAmB,EAAE,SAAS;CACjD;CAED,MAAc,eAAeC,QAAgBC,aAAwC;AACpF,UAAQ,KAAK,gCAAgC,OAAO,EAAE;AACtD,QAAM,KAAK,gBAAgB,SAAS;AACpC,QAAM,KAAK,gBAAgB,SAAS,OAAO;AAC3C,QAAM,KAAK,gBAAgB,OAAO,QAAQ,YAAY;AACtD,QAAM,KAAK,cAAc;CACzB;;;;CAKD,MAAM,SAAS;AACd,OAAK,SAAS;AACd,QAAM,KAAK,gBAAgB,SAAS;CACpC;CAED,MAAM,eAAeC,SAA8BC,QAAmBC,WAA8B;EACnG,MAAM,OAAO,UAAU,QAAQ;EAC/B,IAAIC;AACJ,cAAY,MAAM,qBAAqB,QAAQ;AAC/C,cAAY,gBAAgB,WAAW,UAAU;EACjD,IAAI;AACJ,UAAQ,UAAU,MAAlB;AACC,QAAKC,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;8BACA,UAAU;AACpC;AACD,QAAKA,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;2BACH,OAAO;8BACJ,UAAU;AACpC;AACD,QAAKA,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;2BACH,OAAO;8BACJ,UAAU;AACpC;AACD,WACC,OAAM,IAAI,MAAM;EACjB;AACD,QAAM,KAAK,gBAAgB,IAAI,eAAe,OAAO,eAAe,OAAO;CAC3E;CAED,MAAM,gBAAgBJ,SAA6C;EAClE,MAAM,OAAO,UAAU,QAAQ;EAC/B,IAAIG;AACJ,cAAY,MAAM,qBAAqB,QAAQ;EAC/C,IAAI;AACJ,UAAQ,UAAU,MAAlB;AACC,QAAKC,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;AAC1B;AACD,QAAKA,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;AAC1B,UAAM,KAAK,gBAAgB,IAAI,eAAe,OAAO,eAAe,OAAO;AAC3E,UAAM,KAAK,uBAAuB,KAAK;AACvC;AACD,QAAKA,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;AAC1B;AACD,WACC,OAAM,IAAI,MAAM;EACjB;AACD,QAAM,KAAK,gBAAgB,IAAI,eAAe,OAAO,eAAe,OAAO;CAC3E;CAED,MAAc,uBAAuBC,MAA6B;EACjE,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;0BAEN,KAAK;AAC7B,QAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;CAC7C;CAED,MAAM,IAA0BC,SAAqBL,QAAmBC,WAAkC;EACzG,MAAM,OAAO,UAAU,QAAQ;EAC/B,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AACrD,cAAY,gBAAgB,WAAW,UAAU;EACjD,IAAI;AACJ,UAAQ,UAAU,MAAlB;AACC,QAAKE,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;8BACA,UAAU;AACpC;AACD,QAAKA,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;2BACH,OAAO;8BACJ,UAAU;AACpC;AACD,QAAKA,KAAO;AACX,qBAAiB,IAAI;;yBAEA,KAAK;2BACH,OAAO;8BACJ,UAAU;AACpC;AACD,WACC,OAAM,IAAI,MAAM;EACjB;EACD,MAAM,SAAS,MAAM,KAAK,gBAAgB,IAAI,eAAe,OAAO,eAAe,OAAO;AAC1F,SAAO,QAAQ,SAAS,MAAM,KAAK,YAAY,SAAS,OAAO,OAAO,MAAoB,GAAG;CAC7F;CAED,MAAM,gBAA6CE,SAAqBC,QAAYC,YAAqC;AACxH,MAAI,WAAW,WAAW,EAAG,QAAO,CAAE;EACtC,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AACrD,eAAa,WAAW,IAAI,CAAC,OAAO,gBAAgB,WAAW,GAAG,CAAC;EAEnE,MAAM,OAAO,UAAU,QAAQ;EAC/B,MAAMC,iBAAgE,MAAM,KAAK,WAChF,oBAAoB,GACpB,YACA,CAAC,MAAM,IAAI;;uBAES,KAAK;sBACN,OAAO;0BACH,UAAU,EAAE,CAAC,EACpC;AACD,SAAO,MAAM,KAAK,gBACjB,SACA,eAAe,IAAI,CAAC,MAAM,EAAE,OAAO,MAAoB,CACvD;CACD;CAED,MAAM,cAA2CH,SAAqBC,QAAgC;EACrG,MAAM,OAAO,UAAU,QAAQ;EAC/B,MAAM,YAAY,MAAM,qBAAqB,QAAQ;EACrD,MAAM,QAAQ,MAAM,KAAK,SAAS,SAAS,OAAO;AAClD,MAAI,SAAS,KACZ,OAAM,IAAI,OAAO,sBAAsB,KAAK,YAAY,OAAO;EAEhE,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;0BAEN,KAAK;yBACN,OAAO;6BACH,MAAM,MAAM;iBACxB,cAAc,aAAa,MAAM,MAAM,CAAC;qBACpC,cAAc,aAAa,MAAM,MAAM,CAAC;EAC3D,MAAM,OAAO,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;AAC1D,SAAO,KAAK,IAAI,CAAC,QAAQ,oBAAoB,WAAW,IAAI,UAAU,MAAgB,CAAC;CACvF;;;;CAKD,MAAM,gBAA6CD,SAAqBC,QAAmC;EAC1G,IAAI,QAAQ,MAAM,KAAK,SAAS,SAAS,OAAO;AAChD,MAAI,SAAS,KAAM,QAAO;EAC1B,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AACrD,SAAO;GACN,OAAO,oBAAoB,WAAW,MAAM,MAAM;GAClD,OAAO,oBAAoB,WAAW,MAAM,MAAM;EAClD;CACD;CAED,MAAM,wBAAqDD,SAAqBC,QAAYL,WAAiC;EAC5H,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AACrD,cAAY,gBAAgB,WAAW,UAAU;EAEjD,MAAM,QAAQ,MAAM,KAAK,SAAS,SAAS,OAAO;AAClD,SAAO,SAAS,SAAS,sBAAsB,WAAW,MAAM,MAAM,KAAK,sBAAsB,MAAM,OAAO,UAAU;CACxH;CAED,MAAM,iBAA8CI,SAAqBC,QAAYG,OAAWC,OAAeC,SAAgC;EAC9I,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AACrD,UAAQ,gBAAgB,WAAW,MAAM;EACzC,MAAM,OAAO,UAAU,QAAQ;EAC/B,IAAI;AACJ,MAAI,QACH,kBAAiB,IAAI;;wBAEA,KAAK;0BACH,OAAO;iBAChB,cAAc,OAAO,YAAY,CAAC;iEACc,MAAM;IAEpE,kBAAiB,IAAI;;wBAEA,KAAK;0BACH,OAAO;iBAChB,cAAc,aAAa,MAAM,CAAC;+DACY,MAAM;EAEnE,MAAM,EAAE,OAAO,QAAQ,GAAG;EAC1B,MAAMH,iBAAgE,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;AACnH,SAAO,MAAM,KAAK,gBACjB,SACA,eAAe,IAAI,CAAC,MAAM,EAAE,OAAO,MAAoB,CACvD;CACD;CAED,MAAM,IAAII,gBAA2C;EACpD,MAAM,mBAAmB,KAAK,UAAU,eAAe;EACvD,IAAI,EAAE,QAAQ,WAAW,GAAG,SAAS,eAAe,IAAI;EACxD,MAAM,OAAO,UAAU,eAAe,MAAM;EAC5C,MAAM,aAAa,eAAe;EAClC,MAAM,YAAY,MAAM,qBAAqB,eAAe,MAAM;AAClE,cAAY,gBAAgB,WAAW,UAAU;EACjD,IAAIC;AACJ,UAAQ,UAAU,MAAlB;AACC,QAAKV,KAAO;AACX,qBAAiB,IAAI;;MAEnB,KAAK;MACL,UAAU;MACV,WAAW;MACX,iBAAiB;;AAEnB;AACD,QAAKA,KAAO;AACX,qBAAiB,IAAI;;MAEnB,KAAK;MACL,OAAO;MACP,UAAU;MACV,WAAW;MACX,iBAAiB;;AAEnB;AACD,QAAKA,KAAO;AACX,qBAAiB,IAAI;;MAEnB,KAAK;MACL,OAAO;MACP,UAAU;MACV,WAAW;MACX,iBAAiB;;AAEnB;AACD,WACC,OAAM,IAAI,MAAM;EACjB;AACD,QAAM,KAAK,gBAAgB,IAAI,eAAe,OAAO,eAAe,OAAO;CAC3E;CAED,MAAM,qBAAkDE,SAAqBC,QAAYQ,SAA4B;AACpH,YAAU,gBAAgB,MAAM,qBAAqB,QAAQ,EAAE,QAAQ;EACvE,MAAM,OAAO,UAAU,QAAQ;EAC/B,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;yBACP,QAAQ;0BACP,KAAK;yBACN,OAAO;AAC9B,QAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;CAC7C;CAED,MAAM,qBAAkDT,SAAqBC,QAAYS,SAA4B;AACpH,YAAU,gBAAgB,MAAM,qBAAqB,QAAQ,EAAE,QAAQ;EACvE,MAAM,OAAO,UAAU,QAAQ;EAC/B,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;yBACP,QAAQ;0BACP,KAAK;yBACN,OAAO;AAC9B,QAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;CAC7C;CAED,MAAM,mBAAgDV,SAAqBC,QAAYU,OAAWC,OAA0B;EAC3H,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AACrD,UAAQ,gBAAgB,WAAW,MAAM;AACzC,UAAQ,gBAAgB,WAAW,MAAM;EAEzC,MAAM,OAAO,UAAU,QAAQ;EAC/B,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;IAE5B,KAAK;IACL,OAAO;IACP,MAAM;IACN,MAAM;;AAER,SAAO,KAAK,gBAAgB,IAAI,OAAO,OAAO;CAC9C;CAED,MAAM,uBAAuBC,SAAiC;EAC7D,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;6BAEH,QAAQ;EACnC,MAAM,MAAO,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;AAC1D,SAAQ,KAAK,SAAS,SAAS;CAC/B;CAED,MAAM,uBAAuBA,SAAaC,SAA4B;EACrE,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;IAE5B,QAAQ;IACR,QAAQ;;AAEV,QAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;CAC7C;CAED,MAAM,oBAA6C;EAClD,MAAM,OAAO,MAAM,KAAK,YAAY,iBAAiB;AACrD,SAAO,OAAO;GAAE,MAAM;GAAY;EAAM,IAAG,EAAE,MAAM,QAAS;CAC5D;CAED,MAAM,kBAAkBC,IAA2B;AAClD,QAAM,KAAK,YAAY,kBAAkB,GAAG;CAC5C;CAED,MAAM,eAA8B;AACnC,OAAK,IAAI,QAAQ,OAAO,KAAK,iBAAiB,CAC7C,OAAM,KAAK,gBAAgB,KACzB;YACO,KAAK,GACb,CAAE,EACF;CAEF;CAED,MAAM,YAAYC,SAA2BC,QAA+B;EAC3E,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;0BAEN,UAAU,QAAQ,CAAC;yBACpB,OAAO;AAC9B,QAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;CAC7C;CAED,MAAM,yBAAyBC,SAAwE;EACtG,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;0BAEN,UAAU,QAAQ,CAAC;EAC3C,MAAM,QAAS,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO,IAAK,CAAE;AACnE,SAAO,MAAM,IAAI,CAAC,SAAS,KAAK,iBAAiB,KAAK,OAAO,MAAoB,CAAgD;CACjI;CAED,MAAM,qBAAqBC,SAAgE;EAC1F,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;0BAEN,UAAU,QAAQ,CAAC;EAC3C,MAAM,QAAS,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO,IAAK,CAAE;AACnE,SAAO,MAAM,IAAI,CAAC,SAAS,KAAK,iBAAiB,KAAK,OAAO,MAAoB,CAA4C;CAC7H;CAED,MAAM,kBAA2CnB,SAAwC;EACxF,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;0BAEN,UAAU,QAAQ,CAAC;EAC3C,MAAM,QAAS,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO,IAAK,CAAE;AACnE,SAAO,MAAM,KAAK,gBACjB,SACA,MAAM,IAAI,CAAC,QAAQ,IAAI,OAAO,MAAoB,CAClD;CACD;CAED,MAAM,aAA0CA,SAAqBC,QAA+B;EACnG,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;0BAEN,UAAU,QAAQ,CAAC;yBACpB,OAAO;EAC9B,MAAM,QAAS,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO,IAAK,CAAE;AACnE,SAAO,MAAM,KAAK,gBACjB,SACA,MAAM,IAAI,CAAC,QAAQ,IAAI,OAAO,MAAoB,CAClD;CACD;CAED,MAAM,eAAgD;EACrD,MAAM,QAAQ;EACd,MAAM,SAAS,CAAC,MAAM,KAAK,gBAAgB,IAAI,OAAO,CAAE,EAAC,EAAE,IAAI,CAAC,QAAQ,CAAC,IAAI,IAAI,OAAiB,IAAI,MAAM,KAAoB,EAAU;AAC1I,SAAO,OAAO,YAAY,OAAO,IAAI,CAAC,CAAC,KAAK,MAAM,KAAK,CAAC,KAAK,OAAa,MAAM,AAAC,EAAC,CAAC;CACnF;CAED,MAAM,sBAAsBmB,OAA+BC,SAAiB;AAC3E,SAAO,KAAK,aAAa,EAAE,MAAM,WAAW,QAAQ;CACpD;CAED,yBAAyBC,kBAA2D;AACnF,MAAI,KAAK,sBAAsB,KAC9B,MAAK,qBAAqB,IAAI,sBAC7B;GACC,KAAK;GACL,SAAS,IAAI,gCAAgC;EAC7C,GACD;GAAE,KAAK;GAAa,SAAS,IAAI;EAA+B;AAGlE,SAAO,KAAK;CACZ;CAED,YAAgB;AACf,SAAO,cAAc,KAAK,QAAQ,+BAA+B;CACjE;CAED,MAAM,iBAAiBC,OAA0B;EAChD;GACC,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;iCAEA,MAAM;AACpC,SAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;EAC7C;EACD;GAEC,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;iCAEA,MAAM;GACpC,MAAM,YAAY,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;GAC/D,MAAM,OAAO,UAAU,IAAI,CAAC,QAAQ,eAAe,IAAI,CAAqC;GAC5F,MAAMC,gBAAsC,sBAC3C,MACA,CAAC,QAAQ,IAAI,MACb,CAAC,QAAQ,IAAI,OACb;AAED,QAAK,MAAM,CAAC,MAAM,QAAQ,IAAI,cAAc,SAAS,EAAE;IAEtD,MAAM,gBAAgB,oBAAoB;IAC1C,MAAM,YAAY,MAAM,KAAK,QAAQ;AACrC,UAAM,KAAK,WACV,eACA,WACA,CAAC,MAAM,IAAI;;yBAES,KAAK;yBACL,UAAU,EAAE,CAAC,EACjC;AACD,UAAM,KAAK,WACV,eACA,WACA,CAAC,MAAM,IAAI;;yBAES,KAAK;yBACL,UAAU,EAAE,CAAC,EACjC;GACD;EACD;EACD;GACC,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;iCAEA,MAAM;AACpC,SAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;EAC7C;EACD;GACC,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;8BAEH,MAAM;AACjC,SAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;EAC7C;CACD;CAED,MAAM,gBAA6CxB,SAAqBC,QAA2B;AAClG,QAAM,KAAK,mBAAmB,OAAO;AACrC,QAAM,KAAK,YAAY,SAAS,OAAO;EACvC,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;4BAEJ,OAAO;AACjC,QAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;AAC7C,QAAM,KAAK,qBAAqB,OAAO;CACvC;CAED,MAAc,YAA2CwB,KAAQC,OAAwC;EACxG,IAAI;AACJ,MAAI;AACH,kBAAe,OAAa,MAAM;EAClC,SAAQ,GAAG;AACX,WAAQ,IAAI,sDAAsD,KAAK,cAAc,MAAM;AAC3F,SAAM;EACN;EACD,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;IAE5B,IAAI;IACJ,aAAa;;AAEf,QAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;CAC7C;CAED,MAAc,YAA2CD,KAA0C;EAClG,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;yBAEP,IAAI;EAC3B,MAAM,UAAU,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO;AAC7D,SAAO,WAAW,OAAa,QAAQ,MAAM,MAAoB;CACjE;;;;;;;CAQD,MAAM,kBAAkBE,gBAA+B,KAAK,eAAeC,SAAa,KAAK,WAAW,EAAiB;AACxH,QAAM,KAAK,QAAQ,eAAe,MAAM,eAAe,QAAQ,KAAK,aAAa,KAAK,CAAC;CACvF;CAED,MAAc,eAAe;AAC5B,OAAK,IAAI,CAAC,MAAM,WAAW,IAAI,OAAO,QAAQ,iBAAiB,CAC9D,OAAM,KAAK,gBAAgB,KACzB,6BAA6B,KAAK;;QAE/B,WAAW;SAEf,CAAE,EACF;CAEF;CAED,MAAM,SAASC,SAAqD5B,QAAmC;EACtG,MAAM,OAAO,UAAU,QAAQ;EAC/B,MAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;;0BAEN,KAAK;yBACN,OAAO;EAC9B,MAAM,MAAO,MAAM,KAAK,gBAAgB,IAAI,OAAO,OAAO,IAAK;AAE/D,SAAO,YAAY,KAAK,eAAe;CACvC;CAED,MAAM,SAASe,SAA2BrB,QAAmBO,YAAiC;AAC7F,MAAI,WAAW,WAAW,EAAG;EAC7B,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AACrD,UAAQ,UAAU,MAAlB;AACC,QAAKJ,KAAO,QACX,QAAO,MAAM,KAAK,WACjB,oBAAoB,GACpB,YACA,CAAC,MAAM,IAAI;;yBAES,UAAU,QAAQ,CAAC;4BAChB,UAAU,EAAE,CAAC,EACpC;AACF,QAAKA,KAAO,YACX,QAAO,MAAM,KAAK,WACjB,oBAAoB,GACpB,YACA,CAAC,MAAM,IAAI;;yBAES,UAAU,QAAQ,CAAC;wBACpB,OAAO;4BACH,UAAU,EAAE,CAAC,EACpC;AACF,QAAKA,KAAO,YACX,QAAO,MAAM,KAAK,WACjB,oBAAoB,GACpB,YACA,CAAC,MAAM,IAAI;;yBAES,UAAU,QAAQ,CAAC;wBACpB,OAAO;4BACH,UAAU,EAAE,CAAC,EACpC;AACF,WACC,OAAM,IAAI,MAAM;EACjB;CACD;;;;;;CAOD,MAAM,mBAAmBG,QAAY;AACpC,QAAM,KAAK,gBAAgB,mBAAmB,OAAO;CACrD;;;;;CAMD,MAAM,qBAAqBA,QAAY;AACtC,QAAM,KAAK,gBAAgB,qBAAqB,OAAO;CACvD;CAED,MAAM,wCAAqED,SAAqBC,QAAY6B,aAAgC;EAC3I,MAAM,YAAY,MAAM,qBAAqB,QAAQ;EACrD,MAAM,aAAa,eAAe,UAAU;EAC5C,MAAM,oBAAoB,gBAAgB,WAAW,YAAY;EAEjE,MAAM,QAAQ,MAAM,KAAK,SAAS,SAAS,OAAO;AAClD,MAAI,SAAS,KACZ;EAOD,MAAM,gBAAgB,aAAa,gBAAgB;AACnD,MAAI,MAAM,UAAU,eAAe;GAClC,MAAM,WAAW,MAAM,KAAK,iBAAiB,SAAS,QAAQ,eAAe,GAAG,MAAM;GACtF,MAAM,KAAK,YAAY,SAAS,IAAI,aAAa;GACjD,MAAM,sBAAsB,MAAM,QAAQ,sBAAsB,IAAI,kBAAkB,IAAI,OAAO;AACjG,OAAI,oBACH;EAED;AAED,MAAI,sBAAsB,mBAAmB,MAAM,MAAM,CAIxD,KAAI,sBAAsB,mBAAmB,MAAM,MAAM,CACxD,OAAM,KAAK,YAAY,SAAS,OAAO;IAEvC,OAAM,KAAK,qBAAqB,SAAS,QAAQ,YAAY;CAG/D;CAED,AAAQ,UAAUvB,gBAAwC;AACzD,MAAI;AACH,UAAO,OAAa,gBAAgB,EAAE,cAAc,mBAAoB,EAAC;EACzE,SAAQ,GAAG;AACX,WAAQ,IAAI,oDAAoD,eAAe,OAAO,WAAW,eAAe,IAAI;AACpH,SAAM;EACN;CACD;;;;CAKD,MAAc,YAAkCP,SAAqB+B,QAAuC;EAC3G,IAAI;AACJ,MAAI;AACH,kBAAe,KAAK,iBAAiB,OAAO;EAC5C,SAAQ,GAAG;AACX,WAAQ,IAAI,EAAE;AACd,WAAQ,KAAK,4DAA4D,OAAO,KAAK,OAAO,EAAE;AAC9F,UAAO;EACP;EAED,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AACrD,SAAQ,MAAM,KAAK,cAAc,WAAW,aAAa;CACzD;CAED,AAAQ,iBAAiBA,QAA6C;AACrE,SAAO,OAAa,QAAQ,EAAE,MAAM,mBAAoB,EAAC;CACzD;CAED,MAAc,cAAclC,WAAsBmC,cAAqC;AAItF,eAAa,QAAQ,IAAI,QAAQ,UAAU,KAAK,UAAU;AAC1D,OAAK,MAAM,CAAC,iBAAiB,iBAAiB,IAAI,OAAO,QAAQ,UAAU,aAAa,CACvF,KAAI,iBAAiB,SAAS,gBAAgB,aAAa;GAC1D,MAAM,mBAAmB,IAAI,QAAQ,iBAAiB,cAAc,UAAU,KAAK,iBAAiB;GACpG,MAAM,qBAAqB,MAAM,qBAAqB,iBAAiB;AACvE,WAAQ,iBAAiB,aAAzB;AACC,SAAK,YAAY;AACjB,SAAK,YAAY,WAAW;KAC3B,MAAM,YAAY,aAAa;AAC/B,SAAI,UACH,OAAM,KAAK,cAAc,oBAAoB,UAAU;AAExD;IACA;AACD,SAAK,YAAY,KAAK;KACrB,MAAM,gBAAgB,aAAa;AACnC,UAAK,MAAM,aAAa,cACvB,OAAM,KAAK,cAAc,oBAAoB,UAAU;AAExD;IACA;GACD;EACD;AAEF,SAAO;CACP;CAED,MAAc,gBAAsChC,SAAqBiC,QAA8C;EAEtH,MAAMC,SAAmB,CAAE;AAC3B,OAAK,MAAM,UAAU,QAAQ;GAC5B,MAAM,eAAe,MAAM,KAAK,YAAY,SAAS,OAAO;AAC5D,OAAI,gBAAgB,KACnB,QAAO,KAAK,aAAa;EAE1B;AACD,SAAO;CACP;;;;;CAMD,MAAc,WAAWC,WAAmBC,cAA0BC,WAAiE;AACtI,OAAK,MAAM,SAAS,cAAc,WAAW,aAAa,EAAE;GAC3D,MAAM,iBAAiB,UAAU,MAAM;AACvC,SAAM,KAAK,gBAAgB,IAAI,eAAe,OAAO,eAAe,OAAO;EAC3E;CACD;;;;;CAMD,MAAc,WACbF,WACAC,cACAC,WACiD;EACjD,MAAMC,SAAgD,CAAE;AACxD,OAAK,MAAM,SAAS,cAAc,WAAW,aAAa,EAAE;GAC3D,MAAM,iBAAiB,UAAU,MAAM;AACvC,UAAO,KAAK,GAAI,MAAM,KAAK,gBAAgB,IAAI,eAAe,OAAO,eAAe,OAAO,CAAE;EAC7F;AACD,SAAO;CACP;AACD;AASD,SAAS,UAAUC,QAAiC;CACnD,MAAM,KAAK,OAAO,IAAI,MAAM,IAAI,CAAC,KAAK,IAAI;AAC1C,QAAO,IAAI,aAAa,GAAG,GAAG,IAAI;AAClC;;;;;;;AAQD,SAAS,cAAc,GAAG,MAAkE;CAC3F,IAAI,CAAC,GAAG,EAAoB,GAAG;CAC/B,IAAI;AACJ,KAAI,MAAM,aAAa;AACtB,MAAI;AACJ,MAAI;CACJ,OAAM;AACN,MAAI;AACJ,MAAI;CACJ;AACD,QAAO,IAAI,aAAa,oBAAoB,EAAE,aAAa,EAAE,uBAAuB,EAAE,aAAa,EAAE,gBAAgB,EAAE,KAAK,EAAE,QAAQ;EAAC;EAAG;EAAG;CAAE;AAC/I;AAEM,SAAS,eAAe1C,WAA+B;AAC7D,QAAO,UAAU,OAAO,IAAI,SAAS,UAAU;AAC/C;AAKM,SAAS,gBAAgBA,WAAsBD,WAAmB;AACxE,KAAI,eAAe,UAAU,CAC5B,QAAO,kBAAkB,kBAAkB,UAAU,CAAC;AAEvD,QAAO;AACP;AAEM,SAAS,oBAAoBC,WAAsBD,WAAmB;AAC5E,KAAI,eAAe,UAAU,CAC5B,QAAO,kBAAkB,kBAAkB,UAAU,CAAC;AAEvD,QAAO;AACP;;;;AC51BD,oBAAoB;MAQP,8BAA8B;AAC3C,MAAM,gBAAgB;CACrB;CACA;CACA;CACA;CACA;CACA;CACA;CAIA;CACA;CACA;CACA;CACA;AACA;;;;;;;;;AAUD,MAAM,2BAA2B,CAAC,qBAAqB,eAAgB;IA+K1D,yBAAN,MAAwD;CAC9D,YAA6B4C,kBAAqDC,SAAuB;EA6yBzG,KA7yB6B;EA6yB5B,KA7yBiF;CAAyB;CAE3G,MAAM,KAA2BC,SAAqBC,IAA4BC,OAAoC,CAAE,GAAc;EACrI,MAAM,WAAW,MAAM,KAAK,eAAe,SAAS,KAAK;AACzD,OAAK,SACJ,QAAO,MAAM,KAAK,iBAAiB,KAAK,SAAS,IAAI,KAAK;EAG3D,MAAM,EAAE,QAAQ,WAAW,GAAG,SAAS,GAAG;EAC1C,MAAM,kBAAkB,qBAAqB,KAAK,UAAU;EAC5D,MAAM,eAAe,gBAAgB,iBAAiB,MAAM,KAAK,QAAQ,IAAI,SAAS,QAAQ,UAAU,GAAG;AAE3G,MAAI,gBAAgB,MAAM;GACzB,MAAM,SAAS,MAAM,KAAK,iBAAiB,KAAK,SAAS,IAAI,KAAK;AAClE,OAAI,gBAAgB,cACnB,OAAM,KAAK,QAAQ,IAAI,OAAO;AAE/B,UAAO;EACP;AAED,SAAO;CACP;CAED,MAAM,aACLF,SACAG,QACAC,KACAC,4BACAH,OAAoC,CAAE,GAClB;EACpB,MAAM,WAAW,MAAM,KAAK,eAAe,SAAS,KAAK;AACzD,OAAK,SACJ,QAAO,MAAM,KAAK,iBAAiB,aAAa,SAAS,QAAQ,KAAK,4BAA4B,KAAK;AAExG,SAAO,MAAM,KAAK,cAAc,SAAS,QAAQ,KAAK,4BAA4B,KAAK;CACvF;CAED,MAA4BC,QAAmBG,UAAaC,cAAqBC,SAAqD;AACrI,SAAO,KAAK,iBAAiB,MAAM,QAAQ,UAAU,cAAc,QAAQ;CAC3E;CAED,cAAoCL,QAAmBM,WAAyC;AAC/F,SAAO,KAAK,iBAAiB,cAAc,QAAQ,UAAU;CAC7D;CAED,OAA6BH,UAA4B;AACxD,SAAO,KAAK,iBAAiB,OAAO,SAAS;CAC7C;CAED,MAA4BA,UAAaI,SAAuD;AAC/F,SAAO,KAAK,iBAAiB,MAAM,UAAU,QAAQ;CACrD;CAED,gCAAgCC,SAAiC;AAChE,SAAO,KAAK,QAAQ,uBAAuB,QAAQ;CACnD;CAED,gCAAgCA,SAAaC,SAA4B;AACxE,SAAO,KAAK,QAAQ,uBAAuB,SAAS,QAAQ;CAC5D;CAED,eAA8B;AAC7B,UAAQ,IAAI,sCAAsC;AAClD,SAAO,KAAK,QAAQ,cAAc;CAClC;CAED,MAAM,cAAgC;EACrC,MAAM,oBAAoB,MAAM,KAAK,qBAAqB;AAC1D,SAAO,qBAAqB,QAAQ,oBAAoB;CACxD;CAED,MAAM,iBAAgC;EACrC,MAAM,YAAY,KAAK,sBAAsB;AAC7C,QAAM,KAAK,QAAQ,kBAAkB,UAAU;CAC/C;CAED,MAAM,sBAA8C;EACnD,MAAM,aAAa,MAAM,KAAK,QAAQ,mBAAmB;EACzD,IAAIC;AACJ,UAAQ,WAAW,MAAnB;AACC,QAAK;AACJ,qBAAiB,WAAW;AAC5B;AACD,QAAK,QACJ,QAAO;AACR,QAAK,gBACJ,OAAM,IAAI,iBAAiB;EAC5B;EACD,MAAM,MAAM,KAAK,sBAAsB;AACvC,SAAO,MAAM;CACb;CAED,AAAQ,uBAA+B;AACtC,SAAO,KAAK,iBAAiB,eAAe,CAAC,sBAAsB;CACnE;;;;CAKD,wBAA8Cb,SAAqBG,QAAmBW,WAA8B;AACnH,SAAO,KAAK,QAAQ,eAAe,SAAS,QAAQ,UAAU;CAC9D;CAED,MAAc,cACbd,SACAG,QACAC,KACAC,4BACAH,OAAoC,CAAE,GAClB;EACpB,MAAM,kBAAkB,qBAAqB,KAAK,UAAU;EAC5D,MAAMa,kBAAuB,CAAE;EAE/B,IAAIC;AACJ,MAAI,gBAAgB,gBAAgB;AACnC,eAAY,CAAE;AACd,QAAK,MAAM,MAAM,KAAK;IACrB,MAAM,eAAe,MAAM,KAAK,QAAQ,IAAI,SAAS,QAAQ,GAAG;AAChE,QAAI,gBAAgB,KACnB,iBAAgB,KAAK,aAAa;IAElC,WAAU,KAAK,GAAG;GAEnB;EACD,MACA,aAAY;AAGb,MAAI,UAAU,SAAS,GAAG;GACzB,MAAM,qBAAqB,MAAM,KAAK,iBAAiB,aAAa,SAAS,QAAQ,WAAW,4BAA4B,KAAK;AACjI,OAAI,gBAAgB,cACnB,MAAK,MAAM,UAAU,mBACpB,OAAM,KAAK,QAAQ,IAAI,OAAO;AAGhC,UAAO,mBAAmB,OAAO,gBAAgB;EACjD,MACA,QAAO;CAER;CAED,MAAM,UACLhB,SACAiB,QACAC,OACAC,OACAC,SACAlB,OAAoC,CAAE,GACvB;EACf,MAAM,gBAAgB,KAAK,QAAQ,yBAAyB,KAAK,iBAAiB,CAAC,IAAI,QAAQ;AAC/F,MAAI,iBAAiB,cAAc,UAClC,QAAO,MAAM,cAAc,UAAU,KAAK,SAAS,QAAQ,OAAO,OAAO,QAAQ;EAGlF,MAAM,YAAY,MAAM,qBAAqB,QAAQ;EACrD,MAAM,WAAY,MAAM,KAAK,eAAe,SAAS,KAAK,IAAK,kBAAkB,WAAW,QAAQ;AAEpG,OAAK,SACJ,QAAO,MAAM,KAAK,iBAAiB,UAAU,SAAS,QAAQ,OAAO,OAAO,SAAS,KAAK;EAG3F,MAAM,WAAW,qBAAqB,KAAK,UAAU;AACrD,OAAK,SAAS,eACb,OAAM,IAAI,iBAAiB;AAI5B,QAAM,KAAK,QAAQ,mBAAmB,OAAO;AAE7C,MAAI;GACH,MAAM,QAAQ,MAAM,KAAK,QAAQ,gBAAgB,SAAS,OAAO;AAEjE,OAAI,SAAS,eAAe;AAC3B,QAAI,SAAS,KACZ,OAAM,KAAK,yBAAyB,SAAS,QAAQ,OAAO,OAAO,SAAS,KAAK;SACvE,qBAAqB,OAAO,OAAO,UAAU,CACvD,OAAM,KAAK,sBAAsB,SAAS,QAAQ,OAAO,OAAO,SAAS,KAAK;SACpE,oCAAoC,OAAO,SAAS,OAAO,UAAU,CAC/E,OAAM,KAAK,oBAAoB,SAAS,QAAQ,OAAO,OAAO,SAAS,KAAK;IAE5E,OAAM,KAAK,mBAAmB,SAAS,QAAQ,OAAO,OAAO,SAAS,KAAK;AAE5E,WAAO,MAAM,KAAK,QAAQ,iBAAiB,SAAS,QAAQ,OAAO,OAAO,QAAQ;GAClF,WACI,SAAS,qBAAqB,OAAO,OAAO,UAAU,EAAE;IAC3D,MAAM,WAAW,MAAM,KAAK,QAAQ,iBAAiB,SAAS,QAAQ,OAAO,OAAO,QAAQ;IAC5F,MAAM,EAAE,UAAU,UAAU,GAAG,MAAM,KAAK,wBAAwB,SAAS,QAAQ,OAAO,OAAO,QAAQ;IACzG,MAAM,cAAc,WAAW,IAAI,MAAM,KAAK,iBAAiB,UAAU,SAAS,QAAQ,UAAU,UAAU,QAAQ,GAAG,CAAE;AAC3H,WAAO,SAAS,OAAO,YAAY;GACnC,MAMA,QAAO,MAAM,KAAK,iBAAiB,UAAU,SAAS,QAAQ,OAAO,OAAO,SAAS,KAAK;EAG5F,UAAS;AAET,SAAM,KAAK,QAAQ,qBAAqB,OAAO;EAC/C;CACD;;;;;;;;CASD,MAAc,yBACbF,SACAiB,QACAC,OACAC,OACAC,SACAlB,MACC;EAED,MAAM,WAAW,MAAM,KAAK,iBAAiB,UAAU,SAAS,QAAQ,OAAO,OAAO,SAAS,KAAK;AAGpG,QAAM,KAAK,QAAQ,mBAAmB,SAAS,QAAQ,OAAO,MAAM;AAGpE,QAAM,KAAK,qBAAqB,SAAS,QAAQ,OAAO,SAAS,SAAS;CAC1E;;;;;;;CAQD,MAAc,sBACbF,SACAiB,QACAC,OACAC,OACAC,SACAlB,MACC;EACD,MAAM,EAAE,UAAU,UAAU,GAAG,MAAM,KAAK,wBAAwB,SAAS,QAAQ,OAAO,OAAO,QAAQ;AACzG,MAAI,WAAW,GAAG;GAEjB,MAAM,WAAW,MAAM,KAAK,iBAAiB,UAAU,SAAS,QAAQ,UAAU,UAAU,SAAS,KAAK;AAC1G,SAAM,KAAK,qBAAqB,SAAS,QAAQ,UAAU,SAAS,SAAS;EAC7E;CACD;;;;;;;;;CAUD,MAAc,oBACbF,SACAiB,QACAC,OACAC,OACAC,SACAlB,MACC;AAGD,SAAO,MAAM;GACZ,MAAM,QAAQ,cAAc,MAAM,KAAK,QAAQ,gBAAgB,SAAS,OAAO,CAAC;GAGhF,MAAM,cAAc,UAAU,MAAM,QAAQ,MAAM;GAElD,MAAM,eAAe,KAAK,IAAI,OAAO,4BAA4B;GAGjE,MAAM,WAAW,MAAM,KAAK,iBAAiB,UAAU,SAAS,QAAQ,aAAa,cAAc,SAAS,KAAK;AACjH,SAAM,KAAK,qBAAqB,SAAS,QAAQ,cAAc,SAAS,SAAS;AAGjF,OAAI,SAAS,SAAS,aACrB;GAID,MAAM,oBAAoB,MAAM,KAAK,QAAQ,iBAAiB,SAAS,QAAQ,OAAO,OAAO,QAAQ;AAGrG,OAAI,kBAAkB,WAAW,MAChC;EAED;CACD;;;;;;;;;;;;CAaD,MAAc,mBACbF,SACAiB,QACAC,OACAC,OACAC,SACAlB,MACC;AACD,SAAO,MAAM;GACZ,MAAM,QAAQ,cAAc,MAAM,KAAK,QAAQ,gBAAgB,SAAS,OAAO,CAAC;GAEhF,MAAM,cAAc,UAAU,MAAM,QAAQ,MAAM;GAElD,MAAM,eAAe,KAAK,IAAI,OAAO,4BAA4B;GAEjE,MAAM,WAAW,MAAM,KAAK,iBAAiB,UAAU,SAAS,QAAQ,aAAa,eAAe,SAAS,KAAK;AAElH,SAAM,KAAK,qBAAqB,SAAS,QAAQ,eAAe,SAAS,SAAS;AAIlF,OAAI,MAAM,KAAK,QAAQ,wBAAwB,SAAS,QAAQ,MAAM,CACrE;EAED;AAED,QAAM,KAAK,sBAAsB,SAAS,QAAQ,OAAO,OAAO,SAAS,KAAK;CAC9E;;;;;;CAOD,MAAc,qBACbF,SACAiB,QACAI,gBACAC,mBACAC,kBACC;EACD,MAAM,aAAa,eAAe,MAAM,qBAAqB,QAAQ,CAAC;EACtE,IAAI,gBAAgB;AACpB,MAAI,mBAAmB;AAEtB,mBAAgB,iBAAiB,SAAS;AAC1C,OAAI,iBAAiB,SAAS,gBAAgB;AAC7C,YAAQ,IAAI,mCAAmC;AAC/C,UAAM,KAAK,QAAQ,qBAAqB,SAAS,QAAQ,aAAa,gBAAgB,iBAAiB;GACvG,MAEA,OAAM,KAAK,QAAQ,qBAAqB,SAAS,QAAQ,aAAa,gBAAgB,iBAAiB,CAAC,CAAC;EAE1G,WAEI,iBAAiB,SAAS,gBAAgB;AAE7C,WAAQ,IAAI,mCAAmC;AAC/C,SAAM,KAAK,QAAQ,qBAAqB,SAAS,QAAQ,aAAa,gBAAgB,iBAAiB;EACvG,MACA,OAAM,KAAK,QAAQ,qBAAqB,SAAS,QAAQ,aAAa,UAAU,iBAAiB,CAAC,CAAC;AAIrG,QAAM,QAAQ,IAAI,cAAc,IAAI,CAAC,YAAY,KAAK,QAAQ,IAAI,QAAQ,CAAC,CAAC;CAC5E;;;;;;CAOD,MAAc,wBACbvB,SACAiB,QACAC,OACAC,OACAC,SACkD;EAClD,IAAI,eAAe,MAAM,KAAK,QAAQ,cAAc,SAAS,OAAO;EACpE,IAAI,iBAAiB;EACrB,IAAI,iBAAiB;EACrB,MAAM,QAAQ,MAAM,KAAK,QAAQ,gBAAgB,SAAS,OAAO;AACjE,MAAI,SAAS,KACZ,QAAO;GAAE,UAAU;GAAO,UAAU;EAAO;EAE5C,MAAM,EAAE,OAAO,OAAO,GAAG;EACzB,IAAI,eAAe,aAAa,QAAQ,MAAM;EAE9C,MAAM,YAAY,MAAM,qBAAqB,QAAQ;EACrD,MAAM,aAAa,eAAe,UAAU;AAC5C,OACG,YAAY,aAAa,UAAU,gBAAgB,UAAU,qBAC9D,YAAY,aAAa,UAAU,gBAAgB,UAAU,kBAG9D,kBAAiB;SACP,aAAa,WAAW,EAElC,kBAAiB;SACP,iBAAiB,GAE3B,KAAI,SAAS;AACZ,oBAAiB,QAAQ;AACzB,oBAAiB,aAAa;EAC9B,OAAM;AACN,oBAAiB,SAAS,aAAa,SAAS,IAAI;AACpD,oBAAiB,aAAa,aAAa,SAAS;EACpD;SACS,UAAU,SAAU,sBAAsB,OAAO,OAAO,UAAU,IAAI,sBAAsB,aAAa,IAAI,OAAO,UAAU,EAExI;QAAK,SAAS;AAEb,qBAAiB,aAAa,aAAa,SAAS;AACpD,qBAAiB,QAAQ,aAAa;GACtC;aAGD,UAAU,SACT,sBAAsB,OAAO,aAAa,aAAa,SAAS,IAAI,UAAU,IAAI,sBAAsB,OAAO,OAAO,UAAU,EAGjI;OAAI,SAAS;AAEZ,qBAAiB,aAAa;AAC9B,qBAAiB,QAAQ,aAAa;GACtC;;AAGF,SAAO;GAAE,UAAU;GAAgB,UAAU;EAAgB;CAC7D;;;;;;;;CASD,MAAM,qBAAqBI,OAAkD;AAC5E,QAAM,KAAK,gBAAgB;EAG3B,MAAMC,uBAAuC,CAAE;EAC/C,MAAMC,iBAAiC,CAAE;EACzC,MAAM,eAAe,MAAM;AAC3B,OAAK,MAAM,UAAU,cAAc;GAClC,MAAM,UAAU,IAAI,QAAQ,OAAO,aAAa,OAAO;AAGvD,OAAI,OAAO,gBAAgB,UAAW;AAEtC,OAAI,OAAO,cAAc,cAAc,UAAU,oBAAoB,OAAO,CAAC,kBAAkB,SAAS,cAAc,SAAS,YAAY,CAC1I,sBAAqB,KAAK,OAAO;KAC3B;AACN,mBAAe,KAAK,OAAO;AAC3B,UAAM,KAAK,yBAAyB,SAAS,OAAO;GACpD;EACD;EAED,MAAM,8BAA8B,QAAQ,sBAAsB,CAAC,WAAW,OAAO,eAAe;EAEpG,MAAMC,2BAA6C,CAAE;AAErD,OAAK,IAAI,CAAC,gBAAgB,QAAQ,IAAI,6BAA6B;GAClE,MAAM,cAAc,QAAQ;GAC5B,MAAM,UAAU,IAAI,QAA2B,YAAY,aAAa,YAAY;GACpF,MAAM,MAAM,QAAQ,IAAI,CAAC,WAAW,OAAO,WAAW;GAGtD,MAAM,gBAAgB,KAAK,QAAQ,yBAAyB,KAAK,iBAAiB,CAAC,IAAI,QAAQ;GAC/F,MAAM,kBACL,iBAAiB,cAAc,4BAC5B,MAAM,cAAc,0BAA0B,KAAK,SAAS,gBAAgB,IAAI,GAChF,MAAM,KAAK,0BAA0B,SAAS,gBAAgB,IAAI;AAEtE,OAAI,gBAAgB,WAAW,EAC9B,0BAAyB,KAAK,QAAQ;KAChC;IACN,MAAM,yBACL,gBAAgB,WAAW,QAAQ,SAAS,CAAE,IAAG,QAAQ,OAAO,CAAC,YAAY,gBAAgB,SAAS,OAAO,WAAW,CAAC;AAE1H,QAAI;KAEH,MAAM,oBAAoB,MAAM,KAAK,cAAc,SAAS,gBAAgB,iBAAiB,WAAW,EAAE,WAAW,UAAU,UAAW,EAAC;AAE3I,SAAI,kBAAkB,WAAW,gBAAgB,QAAQ;MACxD,MAAM,cAAc,kBAAkB,IAAI,CAAC,aAAa,aAAa,SAAS,CAAC;AAC/E,+BAAyB,KAAK,QAAQ,OAAO,CAAC,WAAW,YAAY,SAAS,OAAO,WAAW,CAAC,CAAC,OAAO,uBAAuB,CAAC;KACjI,MACA,0BAAyB,KAAK,QAAQ;IAEvC,SAAQ,GAAG;AACX,SAAI,aAAa,mBAEhB,0BAAyB,KAAK,uBAAuB;IAErD,OAAM;IAEP;GACD;EACD;EAED,MAAMC,oBAAoC,CAAE;AAC5C,OAAK,IAAI,UAAU,gBAAgB;GAClC,MAAM,EAAE,WAAW,MAAM,aAAa,GAAG;GACzC,MAAM,EAAE,gBAAgB,YAAY,GAAG,oBAAoB,OAAO;GAClE,MAAM,UAAU,IAAI,QAAoB,aAAa;AAErD,WAAQ,WAAR;AACC,SAAK,cAAc,QAAQ;KAC1B,MAAM,gBAAgB,MAAM,KAAK,mBAAmB,SAAS,OAAO;AACpE,SAAI,cACH,mBAAkB,KAAK,cAAc;AAEtC;IACA;AACD,SAAK,cAAc,QAAQ;AAC1B,SACC,cAAc,aAAa,QAAQ,IACnC,oBAAoB,cAA8C,cAAc,QAAQ,WAAW,EAClG,CAED,WAAU,cAAc,aAAa,QAAQ,EAAE;MAE/C,MAAM,OAAO,MAAM,KAAK,QAAQ,IAAI,aAAa,gBAAgB,WAAW;AAC5E,YAAM,KAAK,QAAQ,eAAe,SAAS,gBAAgB,WAAW;AACtE,UAAI,MAAM,eAAe,KACxB,OAAM,KAAK,QAAQ,eAAe,wBAAwB,KAAK,YAAY,IAAI,KAAK,YAAY,GAAG;KAEpG,MACA,OAAM,KAAK,QAAQ,eAAe,SAAS,gBAAgB,WAAW;AAEvE,uBAAkB,KAAK,OAAO;AAC9B;IACA;AACD,SAAK,cAAc,QAAQ;KAC1B,MAAM,gBAAgB,MAAM,KAAK,mBAAmB,SAAS,QAAQ,aAAa;AAClF,SAAI,cACH,mBAAkB,KAAK,cAAc;AAEtC;IACA;AACD,YACC,OAAM,IAAI,iBAAiB,6BAA6B;GACzD;EACD;AAED,QAAM,KAAK,QAAQ,uBAAuB,MAAM,SAAS,MAAM,QAAQ;AAEvE,SAAO,kBAAkB,OAAO,yBAAyB,MAAM,CAAC;CAChE;;CAGD,MAAc,mBAAmBC,SAAuBC,QAAsBC,OAAkE;EAE/I,MAAM,EAAE,YAAY,gBAAgB,GAAG,oBAAoB,OAAO;AAGlE,MAAI,kBAAkB,MAAM;GAC3B,MAAM,cAAc,eAAe,OAAO,cAAc,QAAQ,WAAW;GAE3E,MAAM,OAAO,eAAe,cAAc,aAAa,QAAQ,GAAG,MAAM,KAAK,QAAQ,IAAI,aAAa,YAAY,gBAAgB,WAAW,GAAG;AAGhJ,OAAI,eAAe,QAAQ,QAAQ,QAAQ,QAAQ,KAAK,KAAK,EAAE;AAE9D,UAAM,KAAK,QAAQ,eAAe,SAAS,YAAY,gBAAgB,WAAW;AAClF,UAAM,KAAK,iCAAiC,MAAM,gBAAgB,WAAW;AAC7E,WAAO;GACP,OAAM;IAGN,MAAM,aACJ,MAAM,KAAK,QAAQ,yBAAyB,KAAK,iBAAiB,CAAC,IAAI,QAAQ,EAAE,0BAA0B,OAAO,IAClH,MAAM,KAAK,QAAQ,wBAAwB,SAAS,gBAAgB,WAAW;AACjF,QAAI,YAAY;AAGf,aAAQ,IAAI,gCAAgC,UAAU,QAAQ,EAAE,gBAAgB,WAAW;AAC3F,YAAO,KAAK,iBACV,KAAK,SAAS,CAAC,gBAAgB,UAAW,EAAC,CAC3C,KAAK,CAAC,WAAW,KAAK,QAAQ,IAAI,OAAO,CAAC,CAC1C,KAAK,MAAM,OAAO,CAClB,MAAM,CAAC,MAAM;AACb,UAAI,kCAAkC,EAAE,CACvC,QAAO;IAEP,OAAM;KAEP,EAAC;IACH,MACA,QAAO;GAER;EACD,MACA,QAAO;CAER;;;;CAKD,MAAc,iCAAiCC,MAAYC,WAAenB,WAAe;AAExF,OAAK,MAAM,CAAC,WAAW,SAAU;AACjC,MAAI,KAAK,aAAa,MAAM;GAK3B,MAAM,iBAAiB,KAAK,UAAU,qBAAqB,KAAK,CAAC,wBAAwB,SAAS,oBAAoB,YAAY,UAAU,CAAC;AAC7I,OAAI,eACH,gBAAe,eAAe;EAE/B;AACD,QAAM,KAAK,QAAQ,IAAI,KAAK;CAC5B;;CAGD,MAAc,mBAAmBoB,SAA8BJ,QAAoD;EAClH,MAAM,EAAE,YAAY,gBAAgB,GAAG,oBAAoB,OAAO;EAClE,MAAM,SAAS,MAAM,KAAK,QAAQ,IAAI,SAAS,gBAAgB,WAAW;AAE1E,MAAI,UAAU,KACb,KAAI;GAQH,MAAM,YAAY,MAAM,KAAK,iBAAiB,KAAK,SAAS,WAAW,gBAAgB,WAAW,CAAC;AACnG,OAAI,cAAc,SAAS,YAAY,CACtC,OAAM,KAAK,kBAAkB,QAAQ,UAAU;AAEhD,SAAM,KAAK,QAAQ,IAAI,UAAU;AACjC,UAAO;EACP,SAAQ,GAAG;AAGX,OAAI,kCAAkC,EAAE,EAAE;AACzC,YAAQ,KAAK,gDAAgD,KAAK,UAAU,OAAO,CAAC,4BAA4B;AAChH,UAAM,KAAK,QAAQ,eAAe,SAAS,gBAAgB,WAAW;AACtE,WAAO;GACP,MACA,OAAM;EAEP;AAEF,SAAO;CACP;CAED,MAAc,kBAAkBK,QAAoBC,WAAuB;EAK1E,MAAM,UAAU;AAChB,MAAI,QAAQ,QAAQ,KAAK,QAAQ,WAAW,CAC3C;EAED,MAAM,UAAU;EAChB,MAAM,eAAe,WAAW,QAAQ,aAAa,QAAQ,aAAa,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,IAAI;AACpG,OAAK,MAAM,QAAQ,cAAc;AAChC,WAAQ,IAAI,uBAAuB,KAAK,KAAK,KAAK,UAAU;AAC5D,SAAM,KAAK,QAAQ,iBAAiB,KAAK,MAAM;EAC/C;CACD;;;;;CAMD,MAAc,0BAAuDpC,SAAqBiB,QAAYoB,KAA0B;EAC/H,MAAMC,MAAY,CAAE;AACpB,OAAK,IAAI,IAAI,GAAG,IAAI,IAAI,QAAQ,IAC/B,KAAI,MAAM,KAAK,QAAQ,wBAAwB,SAAS,QAAQ,IAAI,GAAG,CACtE,KAAI,KAAK,IAAI,GAAG;AAGlB,SAAO;CACP;;;;;CAMD,MAAc,yBAAyBC,SAA2BT,QAAqC;AACtG,MAAI,OAAO,cAAc,cAAc,WAAW,cAAc,SAAS,kBAAkB,CAAE;EAE7F,MAAM,YAAY,MAAM,KAAK,QAAQ,IAAI,mBAAmB,OAAO,gBAAgB,OAAO,WAAW;AAIrG,MAAI,aAAa,QAAQ,UAAU,UAAW;EAC9C,MAAM,gBAAgB,MAAM,KAAK,iBAAiB,KAAK,mBAAmB,CAAC,OAAO,gBAAgB,OAAO,UAAW,EAAC;AACrH,OAAK,cAAc,UAAW;AAC9B,QAAM,KAAK,QAAQ,gBAAgB,aAAa,cAAc,MAAM;AACpE,QAAM,KAAK,QAAQ,IAAI,cAAc;CACrC;;;;;;;CAQD,AAAQ,eAAeD,SAAuBW,MAA6C;AAE1F,MAAI,cAAc,QAAQ,CACzB,QAAO;AAIR,SAAO,MAAM,aAAa,WAAW;CACrC;AACD;;;;;AAMD,SAAS,kCAAkCC,GAAmB;AAC7D,QAAO,aAAa,iBAAiB,aAAa;AAClD;AAEM,SAAS,SAASC,IAAwD;AAChF,YAAW,OAAO,SACjB,QAAO;EACN,QAAQ;EACR,WAAW;CACX;KACK;EACN,MAAM,CAAC,QAAQ,UAAU,GAAG;AAC5B,SAAO;GACN;GACA;EACA;CACD;AACD;AAEM,SAAS,WAAWvC,QAAmBW,WAA6B;AAC1E,KAAI,UAAU,KACb,QAAO,CAAC,QAAQ,SAAU;IAE1B,QAAO;AAER;AAEM,SAAS,oBAAoBgB,QAAqE;CACxG,IAAI;AACJ,KAAI,OAAO,mBAAmB,GAC7B,kBAAiB;IAEjB,kBAAiB,OAAO;AAEzB,QAAO;EAAE;EAAgB,YAAY,OAAO;CAAY;AACxD;;;;AAKD,SAAS,qBAAqBa,OAAcC,SAAaC,WAA+B;AACvF,SAAQ,sBAAsB,SAAS,MAAM,OAAO,UAAU,KAAK,sBAAsB,MAAM,OAAO,SAAS,UAAU;AACzH;;;;;AAMD,SAAS,oCAAoCF,OAAcvB,SAAkB0B,OAAeD,WAAsB;AACjH,QAAO,UAAU,sBAAsB,MAAM,OAAO,OAAO,UAAU,GAAG,sBAAsB,OAAO,MAAM,OAAO,UAAU;AAC5H;;;;;;;AAQD,SAAS,cAAcN,SAAoC;AAC1D,QAAO,QAAQ,QAAQ,aAAa,cAAc,KAAK,CAAC,QAAQ,cAAc,SAAS,IAAI,CAAC;AAC5F;;;;AAKD,SAAS,uBAAuBA,SAAoC;AACnE,QAAO,yBAAyB,KAAK,CAAC,QAAQ,cAAc,SAAS,IAAI,CAAC;AAC1E;;;;;;;AAQD,SAAS,kBAAkBM,WAAsBN,SAAoC;AACpF,SAAS,cAAc,QAAQ,IAAI,kBAAkB,UAAU,IAAK,uBAAuB,QAAQ;AACnG;AAED,SAAS,kBAAkBM,WAA+B;AACzD,QAAO,UAAU,OAAO,IAAI,SAAS,UAAU;AAC/C;;;;ACjhCD,oBAAoB;AAEb,SAAS,cAAcE,SAA+B;AAC5D,SAAQ,QAAQ,QAAQ,IAAI,GAAG,QAAQ,KAAK,aAAa,CAAC;AAC1D;IAuBiB,kCAAX;;AAEN;;;;;;AAOA;;AAGA;;AACA;AAMM,SAAS,qBAAqBC,WAGnC;AACD,SAAQ,aAAa,UAAU,cAA/B;AACC,OAAK,UAAU,aACd,QAAO;GAAE,gBAAgB;GAAM,eAAe;EAAM;AACrD,OAAK,UAAU,UACd,QAAO;GAAE,gBAAgB;GAAO,eAAe;EAAM;AACtD,OAAK,UAAU,SACd,QAAO;GAAE,gBAAgB;GAAM,eAAe;EAAO;CACtD;AACD;IA8FY,mBAAN,MAAsD;CAC5D,IAAI,UAAwB;AAC3B,SAAO,KAAK,YAAY;CACxB;CAED,YACkBC,kBACAC,YACAC,YACAC,gBACAC,uBAChB;EA2cF,KAhdkB;EAgdjB,KA/ciB;EA+chB,KA9cgB;EA8cf,KA7ce;EA6cd,KA5cc;CACd;CAEJ,MAAM,KAA2BC,SAAqBC,IAA4BC,OAAoC,CAAE,GAAc;EACrI,MAAM,EAAE,QAAQ,WAAW,GAAG,SAAS,GAAG;EAC1C,MAAM,EAAE,MAAM,aAAa,SAAS,WAAW,GAAG,MAAM,KAAK,+BAC5D,SACA,QACA,WACA,KAAK,aACL,KAAK,cACL,KAAK,iBACL;EACD,MAAM,OAAO,MAAM,KAAK,WAAW,QAAQ,MAAM,WAAW,KAAK;GAChE;GACA;GACA,cAAc,UAAU;GACxB,SAAS,KAAK;EACd,EAAC;EACF,MAAM,SAAS,KAAK,MAAM,KAAK;EAC/B,MAAM,iBAAiB,MAAM,KAAK,QAAQ,gBAAgB,SAAS,OAAO;EAC1E,MAAM,aAAa,MAAM,KAAK,kBAAkB,KAAK,kBAAkB,gBAAgB,UAAU;EAEjG,MAAM,WAAW,MAAM,KAAK,eAAe,wBAA2B,WAAW,gBAAgB,WAAW;AAC5G,SAAO,KAAK,QAAQ,2BAA2B,SAAS;CACxD;CAED,MAAc,kBAAkBC,kBAAgDC,gBAAqCC,WAAsB;AAC1I,MAAI;AACH,OAAI,oBAAoB,eAAe,qBAAqB;IAC3D,MAAM,WAAW,MAAM,iBAAiB,OAAO,eAAe,oBAAoB,EAAE,CAAC;AACrF,WAAO,KAAK,QAAQ,8BAA8B,gBAAgB,SAAS;GAC3E,MACA,QAAO,MAAM,KAAK,QAAQ,kBAAkB,WAAW,eAAe;EAEvE,SAAQ,GAAG;AACX,OAAI,aAAa,yBAAyB;AACzC,YAAQ,KAAK,qDAAqD,UAAU,IAAI,GAAG,UAAU,KAAK,GAAG,EAAE;AACvG,WAAO;GACP,MACA,OAAM;EAEP;CACD;CAED,MAAM,UACLL,SACAM,QACAC,OACAC,OACAC,SACAP,OAAoC,CAAE,GACvB;EACf,MAAM,qBAAqB;GAC1B,OAAO,OAAO,MAAM;GACpB,OAAO,OAAO,MAAM;GACpB,SAAS,OAAO,QAAQ;EACxB;EACD,MAAM,EAAE,MAAM,SAAS,WAAW,aAAa,GAAG,MAAM,KAAK,+BAC5D,SACA,QACA,MACA,OAAO,OAAO,oBAAoB,KAAK,YAAY,EACnD,KAAK,cACL,KAAK,iBACL;AAED,MAAI,UAAU,SAAS,KAAK,YAAa,OAAM,IAAI,MAAM;EACzD,MAAM,OAAO,MAAM,KAAK,WAAW,QAAQ,MAAM,WAAW,KAAK;GAChE;GACA;GACA,cAAc,UAAU;GACxB,SAAS,KAAK;GACd,oBAAoB,KAAK;EACzB,EAAC;AACF,SAAO,KAAK,0BAA0B,SAAS,KAAK,MAAM,KAAK,CAAC;CAChE;CAED,MAAM,aACLF,SACAU,QACAC,YACAC,4BACAV,OAAoC,CAAE,GAClB;EACpB,MAAM,EAAE,MAAM,SAAS,GAAG,MAAM,KAAK,+BAA+B,SAAS,QAAQ,MAAM,KAAK,aAAa,KAAK,cAAc,KAAK,iBAAiB;EACtJ,MAAM,WAAW,cAAc,qBAAqB,WAAW;EAC/D,MAAM,YAAY,MAAM,qBAAqB,QAAQ;EAErD,MAAM,eAAe,MAAM,KAAW,UAAU,OAAO,YAAY;GAClE,IAAI,cAAc,EACjB,KAAK,QAAQ,KAAK,IAAI,CACtB;GACD,IAAIW;AACJ,OAAI,UAAU,SAAS,KAAK,YAC3B,QAAO,MAAM,KAAK,yBAAyB,QAAQ,aAAa,SAAS,MAAM,SAAS,KAAK,mBAAmB;IAEhH,QAAO,MAAM,KAAK,WAAW,QAAQ,MAAM,WAAW,KAAK;IAC1D;IACA;IACA,cAAc,UAAU;IACxB,SAAS,KAAK;IACd,oBAAoB,KAAK;GACzB,EAAC;AAEH,UAAO,KAAK,0BAA0B,SAAS,KAAK,MAAM,KAAK,EAAE,2BAA2B;EAC5F,EAAC;AACF,SAAO,aAAa,MAAM;CAC1B;CAED,MAAc,yBACbC,WACAC,aACAC,SACAC,MACAxB,SACAyB,oBACkB;AAClB,MAAI,aAAa,KAChB,OAAM,IAAI,MAAM;EAEjB,MAAM,gBAAgB,YAAY;GACjC,MAAM,uBAAuB,MAAM,KAAK,sBAAsB,wBAAwB,UAAU;GAChG,MAAM,0BAA0B,OAAO,OACtC,CAAE,GACF,SACA,YACA;GACD,MAAM,YAAY,MAAM,KAAK,sBAAsB,kBAAkB,sBAAsB,yBAAyB,QAAQ;AAC5H,UAAO,WACN,qBAAqB,SACrB,OAAO,cACN,KAAK,WAAW,QAAQ,MAAM,WAAW,KAAK;IAC7C,aAAa;IACb,SAAS,CAAE;IACX,cAAc,UAAU;IACxB,SAAS;IACT,QAAQ;IACR;GACA,EAAC,GACF,mCACD;EACD;EACD,MAAM,eAAe,MAAM,KAAK,sBAAsB,kBAAkB,UAAU;AAElF,SAAO,uBAAuB,eAAe,aAAa;CAC1D;CAED,MAAM,0BACLlB,SACAmB,gBACAP,4BACoB;EACpB,MAAM,QAAQ,MAAM,qBAAqB,QAAQ;AAIjD,MAAI,cAAc,SAAS,sBAAsB,CAChD,OAAM,KAAW,gBAAgB,CAAC,aAAa,KAAK,QAAQ,gBAAgB,SAAS,SAAS,EAAE,EAC/F,aAAa,EACb,EAAC;AAGH,SAAO,KACN,gBACA,CAAC,aAAa;AACb,UAAO,KAAK,sBAAsB,UAAU,OAAO,2BAA2B;EAC9E,GACD,EAAE,aAAa,EAAG,EAClB;CACD;CAED,MAAM,sBAAyBQ,UAAeC,OAAkBT,4BAAqE;EACpI,IAAIU;AACJ,MAAI,2BACH,cAAa,MAAM,KAAK,QAAQ,kBAAkB,UAAU,MAAM,2BAA2B,aAAa,SAAS,CAAC,CAAC;IAErH,KAAI;AACH,gBAAa,MAAM,KAAK,QAAQ,kBAAkB,OAAO,SAAS;EAClE,SAAQ,GAAG;AACX,OAAI,aAAa,yBAAyB;AACzC,YAAQ,IAAI,iCAAiC,GAAG,EAAE,SAAS,EAAE,MAAM;AACnE,iBAAa;GACb,MACA,OAAM;EAEP;EAEF,MAAM,oBAAoB,MAAM,KAAK,eAAe,wBAA2B,OAAO,UAAU,WAAW;AAC3G,SAAO,KAAK,QAAQ,2BAA8B,kBAAkB;CACpE;CAED,MAAM,MAA4BZ,QAAmBa,UAAaC,cAAqBC,SAAqD;EAC3I,MAAM,UAAU,SAAS;EACzB,MAAM,EAAE,WAAW,MAAM,SAAS,aAAa,GAAG,MAAM,KAAK,+BAC5D,SACA,QACA,MACA,WACA,cACA,SAAS,SACT;AAED,MAAI,UAAU,SAAS,KAAK,aAC3B;QAAK,OAAQ,OAAM,IAAI,MAAM;EAAmC,WAE5D,OAAQ,OAAM,IAAI,MAAM;EAG7B,MAAM,KAAK,MAAM,KAAK,QAAQ,yBAAyB,WAAW,UAAU,SAAS,SAAS;EAE9F,MAAM,kBAAkB,MAAM,KAAK,eAAe,uBAAuB,WAAW,UAAU,GAAG;EACjG,MAAM,wBAAwB,MAAM,KAAK,WAAW,QAAQ,MAAM,WAAW,MAAM;GAClF,SAAS,SAAS;GAClB;GACA;GACA,MAAM,KAAK,UAAU,gBAAgB;GACrC,cAAc,UAAU;EACxB,EAAC;AACF,SAAO,KAAK,MAAM,sBAAsB,CAAC;CACzC;CAED,MAAM,cAAoCf,QAAmBgB,WAAyC;EACrG,MAAM,QAAQ,UAAU;AAExB,MAAI,QAAQ,EACX,QAAO,CAAE;EAGV,MAAM,iBAAiB,cAAc,qBAAqB,UAAU;EACpE,MAAM,UAAU,UAAU,GAAG;EAC7B,MAAM,EAAE,WAAW,MAAM,SAAS,GAAG,MAAM,KAAK,+BAA+B,SAAS,QAAQ,MAAM,WAAW,WAAW,UAAU;AAEtI,MAAI,UAAU,SAAS,KAAK,aAC3B;QAAK,OAAQ,OAAM,IAAI,MAAM;EAAmC,WAE5D,OAAQ,OAAM,IAAI,MAAM;EAG7B,MAAMC,SAAkB,CAAE;EAC1B,MAAMC,kBAAuB,CAAE;EAC/B,MAAMC,WAA6B,MAAM,KAAW,gBAAgB,OAAO,kBAAkB;AAC5F,OAAI;IACH,MAAM,oBAAoB,MAAM,KAAW,eAAe,OAAO,MAAM;KACtE,MAAM,KAAK,MAAM,KAAK,QAAQ,yBAAyB,WAAW,EAAE;AAEpE,YAAO,KAAK,eAAe,uBAAuB,WAAW,GAAG,GAAG;IACnE,EAAC;IAEF,MAAM,cAAc,EACnB,OAAO,OAAO,cAAc,OAAO,CACnC;IACD,MAAM,wBAAwB,MAAM,KAAK,WAAW,QAAQ,MAAM,WAAW,MAAM;KAClF;KACA;KACA,MAAM,KAAK,UAAU,kBAAkB;KACvC,cAAc,UAAU;IACxB,EAAC;AACF,WAAO,KAAK,mBAAmB,sBAAsB;GACrD,SAAQ,GAAG;AACX,QAAI,aAAa,sBAAsB;KAGtC,MAAM,cAAc,MAAM,KAAW,eAAe,CAAC,aAAa;AACjE,aAAO,KAAK,MAAM,QAAQ,SAAS,CAAC,MAAM,CAACC,QAAM;AAChD,cAAO,KAAKA,IAAE;AACd,uBAAgB,KAAK,SAAS;MAC9B,EAAC;KACF,EAAC;AACF,YAAO,YAAY,OAAO,QAAQ;IAClC,OAAM;AACN,YAAO,KAAK,EAAE;AACd,qBAAgB,KAAK,GAAG,cAAc;AACtC,YAAO,CAAE;IACT;GACD;EACD,EAAC;AAEF,MAAI,OAAO,QAAQ;AAClB,OAAI,OAAO,KAAK,eAAe,CAC9B,OAAM,IAAI,gBAAgB;AAE3B,SAAM,IAAI,mBAAsB,kCAAkC,QAAQ;EAC1E,MACA,QAAO,SAAS,MAAM;CAEvB;CAED,MAAM,OAA6BP,UAAaQ,SAAwD;AACvG,OAAK,SAAS,IAAK,OAAM,IAAI,MAAM;EACnC,MAAM,EAAE,QAAQ,WAAW,GAAG,SAAS,SAAS,IAAI;EACpD,MAAM,EAAE,MAAM,aAAa,SAAS,WAAW,GAAG,MAAM,KAAK,+BAC5D,SAAS,OACT,QACA,WACA,WACA,WACA,SAAS,iBACT;EACD,MAAM,aAAa,MAAM,KAAK,kBAAkB,SAAS,kBAAkB,UAAU,UAAU;EAC/F,MAAM,kBAAkB,MAAM,KAAK,eAAe,uBAAuB,WAAW,UAAU,WAAW;AACzG,QAAM,KAAK,WAAW,QAAQ,MAAM,WAAW,KAAK;GACnD,SAAS,SAAS;GAClB;GACA;GACA,MAAM,KAAK,UAAU,gBAAgB;GACrC,cAAc,UAAU;EACxB,EAAC;CACF;CAED,MAAM,MAA4BR,UAAaS,SAAuD;EACrG,MAAM,EAAE,QAAQ,WAAW,GAAG,SAAS,SAAS,IAAI;EACpD,MAAM,EAAE,MAAM,aAAa,SAAS,GAAG,MAAM,KAAK,+BACjD,SAAS,OACT,QACA,WACA,WACA,SAAS,cACT,UACA;AACD,QAAM,KAAK,WAAW,QAAQ,MAAM,WAAW,QAAQ;GACtD;GACA;EACA,EAAC;CACF;CAED,MAAM,+BACLvC,SACAiB,QACAuB,WACAC,aACAC,cACAC,UAME;EACF,MAAM,YAAY,MAAM,qBAAqB,QAAQ;AAErD,cAAY,UAAU;AAEtB,MAAI,YAAY,cAAc,KAAK,iBAAiB,iBAAiB,IAAI,UAAU,UAElF,OAAM,IAAI,sBAAsB,6FAA6F,UAAU,KAAK;EAG7I,IAAI,OAAO,cAAc,QAAQ;AAEjC,MAAI,OACH,SAAQ,MAAM;AAGf,MAAI,UACH,SAAQ,MAAM;EAGf,MAAM,UAAU,OAAO,OAAO,CAAE,GAAE,KAAK,iBAAiB,mBAAmB,EAAE,aAAa;AAE1F,MAAI,OAAO,KAAK,QAAQ,CAAC,WAAW,EACnC,OAAM,IAAI,sBAAsB;AAGjC,UAAQ,IAAI,UAAU;AACtB,SAAO;GACN;GACA;GACA;GACA;EACA;CACD;;;;CAKD,qBAAqBC,OAAkD;AACtE,SAAO,QAAQ,QAAQ,MAAM,OAAO;CACpC;CAED,gBAA4B;AAC3B,SAAO,KAAK;CACZ;CAED,AAAQ,mBAAmBC,QAAmB;AAC7C,MAAI;AACH,UAAO,KAAK,MAAM,OAAO,CAAC,IAAI,CAACC,MAAW,EAAE,YAAY;EACxD,SAAQ,GAAG;AACX,SAAM,IAAI,OAAO,oBAAoB,OAAO,IAAI,EAAE;EAClD;CACD;AACD;AAQM,eAAe,WAAcC,SAA0BC,QAA2BC,UAA8B;CACtH,IAAI,QAAQ;CACZ,IAAIC,QAAsB;AAC1B,MAAK,MAAM,UAAU,SAAS;AAC7B,MAAI;AACH,UAAO,MAAM,OAAO,OAAO,KAAK,MAAM;EACtC,SAAQ,GAAG;AAEX,OAAI,aAAa,mBAAmB,aAAa,uBAAuB,aAAa,eAAe;AACnG,YAAQ,KAAK,EAAE,SAAS,GAAG,OAAO,IAAI,GAAG,EAAE;AAC3C,YAAQ;GACR,MACA,OAAM;EAEP;AACD;CACA;AACD,OAAM;AACN;AASM,eAAe,uBAA0BC,eAAiCC,yBAAiD;AACjI,QAAO,eAAe,CAAC;;;EAGtB,QAAQ,oBAAoB,CAAC,MAAM;AAClC,4BAAyB;AACzB,UAAO,eAAe;EACtB,EAAC;CACF;AACD;AAEM,SAAS,OACfzB,UACAf,WAIC;AACD,MAAK,SAAS,IAAK,OAAM,IAAI,MAAM;CACnC,IAAI,SAAS;CACb,IAAI;AAEJ,KAAI,UAAU,SAAS,KAAK,aAAa;AACxC,WAAS,SAAS,IAAI;AACtB,OAAK,SAAS,IAAI;CAClB,MACA,MAAK,SAAS;AAGf,QAAO;EACN;EACA;CACA;AACD"}